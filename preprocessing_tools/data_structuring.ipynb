{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration (sec) :  3560.045833\n",
    "frame_count :  1708822\n",
    "\n",
    "duration (sec) :  3560.083333\n",
    "frame_count :  170884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H :  105\n",
      "W :  112\n",
      "fps :  48/1\n",
      "duration (sec) :  20.689583\n",
      "frame_count :  994\n",
      "codec_name :  h264\n",
      "pixel_format :  yuv444p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'streams': [{'index': 0,\n",
       "   'codec_name': 'h264',\n",
       "   'codec_long_name': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10',\n",
       "   'profile': 'High 4:4:4 Predictive',\n",
       "   'codec_type': 'video',\n",
       "   'codec_tag_string': 'avc1',\n",
       "   'codec_tag': '0x31637661',\n",
       "   'width': 112,\n",
       "   'height': 105,\n",
       "   'coded_width': 112,\n",
       "   'coded_height': 105,\n",
       "   'closed_captions': 0,\n",
       "   'film_grain': 0,\n",
       "   'has_b_frames': 2,\n",
       "   'sample_aspect_ratio': '225:224',\n",
       "   'display_aspect_ratio': '15:14',\n",
       "   'pix_fmt': 'yuv444p',\n",
       "   'level': 30,\n",
       "   'chroma_location': 'left',\n",
       "   'field_order': 'progressive',\n",
       "   'refs': 1,\n",
       "   'is_avc': 'true',\n",
       "   'nal_length_size': '4',\n",
       "   'id': '0x1',\n",
       "   'r_frame_rate': '48/1',\n",
       "   'avg_frame_rate': '477120/9931',\n",
       "   'time_base': '1/15360',\n",
       "   'start_pts': 630,\n",
       "   'start_time': '0.041016',\n",
       "   'duration_ts': 317792,\n",
       "   'duration': '20.689583',\n",
       "   'bit_rate': '80753',\n",
       "   'bits_per_raw_sample': '8',\n",
       "   'nb_frames': '994',\n",
       "   'extradata_size': 50,\n",
       "   'disposition': {'default': 1,\n",
       "    'dub': 0,\n",
       "    'original': 0,\n",
       "    'comment': 0,\n",
       "    'lyrics': 0,\n",
       "    'karaoke': 0,\n",
       "    'forced': 0,\n",
       "    'hearing_impaired': 0,\n",
       "    'visual_impaired': 0,\n",
       "    'clean_effects': 0,\n",
       "    'attached_pic': 0,\n",
       "    'timed_thumbnails': 0,\n",
       "    'non_diegetic': 0,\n",
       "    'captions': 0,\n",
       "    'descriptions': 0,\n",
       "    'metadata': 0,\n",
       "    'dependent': 0,\n",
       "    'still_image': 0},\n",
       "   'tags': {'language': 'und',\n",
       "    'handler_name': 'VideoHandler',\n",
       "    'vendor_id': '[0][0][0][0]',\n",
       "    'encoder': 'Lavc60.31.102 libx264'}}],\n",
       " 'format': {'filename': '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/segment_000.mp4',\n",
       "  'nb_streams': 1,\n",
       "  'nb_programs': 0,\n",
       "  'format_name': 'mov,mp4,m4a,3gp,3g2,mj2',\n",
       "  'format_long_name': 'QuickTime / MOV',\n",
       "  'start_time': '0.041016',\n",
       "  'duration': '20.689583',\n",
       "  'size': '221436',\n",
       "  'bit_rate': '85622',\n",
       "  'probe_score': 100,\n",
       "  'tags': {'major_brand': 'isom',\n",
       "   'minor_version': '512',\n",
       "   'compatible_brands': 'isomiso2avc1mp41',\n",
       "   'encoder': 'Lavf60.16.100'}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"get video info using ffmpeg.probe\"\"\"\n",
    "import ffmpeg\n",
    "\n",
    "video_path ='/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/segment_000.mp4'\n",
    "# video_path = '/local1/video-analysis/scratch/706893_2024-05-28_15-15-38/figures/nose/ae/D=16_recon_ae_test.mp4'\n",
    "# video_path = '/home/faeze.aminmansoor/video-analysis/videos/706893_2024-05-28_15-15-38/nose/nose_48/processed_video.mp4'\n",
    "\n",
    "# print(hight, width, fps)\n",
    "print('H : ', ffmpeg.probe(video_path)['streams'][0]['height'])\n",
    "print('W : ', ffmpeg.probe(video_path)['streams'][0]['width'])\n",
    "print('fps : ', ffmpeg.probe(video_path)['streams'][0]['r_frame_rate'])\n",
    "print('duration (sec) : ', ffmpeg.probe(video_path)['streams'][0]['duration'])\n",
    "print('frame_count : ', ffmpeg.probe(video_path)['streams'][0]['nb_frames'])\n",
    "print('codec_name : ', ffmpeg.probe(video_path)['streams'][0]['codec_name'])\n",
    "print('pixel_format : ', ffmpeg.probe(video_path)['streams'][0]['pix_fmt'])\n",
    "\n",
    "\n",
    "\n",
    "ffmpeg.probe(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H : 210\n",
      "W : 225\n",
      "FPS : 480/1\n",
      "Duration (sec) : 3560.045833\n",
      "Frame Count : 1708822\n",
      "Codec Name : h264\n",
      "Pixel Format : yuv444p\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m get_video_info(video_path)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfractions\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m fps_str \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_frame_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0/1\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Default to '0/1' if missing\u001b[39;00m\n\u001b[1;32m     28\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(fractions\u001b[38;5;241m.\u001b[39mFraction(fps_str))  \u001b[38;5;66;03m# Convert to float\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPS : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stream' is not defined"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "def get_video_info(video_path):\n",
    "    try:\n",
    "        probe = ffmpeg.probe(video_path)\n",
    "        stream = probe['streams'][0]  # Extracting the first video stream\n",
    "\n",
    "        print(f\"H : {stream.get('height', 'N/A')}\")\n",
    "        print(f\"W : {stream.get('width', 'N/A')}\")\n",
    "        print(f\"FPS : {stream.get('r_frame_rate', 'N/A')}\")  # FPS might be a fraction (e.g., '30000/1001')\n",
    "        print(f\"Duration (sec) : {stream.get('duration', 'N/A')}\")\n",
    "        print(f\"Frame Count : {stream.get('nb_frames', 'N/A')}\")\n",
    "        print(f\"Codec Name : {stream.get('codec_name', 'N/A')}\")\n",
    "        print(f\"Pixel Format : {stream.get('pix_fmt', 'N/A')}\")\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error retrieving video info: {e.stderr.decode()}\")\n",
    "\n",
    "# Define video path\n",
    "video_path = '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ears/left_ear_.mp4'\n",
    "\n",
    "# Run the function\n",
    "get_video_info(video_path)\n",
    "\n",
    "import fractions\n",
    "\n",
    "fps_str = stream.get('r_frame_rate', '0/1')  # Default to '0/1' if missing\n",
    "fps = float(fractions.Fraction(fps_str))  # Convert to float\n",
    "print(f\"FPS : {fps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trims to the first `t` seconds (if specified). Downsizes dimensions by a specified ratio. Adjusts the frame rate by a specified factor. Splits the video into segments of a specified duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def process_video(input_video_path, output_directory, downsize_ratio=None, frame_rate_factor=None,\n",
    "                   segment_duration=None, t_start=None, t_stop=None, frame_rate_mode=\"vfr\"):\n",
    "    \"\"\"\n",
    "    Processes a video with optional resizing, frame rate adjustment, trimming (using t_start and t_stop),\n",
    "    and segmentation. Allows choosing frame rate mode (-vsync vfr or -vsync cfr).\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Temporary file path for the processed video\n",
    "    temp_video_path = os.path.join(output_directory, 'temp_video.mp4')\n",
    "\n",
    "    # Build the FFmpeg command for processing\n",
    "    ffmpeg_command = ['ffmpeg', '-i', input_video_path]\n",
    "\n",
    "    # Apply trimming if t_start and t_stop are specified\n",
    "    if t_start is not None:\n",
    "        ffmpeg_command.extend(['-ss', str(t_start)])\n",
    "    if t_stop is not None:\n",
    "        ffmpeg_command.extend(['-to', str(t_stop)])\n",
    "\n",
    "    # Get original frame rate if frame rate adjustment is needed\n",
    "    original_frame_rate = None\n",
    "    new_frame_rate = None\n",
    "    N = None\n",
    "\n",
    "    if frame_rate_factor is not None:\n",
    "        probe = subprocess.run(\n",
    "            ['ffprobe', '-v', 'error', '-select_streams', 'v:0',\n",
    "             '-show_entries', 'stream=r_frame_rate', '-of',\n",
    "             'default=noprint_wrappers=1:nokey=1', input_video_path],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        original_frame_rate = eval(probe.stdout.strip())  # Convert frame rate from string to float\n",
    "        new_frame_rate = int(original_frame_rate * frame_rate_factor)\n",
    "        N = int(1 / frame_rate_factor)  # Calculate frame step (e.g., N=10 for 480 → 48)\n",
    "\n",
    "    # Construct filter list\n",
    "    filter_list = []\n",
    "\n",
    "    # Apply downscaling if requested\n",
    "    if downsize_ratio is not None:\n",
    "        filter_list.append(f\"scale=iw*{downsize_ratio}:ih*{downsize_ratio}\")\n",
    "\n",
    "    # Apply frame rate reduction if needed\n",
    "    if frame_rate_factor is not None and N is not None:\n",
    "        if frame_rate_mode == \"vfr\":\n",
    "            # Apply frame skipping using select filter\n",
    "            filter_list.append(f\"select='not(mod(n,{N}))'\")\n",
    "        elif frame_rate_mode == \"cfr\":\n",
    "            # Enforce exact FPS by duplicating/removing frames if necessary\n",
    "            filter_list.append(f\"fps={new_frame_rate}\")\n",
    "\n",
    "    # Merge filters to avoid overwriting\n",
    "    if filter_list:\n",
    "        ffmpeg_command.extend(['-vf', ','.join(filter_list)])\n",
    "\n",
    "    # Set vsync option **before** filters\n",
    "    if frame_rate_factor is not None:\n",
    "        if frame_rate_mode == \"vfr\":\n",
    "            ffmpeg_command.insert(1, '-vsync')\n",
    "            ffmpeg_command.insert(2, 'vfr')\n",
    "        elif frame_rate_mode == \"cfr\":\n",
    "            ffmpeg_command.insert(1, '-vsync')\n",
    "            ffmpeg_command.insert(2, 'cfr')\n",
    "\n",
    "    # Set the codec and output file\n",
    "    ffmpeg_command.extend(['-c:v', 'libx264', '-crf', '18', '-preset', 'slow', temp_video_path])\n",
    "\n",
    "    # Execute the FFmpeg command\n",
    "    subprocess.run(ffmpeg_command, check=True)\n",
    "\n",
    "    # Split the processed video into segments if 'segment_duration' is specified\n",
    "    if segment_duration is not None:\n",
    "        segment_output_path = os.path.join(output_directory, 'segment_%03d.mp4')\n",
    "        split_command = [\n",
    "            'ffmpeg', '-i', temp_video_path, '-c', 'copy',\n",
    "            '-f', 'segment', '-segment_time', str(segment_duration), '-reset_timestamps', '1',\n",
    "            segment_output_path\n",
    "        ]\n",
    "        subprocess.run(split_command, check=True)\n",
    "        os.remove(temp_video_path)\n",
    "    else:\n",
    "        final_output_path = os.path.join(output_directory, 'processed_video.mp4')\n",
    "        os.rename(temp_video_path, final_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodypart = 'ear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-2)\n",
      "  configuration: --prefix=/home/faeze.aminmansoor/miniconda3/envs/video-analysis-env --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1699729448698/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1699729448698/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1699729448698/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1699729448698/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1699729448698/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/left_ear_.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:59:20.05, start: 0.002018, bitrate: 85792 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p(progressive), 225x210 [SAR 1:1 DAR 15:14], 85775 kb/s, 480 fps, 480 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55c0a635fb80] using SAR=1/1\n",
      "[libx264 @ 0x55c0a635fb80] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x55c0a635fb80] profile High 4:4:4 Predictive, level 3.1, 4:4:4, 8-bit\n",
      "[libx264 @ 0x55c0a635fb80] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/temp_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv444p(progressive), 225x210 [SAR 1:1 DAR 15:14], q=2-31, 480 fps, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/mp4 @ 0x55c0a628bf80] video:76711kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.831670%\n",
      "frame=120000 fps=740 q=-1.0 Lsize=   78116kB time=00:04:09.99 bitrate=2559.8kbits/s speed=1.54x    \n",
      "[libx264 @ 0x55c0a635fb80] frame I:480   Avg QP:19.02  size: 10155\n",
      "[libx264 @ 0x55c0a635fb80] frame P:30628 Avg QP:21.41  size:  2085\n",
      "[libx264 @ 0x55c0a635fb80] frame B:88892 Avg QP:27.95  size:   111\n",
      "[libx264 @ 0x55c0a635fb80] consecutive B-frames:  1.1%  0.2%  0.5% 98.2%\n",
      "[libx264 @ 0x55c0a635fb80] mb I  I16..4:  0.9% 69.3% 29.8%\n",
      "[libx264 @ 0x55c0a635fb80] mb P  I16..4:  0.4%  1.8%  0.8%  P16..4: 42.3% 24.8% 16.0%  0.0%  0.0%    skip:13.9%\n",
      "[libx264 @ 0x55c0a635fb80] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 33.4%  1.3%  0.2%  direct: 0.5%  skip:64.5%  L0:32.3% L1:62.5% BI: 5.2%\n",
      "[libx264 @ 0x55c0a635fb80] 8x8 transform intra:63.2% inter:41.2%\n",
      "[libx264 @ 0x55c0a635fb80] direct mvs  spatial:100.0% temporal:0.0%\n",
      "[libx264 @ 0x55c0a635fb80] coded y,u,v intra: 68.3% 5.2% 11.7% inter: 13.6% 0.1% 0.3%\n",
      "[libx264 @ 0x55c0a635fb80] i16 v,h,dc,p:  4% 86%  7%  3%\n",
      "[libx264 @ 0x55c0a635fb80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 44%  9%  5%  3%  3%  6%  5% 10%\n",
      "[libx264 @ 0x55c0a635fb80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 25%  6%  4%  4%  3%  6%  4%  9%\n",
      "[libx264 @ 0x55c0a635fb80] Weighted P-Frames: Y:0.7% UV:0.0%\n",
      "[libx264 @ 0x55c0a635fb80] ref P L0: 64.0% 15.2% 16.1%  2.1%  2.6%  0.0%\n",
      "[libx264 @ 0x55c0a635fb80] ref B L0: 89.7%  8.7%  1.3%  0.4%\n",
      "[libx264 @ 0x55c0a635fb80] ref B L1: 93.6%  6.4%\n",
      "[libx264 @ 0x55c0a635fb80] kb/s:2513.64\n"
     ]
    }
   ],
   "source": [
    "input_video_path = f\"/local1/video-analysis/videos/706893_2024-05-28_15-15-38/{bodypart}/left_ear_.mp4\"\n",
    "output_directory = f'/local1/video-analysis/videos/706893_2024-05-28_15-15-38/{bodypart}'\n",
    "\n",
    "process_video(\n",
    "    input_video_path,\n",
    "    output_directory,\n",
    "    downsize_ratio=None,        # Resize by 50% (properly applied)\n",
    "    frame_rate_factor=None,     # Reduce to 10% of original frame rate (e.g., 480 → 48)\n",
    "    segment_duration=None,       # Set to desired duration or None to skip\n",
    "    t_start=2300, \n",
    "    t_stop=2500,                    # Trim first 30 sec\n",
    "    frame_rate_mode=\"vfr\"      # Choose \"vfr\" for dropping frames, \"cfr\" for forcing exact FPS\n",
    ")\n",
    "\n",
    "# def process_video(input_video_path, output_directory, downsize_ratio=None, frame_rate_factor=None,\n",
    "#                    segment_duration=None, t_start=None, t_stop=None, frame_rate_mode=\"vfr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of command options\n",
    "\n",
    "-c:v h264: This sets the video codec to H.264, a commonly used codec known for its efficient compression and high quality. H.264 is widely compatible with most video players and platforms.\n",
    "\n",
    "-crf 0: The Constant Rate Factor (CRF) is a setting that adjusts the video quality. Setting -crf 0 results in lossless compression for H.264, meaning the video quality will be preserved exactly as in the input. (For lossy but efficient compression, a CRF value of 18-23 is typically used.)\n",
    "\n",
    "-preset slow: This option defines the speed of the encoding process. Preset values (from \"ultrafast\" to \"veryslow\") impact both quality and file size; slower presets generally provide better compression. The slow preset means the encoding process will take more time but result in better compression efficiency (i.e., smaller file size for the same quality).\n",
    "\n",
    "-c:a copy: This sets the audio codec, with copy indicating that the audio stream should be copied without re-encoding. This preserves the original audio quality and saves processing time, as the audio doesn’t need to be processed further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mata data of segment_000.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specs of the prosesseced video, first segment:\n",
      "H :  124\n",
      "W :  309\n",
      "fps :  480/1\n",
      "duration (sec) :  20.312500\n",
      "frame_count :  9750\n",
      "codec_name :  h264\n",
      "pixel_format :  yuv444p\n"
     ]
    }
   ],
   "source": [
    "# print(hight, width, fps)\n",
    "import ffmpeg\n",
    "video_path = output_directory + '/segment_000.mp4'\n",
    "print('specs of the prosesseced video, first segment:')\n",
    "\n",
    "print('H : ', ffmpeg.probe(video_path)['streams'][0]['height'])\n",
    "print('W : ', ffmpeg.probe(video_path)['streams'][0]['width'])\n",
    "print('fps : ', ffmpeg.probe(video_path)['streams'][0]['r_frame_rate'])\n",
    "print('duration (sec) : ', ffmpeg.probe(video_path)['streams'][0]['duration'])\n",
    "print('frame_count : ', ffmpeg.probe(video_path)['streams'][0]['nb_frames'])\n",
    "print('codec_name : ', ffmpeg.probe(video_path)['streams'][0]['codec_name'])\n",
    "print('pixel_format : ', ffmpeg.probe(video_path)['streams'][0]['pix_fmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local1/video-analysis/videos/706893_2024-05-28_15-15-38/tongue_mouth/tongue_mouth-seg20sec-480Hz/segment_000.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "\n",
    "# # assume images are in an np array named \"images_np\"; this should be a an array of dtype\n",
    "# # 'uint8', and values should be between 0 and 255. The data type is converted to float\n",
    "# # and values are divided by 255 during the data loading process.\n",
    "\n",
    "# Video data is assumed to be in a list, where each list element corresponds to a single trial, and is a numpy array of shape \n",
    "# (n_frames, n_channels, y_pix, x_pix).\n",
    "\n",
    "# hdf5_file = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/VideoFolder/hdf5_file/data.hdf5'  # path needs to exist, but not 'data.hdf5' file\n",
    "\n",
    "# with h5py.File(hdf5_file, 'w', libver='latest', swmr=True) as f:\n",
    "\n",
    "#     # enable single write, multi-read - needed for simultaneous model fitting\n",
    "#     f.swmr_mode = True\n",
    "\n",
    "#     # create \"image\" HDF5 group\n",
    "#     group_i = f.create_group('images')\n",
    "\n",
    "#     # create a dataset for each trial within groups\n",
    "#     for trial in range(len(images_np)):\n",
    "\n",
    "#         # create dataset in \"image\" group\n",
    "#         # images_np[trial] should be of shape (n_frames, n_channels, y_pix, x_pix)\n",
    "#         group_i.create_dataset('trial_%04i' % trial, data=images_np[trial], dtype='uint8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make data.hdf5 file from segmented videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17641/2860369652.py:38: UserWarning: swmr=True only affects read ('r') mode. For swmr write mode, set f.swmr_mode = True after opening the file.\n",
      "  with h5py.File(hdf5_file, 'w', libver='latest', swmr=True) as f:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extracts frames from a given video file, adds a channel dimension for grayscale, and stores them in an HDF5 file, with dimensions \n",
    "(n_frames, 1, y_pix, x_pix)\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Video data is assumed to be in a list, where each list element corresponds to a single trial, and is a numpy array of shape \n",
    "# (n_frames, n_channels, y_pix, x_pix).\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    \"\"\" Extracts frames from a given video file and adds a channel dimension for grayscale \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Add a channel dimension: (y_pix, x_pix) to (1, y_pix, x_pix)\n",
    "        gray_frame = gray_frame[np.newaxis, :, :]  # Adds a new axis for the channel\n",
    "        frames.append(gray_frame)\n",
    "    cap.release()\n",
    "    return np.array(frames, dtype=np.uint8)  # Shape becomes (n_frames, 1, y_pix, x_pix)\n",
    "\n",
    "def videos_to_hdf5(video_folder, hdf5_path):\n",
    "    \"\"\" Converts video segments into an HDF5 file with a specified shape per trial \"\"\"\n",
    "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
    "    video_files.sort()  # Sort files to maintain order\n",
    "\n",
    "    hdf5_file = hdf5_path  # Define the path to your HDF5 file\n",
    "    # if hdf5_path dose not exist, create it\n",
    "    if not os.path.exists(os.path.dirname(hdf5_file)):\n",
    "        os.makedirs(os.path.dirname(hdf5_file))\n",
    "\n",
    "\n",
    "    with h5py.File(hdf5_file, 'w', libver='latest', swmr=True) as f:\n",
    "        f.swmr_mode = True\n",
    "        group_i = f.create_group('images')\n",
    "        for i, video_file in enumerate(video_files):\n",
    "            video_path = os.path.join(video_folder, video_file)\n",
    "            frames = extract_frames(video_path)\n",
    "            # Store each video's frames in a separate dataset\n",
    "            group_i.create_dataset(f'trial_{i:04d}', data=frames, dtype='uint8')\n",
    "\n",
    "# Define paths and call the function\n",
    "video_folder = '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/ear-seg20sec'  # Update this path to your video segments folder\n",
    "hdf5_path = '/local1/video-analysis/videos/706893_2024-05-28_15-15-38/ear/hdf5-dir/data.hdf5'  # Update this path to where you want your HDF5 file\n",
    "videos_to_hdf5(video_folder, hdf5_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.hdf5 file size: 251205522.375 Bytes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"get the size of data.hdf5 file\"\"\"\n",
    "\n",
    "file_size = os.path.getsize(hdf5_path)  # Size in bytes\n",
    "print(f\"data.hdf5 file size: {file_size/8} Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the number of frames in the selected_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataset for trial_0000  [(n_frames, n_channels, y_pix, x_pix)]: (1000, 1, 105, 112)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"get the dimensions of a dataset in an HDF5 file\"\"\"\n",
    "\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file and access a specific dataset to print its dimensions\n",
    "with h5py.File(hdf5_path, 'r') as file:\n",
    "    data_shape = file['images/trial_0000'].shape  # Adjust the dataset path as needed\n",
    "    print(f\"Dimensions of the dataset for trial_0000  [(n_frames, n_channels, y_pix, x_pix)]: {data_shape}\")\n",
    "\n",
    "# print(hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def get_frame_counts(hdf5_path, selected_trials=None):\n",
    "    \"\"\"\n",
    "    Reads an HDF5 file and extracts the number of frames for each selected trial.\n",
    "\n",
    "    Parameters:\n",
    "        hdf5_path (str): Path to the HDF5 file.\n",
    "        selected_trials (list, optional): List of trial indices to include. If None, all trials will be used.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with trial keys and their corresponding frame counts.\n",
    "        int: The total number of frames across the selected trials.\n",
    "        int: The total number of trials in the HDF5 file.\n",
    "    \"\"\"\n",
    "    n_frames_dict = {}\n",
    "\n",
    "    with h5py.File(hdf5_path, 'r') as f:\n",
    "        images_group = f['images']\n",
    "        total_num_trials = len(images_group.keys())  # Get the total number of trials\n",
    "\n",
    "        # If no specific trials are selected, use all available trials\n",
    "        if selected_trials is None:\n",
    "            selected_trials = list(range(total_num_trials))\n",
    "\n",
    "        # Loop over the selected trial indices\n",
    "        for idx in selected_trials:\n",
    "            trial_key = f\"trial_{idx:04d}\"\n",
    "            if trial_key in images_group:\n",
    "                n_frames = images_group[trial_key].shape[0]  # Extract number of frames\n",
    "                n_frames_dict[trial_key] = n_frames\n",
    "\n",
    "    # Compute total frames across selected trials\n",
    "    total_num_frames = sum(n_frames_dict.values())\n",
    "\n",
    "    return n_frames_dict, total_num_frames, total_num_trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trials in the HDF5 file: 178\n",
      "Total number of frames for selected trials: 170883\n",
      "Frame counts per trial: {'trial_0000': 1000, 'trial_0001': 1071, 'trial_0002': 1000, 'trial_0003': 1000, 'trial_0004': 889, 'trial_0005': 1000, 'trial_0006': 1000, 'trial_0007': 750, 'trial_0008': 1119, 'trial_0009': 978, 'trial_0010': 890, 'trial_0011': 1000, 'trial_0012': 1000, 'trial_0013': 973, 'trial_0014': 750, 'trial_0015': 997, 'trial_0016': 1000, 'trial_0017': 971, 'trial_0018': 1000, 'trial_0019': 986, 'trial_0020': 1000, 'trial_0021': 750, 'trial_0022': 1143, 'trial_0023': 870, 'trial_0024': 882, 'trial_0025': 979, 'trial_0026': 933, 'trial_0027': 1188, 'trial_0028': 968, 'trial_0029': 750, 'trial_0030': 1000, 'trial_0031': 975, 'trial_0032': 1000, 'trial_0033': 1000, 'trial_0034': 1000, 'trial_0035': 750, 'trial_0036': 1000, 'trial_0037': 972, 'trial_0038': 1000, 'trial_0039': 1000, 'trial_0040': 971, 'trial_0041': 1000, 'trial_0042': 1000, 'trial_0043': 750, 'trial_0044': 1000, 'trial_0045': 1000, 'trial_0046': 1000, 'trial_0047': 954, 'trial_0048': 1000, 'trial_0049': 1000, 'trial_0050': 965, 'trial_0051': 750, 'trial_0052': 1000, 'trial_0053': 1000, 'trial_0054': 960, 'trial_0055': 1000, 'trial_0056': 1000, 'trial_0057': 1000, 'trial_0058': 945, 'trial_0059': 975, 'trial_0060': 956, 'trial_0061': 962, 'trial_0062': 1000, 'trial_0063': 750, 'trial_0064': 1000, 'trial_0065': 1000, 'trial_0066': 1000, 'trial_0067': 1000, 'trial_0068': 1000, 'trial_0069': 750, 'trial_0070': 1000, 'trial_0071': 1000, 'trial_0072': 1000, 'trial_0073': 1000, 'trial_0074': 1000, 'trial_0075': 743, 'trial_0076': 992, 'trial_0077': 1000, 'trial_0078': 982, 'trial_0079': 1000, 'trial_0080': 1000, 'trial_0081': 1000, 'trial_0082': 991, 'trial_0083': 750, 'trial_0084': 1000, 'trial_0085': 1000, 'trial_0086': 934, 'trial_0087': 1000, 'trial_0088': 1000, 'trial_0089': 1000, 'trial_0090': 750, 'trial_0091': 1000, 'trial_0092': 971, 'trial_0093': 1000, 'trial_0094': 992, 'trial_0095': 1000, 'trial_0096': 1000, 'trial_0097': 976, 'trial_0098': 750, 'trial_0099': 1000, 'trial_0100': 964, 'trial_0101': 1000, 'trial_0102': 1000, 'trial_0103': 1000, 'trial_0104': 991, 'trial_0105': 1000, 'trial_0106': 945, 'trial_0107': 912, 'trial_0108': 1000, 'trial_0109': 750, 'trial_0110': 984, 'trial_0111': 1000, 'trial_0112': 997, 'trial_0113': 1000, 'trial_0114': 1000, 'trial_0115': 1000, 'trial_0116': 750, 'trial_0117': 1000, 'trial_0118': 1000, 'trial_0119': 973, 'trial_0120': 1000, 'trial_0121': 1000, 'trial_0122': 1000, 'trial_0123': 750, 'trial_0124': 958, 'trial_0125': 1000, 'trial_0126': 1000, 'trial_0127': 1000, 'trial_0128': 1000, 'trial_0129': 1000, 'trial_0130': 750, 'trial_0131': 1000, 'trial_0132': 1000, 'trial_0133': 1000, 'trial_0134': 994, 'trial_0135': 1000, 'trial_0136': 992, 'trial_0137': 750, 'trial_0138': 1000, 'trial_0139': 1000, 'trial_0140': 1000, 'trial_0141': 1000, 'trial_0142': 971, 'trial_0143': 1000, 'trial_0144': 750, 'trial_0145': 1000, 'trial_0146': 1000, 'trial_0147': 978, 'trial_0148': 1000, 'trial_0149': 1000, 'trial_0150': 901, 'trial_0151': 1000, 'trial_0152': 1000, 'trial_0153': 750, 'trial_0154': 1000, 'trial_0155': 1000, 'trial_0156': 1000, 'trial_0157': 979, 'trial_0158': 998, 'trial_0159': 989, 'trial_0160': 750, 'trial_0161': 1000, 'trial_0162': 1000, 'trial_0163': 1000, 'trial_0164': 1000, 'trial_0165': 1000, 'trial_0166': 750, 'trial_0167': 1000, 'trial_0168': 1160, 'trial_0169': 750, 'trial_0170': 1000, 'trial_0171': 1000, 'trial_0172': 1000, 'trial_0173': 977, 'trial_0174': 994, 'trial_0175': 953, 'trial_0176': 1000, 'trial_0177': 720}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# hdf5_path = '/home/faeze.aminmansoor/video-analysis/scratch/706893_2024-05-28_15-15-38/data/xinxin/coupled-baiting_tongue_mouth/706893/2024-05-28/data.hdf5'\n",
    "\n",
    "# Define the list of trial indices you are interested in (e.g., excluded segments)\n",
    "# excluded_segments = [0, 1, 2, 3, 174, 175, 176, 177]\n",
    "# selected_segments = excluded_segments\n",
    "# print('Excluded segments:', excluded_segments)\n",
    "# selected_segments = [0, 1, 2, 3]\n",
    "selected_segments = list(range(178))  # Define specific trials to analyze\n",
    "\n",
    "n_frames_dict, total_num_frames, total_num_frames_in_segments = get_frame_counts(hdf5_path, selected_segments)\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of trials in the HDF5 file:\", total_num_frames_in_segments)\n",
    "print(\"Total number of frames for selected trials:\", total_num_frames)\n",
    "print(\"Frame counts per trial:\", n_frames_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mkdir -p /local1/video-analysis/scratch/706893_2024-05-28_15-15-38/data/xinxin/coupled-baiting_tongue_mouth/706893/2024-05-28/\n",
    "### mv hdf5_path /local1/video-analysis/scratch/706893_2024-05-28_15-15-38/data/xinxin/coupled-baiting_tongue_mouth/706893/2024-05-28/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few random functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_090.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_091.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_092.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_093.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_094.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_095.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_096.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_097.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_098.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_099.avi\n",
      "Processing: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/segment_100.avi\n",
      "Video concatenation completed: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/combined_video_90_to_100.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, concat, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/input_videos.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: 258 kb/s\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 290x224 [SAR 1:1 DAR 145:112], 258 kb/s, 50 fps, 50 tbr, 50 tbn\n",
      "Output #0, avi, to '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/combined_video_90_to_100.avi':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (FMP4 / 0x34504D46), yuv420p, 290x224 [SAR 1:1 DAR 145:112], q=2-31, 258 kb/s, 50 fps, 50 tbr, 50 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[out#0/avi @ 0x11de10610] video:3638kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.786685%\n",
      "size=    3776kB time=00:01:50.36 bitrate= 280.3kbits/s speed=1.72e+03x    \n"
     ]
    }
   ],
   "source": [
    "\"\"\"combine video segments into a single video file\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Path to the directory containing the video segments\n",
    "directory = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/face_50fr_10sec_clips/'\n",
    "\n",
    "# Create a text file to list the video segments from 351 to 361\n",
    "file_list_path = os.path.join(directory, 'input_videos.txt')\n",
    "\n",
    "with open(file_list_path, 'w') as file_list:\n",
    "    for i in range(90, 101):  # 362 because range end is exclusive\n",
    "        if i < 10:\n",
    "            segment_path = os.path.join(directory, f'segment_00{i}.avi')\n",
    "        elif i < 100:\n",
    "            segment_path = os.path.join(directory, f'segment_0{i}.avi')\n",
    "        else:\n",
    "            segment_path = os.path.join(directory, f'segment_{i}.avi')\n",
    "        # print(f\"Processing: {segment_path}\")\n",
    "        if os.path.exists(segment_path):\n",
    "            file_list.write(f\"file '{segment_path}'\\n\")\n",
    "        else:\n",
    "            print(f\"Warning: {segment_path} not found.\")\n",
    "\n",
    "# Output path for the combined video\n",
    "output_video = os.path.join(directory, 'combined_video_90_to_100.avi')\n",
    "\n",
    "# Run ffmpeg command to concatenate the videos\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-f', 'concat',\n",
    "    '-safe', '0',\n",
    "    '-i', file_list_path,\n",
    "    '-c', 'copy',\n",
    "    output_video\n",
    "]\n",
    "\n",
    "# Execute the ffmpeg command\n",
    "subprocess.run(ffmpeg_command)\n",
    "\n",
    "print(f\"Video concatenation completed: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, image2, from '/Users/faeze.aminmansoor/Downloads/IMG_5439.jpg':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 491968 kb/s\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 3024x4032 [SAR 72:72 DAR 3:4], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x120028000] deprecated pixel format used, make sure you did set range correctly\n",
      "[swscaler @ 0x110008000] deprecated pixel format used, make sure you did set range correctly\n",
      "[swscaler @ 0x1580b0000] deprecated pixel format used, make sure you did set range correctly\n",
      "    Last message repeated 1 times\n",
      "[swscaler @ 0x130890000] deprecated pixel format used, make sure you did set range correctly\n",
      "[swscaler @ 0x140ac8000] deprecated pixel format used, make sure you did set range correctly\n",
      "    Last message repeated 2 times\n",
      "Output #0, image2, to '/Users/faeze.aminmansoor/Downloads/IMG_5439_brightened_02.jpg':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown, progressive), 3024x4032 [SAR 1:1 DAR 3:4], q=2-31, 200 kb/s, 25 fps, 25 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "[image2 @ 0x150005b20] The specified filename '/Users/faeze.aminmansoor/Downloads/IMG_5439_brightened_02.jpg' does not contain an image sequence pattern or a pattern is invalid.\n",
      "[image2 @ 0x150005b20] Use a pattern such as %03d for an image sequence or use the -update option (with -frames:v 1 if needed) to write a single image.\n",
      "[out#0/image2 @ 0x1500058b0] video:358kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "frame=    1 fps=0.0 q=9.1 Lsize=N/A time=00:00:00.00 bitrate=N/A speed=   0x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" get an image and increase brightness  \"\"\"\n",
    "import ffmpeg\n",
    "\n",
    "# Step 1: Convert HEIC to JPG\n",
    "input_path = '/Users/faeze.aminmansoor/Downloads/IMG_5439.jpg'\n",
    "# intermediate_path = '/Users/faeze.aminmansoor/Downloads/IMG_5439_intermediate.jpg'\n",
    "output_path = '/Users/faeze.aminmansoor/Downloads/IMG_5439_brightened_02.jpg'\n",
    "\n",
    "# Convert HEIC to intermediate JPG\n",
    "# ffmpeg.input(input_path).output(intermediate_path).run()\n",
    "\n",
    "# Step 2: Increase brightness on the JPG file\n",
    "ffmpeg.input(input_path).output(output_path, vf='eq=brightness=0.2').run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffplay version 7.1 Copyright (c) 2003-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, avi, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/side_camera.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf60.12.100\n",
      "  Duration: 01:05:51.21, start: 0.000000, bitrate: 7966 kb/s\n",
      "  Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(progressive), 720x540, 7884 kb/s, 500 fps, 500 tbr, 500 tbn\n",
      "[swscaler @ 0x1505f8000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x150738000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x150878000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x1509b8000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x1582b0000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x1585e8000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x158728000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x158868000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x1589a8000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x158ae8000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "[swscaler @ 0x158c28000] No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "-18446744073709548.00 M-V:  0.000 fd=4143 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffplay', '-ss', '10', '-i', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/side_camera.avi', '-t', '10'], returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"read the input video and display a segment of it, from start_time to start_time + duration\"\"\"\n",
    "import subprocess\n",
    "\n",
    "# Define the input file path and parameters\n",
    "# input_file = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/VideoFolder/face_paw_500fr_10sec_clips/segment_000.avi\"\n",
    "start_time = \"10\"  # Start time in seconds\n",
    "duration = \"10\"    # Duration in seconds\n",
    "\n",
    "# Run the FFmpeg command to display the video section\n",
    "subprocess.run([\n",
    "    \"ffplay\", \n",
    "    \"-ss\", start_time, \n",
    "    \"-i\", input_file, \n",
    "    \"-t\", duration\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, avi, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/side_camera.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf60.12.100\n",
      "  Duration: 01:05:51.21, start: 0.000000, bitrate: 7966 kb/s\n",
      "  Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(progressive), 720x540, 7884 kb/s, 500 fps, 500 tbr, 500 tbn\n",
      "Output #0, avi, to '/Users/faeze.aminmansoor/Downloads/output_clip_.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf60.12.100\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(progressive), 720x540, q=2-31, 7884 kb/s, 500 fps, 500 tbr, 500 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[avi @ 0x15971edb0] Timestamps are unset in a packet for stream 0. This is deprecated and will stop working in the future. Fix your code to set the timestamps properly\n",
      "[out#0/avi @ 0x15971ecf0] video:9035kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.452069%\n",
      "size=    9166kB time=00:00:09.99 bitrate=7510.4kbits/s speed= 302x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-ss', '10', '-i', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/side_camera.avi', '-t', '10', '-c', 'copy', '/Users/faeze.aminmansoor/Downloads/output_clip_.avi'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"read the input video and save a segment of it, from start_time to start_time + duration \"\"\"\n",
    "output_file = \"/Users/faeze.aminmansoor/Downloads/output_clip_.avi\"\n",
    "input_file = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/684039_2023-12-13_10-46-46/side_camera.avi'\n",
    "# output_file = \"output_clip_.avi\"\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \n",
    "    \"-ss\", start_time, \n",
    "    \"-i\", input_file, \n",
    "    \"-t\", duration, \n",
    "    \"-c\", \"copy\", \n",
    "    output_file\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and save a selected frame from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame saved as 'frame.png'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code snopeet shows how to extract a chosen frame from a video file and save it as an image file using OpenCV.\"\"\"\n",
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "video_path = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Set to the desired frame (e.g., frame #100)\n",
    "frame_number = 160\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "# Read the frame\n",
    "ret, frame = cap.read()\n",
    "if ret:\n",
    "    # Save the frame as an image\n",
    "    cv2.imwrite('frame.png', frame)\n",
    "    print(\"Frame saved as 'frame.png'\")\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept clicks on images, and stores the coordinates of the clicked point,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point added at (19, 346)\n",
      "Point added at (217, 336)\n",
      "Point added at (282, 375)\n",
      "Point added at (337, 378)\n",
      "Point added at (526, 531)\n",
      "Point added at (11, 536)\n",
      "Coordinates of clicked points: [(19, 346), (217, 336), (282, 375), (337, 378), (526, 531), (11, 536)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code snippet shows how to display an image using Matplotlib and add a point to the plot when the user clicks on the image. \n",
    "The coordinates of the clicked points are stored in a list named \"coords\" and displayed after the plot window is closed.\"\"\"\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Ensure an interactive backend is used\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved frame\n",
    "img = plt.imread('frame.png')\n",
    "\n",
    "# List to store the coordinates\n",
    "coords = []\n",
    "\n",
    "# Define the click event function\n",
    "def onclick(event):\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        coords.append((x, y))\n",
    "        print(f\"Point added at ({x}, {y})\")\n",
    "        ax.plot(x, y, 'ro')  # Mark the point in red\n",
    "        fig.canvas.draw_idle()  # Update the figure\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Connect the click event handler\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# After closing the plot window\n",
    "fig.canvas.mpl_disconnect(cid)\n",
    "print(\"Coordinates of clicked points:\", coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 346), (217, 336), (282, 375), (337, 378), (526, 531), (11, 536)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks the area outside a polygon defined by polygon_points on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mask_outside_polygon(image_path, polygon_points):\n",
    "    \"\"\"\n",
    "    Masks the area outside a polygon defined by polygon_points on an image.\n",
    "\n",
    "    :param image_path: Path to the input image.\n",
    "    :param polygon_points: List of (x, y) tuples defining the polygon.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Could not find or open the image at {image_path}\")\n",
    "\n",
    "    # Convert polygon points to a NumPy array\n",
    "    points = np.array(polygon_points, dtype=np.int32)\n",
    "\n",
    "    # Create a mask with the same size as the image, initialized to zero (black)\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Fill the polygon in the mask with white (value 255)\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "\n",
    "    # Apply the mask to the image: keep the polygon and set the rest to black\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Display the original and masked image\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Masked Image\")\n",
    "    plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = './frame.png' # \"your_image_path_here.jpg\"  # Replace with the path to your image\n",
    "polygon_points = coords #[(73, 5), (77, 166), (245, 162), (286, 137), (360, 127), (429, 52), (447, 5)]\n",
    "\n",
    "try:\n",
    "    mask_outside_polygon(image_path, polygon_points)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crops a video to the smallest rectangle surrounding a polygon, masks the outside of the polygon black, and saves the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crop_and_mask_video(video_path, polygon_points, output_path):\n",
    "    \"\"\"\n",
    "    Crops a video to the smallest rectangle surrounding a polygon, masks the outside of the polygon black, and saves the output video.\n",
    "\n",
    "    :param video_path: Path to the input video.\n",
    "    :param polygon_points: List of (x, y) tuples defining the polygon.\n",
    "    :param output_path: Path to save the output video.\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        raise FileNotFoundError(f\"Could not find or open the video at {video_path}\")\n",
    "\n",
    "    # Convert polygon points to a NumPy array\n",
    "    points = np.array(polygon_points, dtype=np.int32)\n",
    "\n",
    "    # Find the bounding rectangle of the polygon\n",
    "    x, y, w, h = cv2.boundingRect(points)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    output_size = (w, h)\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, output_size)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Create a mask for the polygon\n",
    "        mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        cv2.fillPoly(mask, [points], 255)\n",
    "\n",
    "        # Apply the mask to the frame\n",
    "        masked_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        # Crop the frame to the bounding rectangle\n",
    "        cropped_frame = masked_frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Write the cropped frame to the output video\n",
    "        out.write(cropped_frame)\n",
    "\n",
    "    # Release resources\n",
    "    video.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "# video_path = \"your_video_path_here.avi\"  # Replace with the path to your video\n",
    "polygon_points = coords#[(73, 5), (77, 166), (245, 162), (286, 137), (360, 127), (429, 52), (447, 5)]\n",
    "# output_path = \"output_video.avi\"\n",
    "input_video_path = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi'\n",
    "output_video_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4\"\n",
    "\n",
    "try:\n",
    "    crop_and_mask_video(input_video_path, polygon_points, output_video_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacks two videos vertically, with additional padding to ensure equal widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Metadata:\n",
      "Video 1:\n",
      "  Path: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_right.mp4\n",
      "  Width: 374 px\n",
      "  Height: 162 px\n",
      "  Frames: 1708821\n",
      "  Frame Rate: 480.0 fps\n",
      "  Duration: 3560.04375 seconds\n",
      "\n",
      "Video 2:\n",
      "  Path: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4\n",
      "  Width: 516 px\n",
      "  Height: 200 px\n",
      "  Frames: 1708821\n",
      "  Frame Rate: 480.0 fps\n",
      "  Duration: 3560.04375 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_right.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:59:20.04, start: 0.000000, bitrate: 4192 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 374x162 [SAR 1:1 DAR 187:81], 4176 kb/s, 480 fps, 480 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:59:20.04, start: 0.000000, bitrate: 5456 kb/s\n",
      "  Stream #1:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 516x200 [SAR 1:1 DAR 129:50], 5439 kb/s, 480 fps, 480 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 (mpeg4) -> pad:default\n",
      "  Stream #1:0 (mpeg4) -> pad:default\n",
      "  vstack:default -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x14c012cd0] using SAR=1/1\n",
      "[libx264 @ 0x14c012cd0] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x14c012cd0] profile High, level 4.2, 4:2:0, 8-bit\n",
      "[libx264 @ 0x14c012cd0] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=1 deblock=1:0:0 analyse=0x3:0x3 me=dia subme=1 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc=crf mbtree=0 crf=10.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 pb_ratio=1.30 aq=1:1.00\n",
      "Output #0, mp4, to '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/stacked_whiskers.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 516x372 [SAR 1:1 DAR 43:31], q=2-31, 480 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=1708078 fps=2478 q=11.0 size= 9411584kB time=00:59:18.49 bitrate=21666.4kbits/s speed=5.16x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stacking completed successfully. Output saved at /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/stacked_whiskers.mp4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x14c011b60] video:9415072kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.213981%\n",
      "frame=1708821 fps=2478 q=-1.0 Lsize= 9435219kB time=00:59:20.03 bitrate=21711.4kbits/s speed=5.16x    \n",
      "[libx264 @ 0x14c012cd0] frame I:6836  Avg QP: 3.09  size: 16312\n",
      "[libx264 @ 0x14c012cd0] frame P:441984 Avg QP: 7.27  size:  9897\n",
      "[libx264 @ 0x14c012cd0] frame B:1260001 Avg QP:11.15  size:  4091\n",
      "[libx264 @ 0x14c012cd0] consecutive B-frames:  1.0%  1.5%  1.3% 96.2%\n",
      "[libx264 @ 0x14c012cd0] mb I  I16..4: 56.1% 14.7% 29.2%\n",
      "[libx264 @ 0x14c012cd0] mb P  I16..4:  4.8%  3.2%  4.1%  P16..4: 30.0%  0.0%  0.0%  0.0%  0.0%    skip:58.0%\n",
      "[libx264 @ 0x14c012cd0] mb B  I16..4:  0.3%  0.2%  0.2%  B16..8: 22.9%  0.0%  0.0%  direct: 8.8%  skip:67.7%  L0:38.0% L1:39.1% BI:23.0%\n",
      "[libx264 @ 0x14c012cd0] 8x8 transform intra:25.5% inter:15.3%\n",
      "[libx264 @ 0x14c012cd0] coded y,uvDC,uvAC intra: 56.0% 27.6% 21.6% inter: 18.0% 3.6% 0.7%\n",
      "[libx264 @ 0x14c012cd0] i16 v,h,dc,p: 73% 17%  9%  1%\n",
      "[libx264 @ 0x14c012cd0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 20% 33%  3%  8%  4%  4%  5%  4%\n",
      "[libx264 @ 0x14c012cd0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 11% 18%  3%  8%  9%  3%  8%  3%\n",
      "[libx264 @ 0x14c012cd0] i8c dc,h,v,p: 72% 12% 13%  3%\n",
      "[libx264 @ 0x14c012cd0] Weighted P-Frames: Y:3.8% UV:0.0%\n",
      "[libx264 @ 0x14c012cd0] kb/s:21664.98\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import ffmpeg\n",
    "\n",
    "def collect_video_metadata(video_paths):\n",
    "    \"\"\"\n",
    "    Collects metadata for a list of videos.\n",
    "\n",
    "    :param video_paths: List of paths to video files.\n",
    "    :return: List of metadata dictionaries.\n",
    "    \"\"\"\n",
    "    metadata = []\n",
    "    for video in video_paths:\n",
    "        probe = ffmpeg.probe(video)\n",
    "        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "        video_meta = {\n",
    "            \"path\": video,\n",
    "            \"width\": video_stream['width'],\n",
    "            \"height\": video_stream['height'],\n",
    "            \"frames\": int(video_stream['nb_frames']),\n",
    "            \"frame_rate\": eval(video_stream['r_frame_rate']),\n",
    "            \"duration\": float(probe['format']['duration'])\n",
    "        }\n",
    "        metadata.append(video_meta)\n",
    "    return metadata\n",
    "\n",
    "def print_video_metadata(metadata):\n",
    "    \"\"\"\n",
    "    Prints video metadata.\n",
    "\n",
    "    :param metadata: List of metadata dictionaries.\n",
    "    \"\"\"\n",
    "    print(\"Video Metadata:\")\n",
    "    for i, meta in enumerate(metadata):\n",
    "        print(f\"Video {i+1}:\")\n",
    "        print(f\"  Path: {meta['path']}\")\n",
    "        print(f\"  Width: {meta['width']} px\")\n",
    "        print(f\"  Height: {meta['height']} px\")\n",
    "        print(f\"  Frames: {meta['frames']}\")\n",
    "        print(f\"  Frame Rate: {meta['frame_rate']} fps\")\n",
    "        print(f\"  Duration: {meta['duration']} seconds\\n\")\n",
    "\n",
    "def stack_videos_with_ffmpeg(video_paths, output_path, padding=10):\n",
    "    \"\"\"\n",
    "    Stacks videos vertically with padding between them using FFmpeg.\n",
    "\n",
    "    :param video_paths: List of paths to video files.\n",
    "    :param output_path: Path to save the stacked video.\n",
    "    :param padding: Padding size in pixels.\n",
    "    \"\"\"\n",
    "    metadata = collect_video_metadata(video_paths)\n",
    "    print_video_metadata(metadata)\n",
    "\n",
    "    # Check for frame count and frame rate mismatches\n",
    "    frames = {meta['frames'] for meta in metadata}\n",
    "    frame_rates = {meta['frame_rate'] for meta in metadata}\n",
    "\n",
    "    if len(frames) > 1 or len(frame_rates) > 1:\n",
    "        print(\"Frame count or frame rate mismatch detected:\")\n",
    "        for i, meta in enumerate(metadata):\n",
    "            print(f\"Video {i+1}: {meta['frames']} frames, {meta['frame_rate']} fps, {meta['duration']} seconds\")\n",
    "        raise ValueError(\"All videos must have the same frame count and frame rate to stack.\")\n",
    "\n",
    "    # Prepare the filter_complex string\n",
    "    filter_complex_parts = []\n",
    "    max_width = max(meta['width'] for meta in metadata)\n",
    "    for i, meta in enumerate(metadata):\n",
    "        pad_filter = f\"[{i}:v]pad=width={max_width}:height=ih+{padding if i < len(video_paths) - 1 else 0}:x={(max_width - meta['width']) // 2}:y=0:color=black[v{i}]\"\n",
    "        filter_complex_parts.append(pad_filter)\n",
    "    stacked_filter = \"\".join(f\"[v{i}]\" for i in range(len(video_paths))) + f\"vstack=inputs={len(video_paths)}[v]\"\n",
    "    filter_complex_parts.append(stacked_filter)\n",
    "\n",
    "    # Build FFmpeg command\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        *[item for video in video_paths for item in (\"-i\", video)],\n",
    "        \"-filter_complex\", \";\".join(filter_complex_parts),\n",
    "        \"-map\", \"[v]\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-crf\", \"10\",\n",
    "        \"-preset\", \"superfast\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Run FFmpeg\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, check=True)\n",
    "        print(f\"Video stacking completed successfully. Output saved at {output_path}.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during FFmpeg execution: {e}\")\n",
    "\n",
    "# Example usage\n",
    "video1_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_right.mp4\"  # Replace with the path to your first video\n",
    "video2_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4\"  # Replace with the path to your second video\n",
    "stacked_output_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/stacked_whiskers.mp4\"\n",
    "\n",
    "video_paths = [video1_path, video2_path]  # Replace with your video paths\n",
    "stacked_output_path = stacked_output_path\n",
    "\n",
    "try:\n",
    "    stack_videos_with_ffmpeg(video_paths, stacked_output_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_videos_vertically(video1_path, video2_path, output_path):\n",
    "    \"\"\"\n",
    "    Stacks two videos vertically. If their widths don't match, adds padding to ensure equal widths.\n",
    "\n",
    "    :param video1_path: Path to the first video.\n",
    "    :param video2_path: Path to the second video.\n",
    "    :param output_path: Path to save the stacked video.\n",
    "    \"\"\"\n",
    "    # Open the video files\n",
    "    video1 = cv2.VideoCapture(video1_path)\n",
    "    video2 = cv2.VideoCapture(video2_path)\n",
    "\n",
    "    if not video1.isOpened() or not video2.isOpened():\n",
    "        raise FileNotFoundError(\"Could not open one or both video files.\")\n",
    "\n",
    "    # Get properties of the videos\n",
    "    fps = int(video1.get(cv2.CAP_PROP_FPS))\n",
    "    width1 = int(video1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height1 = int(video1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width2 = int(video2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height2 = int(video2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate the new width (maximum of both widths)\n",
    "    new_width = max(width1, width2)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    output_size = (new_width, height1 + height2)\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, output_size)\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = video1.read()\n",
    "        ret2, frame2 = video2.read()\n",
    "\n",
    "        if not ret1 and not ret2:\n",
    "            break\n",
    "\n",
    "        # Add padding to make the widths equal\n",
    "        if ret1:\n",
    "            pad1 = new_width - width1\n",
    "            frame1 = cv2.copyMakeBorder(frame1, 0, 0, 0, pad1, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        else:\n",
    "            frame1 = np.zeros((height1, new_width, 3), dtype=np.uint8)\n",
    "\n",
    "        if ret2:\n",
    "            pad2 = new_width - width2\n",
    "            frame2 = cv2.copyMakeBorder(frame2, 0, 0, 0, pad2, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        else:\n",
    "            frame2 = np.zeros((height2, new_width, 3), dtype=np.uint8)\n",
    "\n",
    "        # Stack the frames vertically\n",
    "        stacked_frame = np.vstack((frame1, frame2))\n",
    "\n",
    "        # Write the stacked frame to the output video\n",
    "        out.write(stacked_frame)\n",
    "\n",
    "    # Release resources\n",
    "    video1.release()\n",
    "    video2.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Stacked video saved to {output_path}\")\n",
    "\n",
    "# Example usage for stacking videos\n",
    "video1_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_right.mp4\"  # Replace with the path to your first video\n",
    "video2_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/whiskers_bottom_left.mp4\"  # Replace with the path to your second video\n",
    "stacked_output_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/whiskers/stacked_whiskers.mp4\"\n",
    "\n",
    "try:\n",
    "    stack_videos_vertically(video1_path, video2_path, stacked_output_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculates the bounding box coordinates of a set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box Coordinates:\n",
      "Top-left corner: (267, 81)\n",
      "Bottom-right corner: (515, 406)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code snippet calculates the bounding box coordinates of a set of points in a list. \n",
    "The minimum and maximum x and y coordinates are found, and the top-left and bottom-right corners of the bounding box are displayed.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Example list of points (more can be added)\n",
    "points = coords\n",
    "\n",
    "# Convert the list of points to a numpy array for easier processing\n",
    "points_array = np.array(points)\n",
    "\n",
    "# Find the minimum and maximum x and y coordinates\n",
    "min_x, min_y = points_array.min(axis=0) # Top-left corner\n",
    "max_x, max_y = points_array.max(axis=0) # Bottom-right corner\n",
    "\n",
    "# Calculate the bounding box\n",
    "bounding_box = ((min_x, min_y), (max_x, max_y))\n",
    "\n",
    "print(\"Bounding Box Coordinates:\")\n",
    "print(f\"Top-left corner: ({min_x}, {min_y})\")\n",
    "print(f\"Bottom-right corner: ({max_x}, {max_y})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask the area outside the bounding box black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bounding_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m img_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)  \u001b[38;5;66;03m# Convert image to NumPy array for masking\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define the bounding box coordinates (example coordinates)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Replace these values with your actual bounding box coordinates\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# x_min, y_min = 150, 200 # Top-left corner\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# x_max, y_max = 717, 245 # Bottom-right corner\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x_min, y_min \u001b[38;5;241m=\u001b[39m \u001b[43mbounding_box\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Top-left corner\u001b[39;00m\n\u001b[1;32m     16\u001b[0m x_max, y_max \u001b[38;5;241m=\u001b[39m bounding_box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Bottom-right corner\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a mask: set the area outside the bounding box to black\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bounding_box' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"This code snippet demonstrates how to mask an image using a bounding box. The area outside the bounding box is set to black, \n",
    "and the masked image is displayed.\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('frame.png')\n",
    "img_np = np.array(img)  # Convert image to NumPy array for masking\n",
    "\n",
    "# Define the bounding box coordinates (example coordinates)\n",
    "# Replace these values with your actual bounding box coordinates\n",
    "# x_min, y_min = 150, 200 # Top-left corner\n",
    "# x_max, y_max = 717, 245 # Bottom-right corner\n",
    "x_min, y_min = bounding_box[0] # Top-left corner\n",
    "x_max, y_max = bounding_box[1] # Bottom-right corner\n",
    "\n",
    "# Create a mask: set the area outside the bounding box to black\n",
    "masked_img = img_np.copy()\n",
    "masked_img[:y_min, :] = 0  # Top area\n",
    "masked_img[y_max:, :] = 0  # Bottom area\n",
    "masked_img[:, :x_min] = 0  # Left area\n",
    "masked_img[:, x_max:] = 0  # Right area\n",
    "\n",
    "# Display the masked image\n",
    "plt.imshow(masked_img)\n",
    "plt.axis('off')  # Hide axes for cleaner display\n",
    "plt.show()\n",
    "\n",
    "# Optionally, save the masked image\n",
    "Image.fromarray(masked_img).save('masked_frame.png')\n",
    "\n",
    "# print(x_min, y_min, x_max, y_max)\n",
    "print(bounding_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = ((267, 81), (515, 406))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comments on high quality code for high-quality output\n",
    "\n",
    "command = [\n",
    "\n",
    "\"ffmpeg\", \"-i\", input_video_path,\n",
    "\n",
    "\"-vf\", crop_filter,\n",
    "\n",
    "\"-c:v\", \"libx264\",       # High-quality H.264 codec\n",
    "\n",
    "\"-preset\", \"veryslow\",   # Best compression quality\n",
    "\n",
    "\"-crf\", \"18\",            # High-quality constant rate factor\n",
    "\n",
    "\"-c:a\", \"aac\",           # High-quality audio codec\n",
    "\n",
    "\"-b:a\", \"320k\",          # High-quality audio bitrate\n",
    "\n",
    "output_video_path\n",
    "\n",
    "]\n",
    "\n",
    "Set -crf to a low value (e.g., 18 or 0 for lossless).\n",
    "\n",
    "Use -preset veryslow for better compression and quality.\n",
    "\n",
    "Ensure -c:v libx264 or -c:v libx265 for efficient codecs.\n",
    "\n",
    "Include high-quality audio with -c:a aac -b:a 320k.\n",
    "\n",
    "#### Trade-Offs\n",
    "\n",
    "File Size: Higher quality produces larger files.\n",
    "\n",
    "Processing Time: Slower presets (veryslow) take significantly longer to encode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crops a video to a specified bounding box and saves the cropped output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Metadata:\n",
      "  Path: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi\n",
      "  Width: 720 px\n",
      "  Height: 540 px\n",
      "  Frames: 1708821\n",
      "  Frame Rate: 480.0 fps\n",
      "  Duration: 3560.04375 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, avi, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf60.12.100\n",
      "  Duration: 00:59:20.04, start: 0.000000, bitrate: 50419 kb/s\n",
      "  Stream #0:0: Video: h264 (High 4:4:4 Predictive) (H264 / 0x34363248), gbrp(pc, gbr/unknown/unknown, progressive), 720x540 [SAR 1:1 DAR 4:3], 50353 kb/s, 480 fps, 480 tbr, 480 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x130105060] using SAR=1/1\n",
      "[libx264 @ 0x130105060] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x130105060] profile High 4:4:4 Predictive, level 3.2, 4:4:4, 8-bit\n",
      "[libx264 @ 0x130105060] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=0 ref=1 deblock=0:0:0 analyse=0:0 me=dia subme=0 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=6 threads=10 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=0 weightp=0 keyint=250 keyint_min=25 scenecut=0 intra_refresh=0 rc=crf mbtree=0 crf=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=0\n",
      "Output #0, mp4, to '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/tongue_bottom.mp4':\n",
      "  Metadata:\n",
      "    software        : Lavf60.12.100\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 248x325 [SAR 1:1 DAR 248:325], q=2-31, 480 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[vost#0:0/libx264 @ 0x130104cf0] Error submitting a packet to the muxer: No space left on device\n",
      "[out#0/mp4 @ 0x13010d860] Error muxing a packet\n",
      "[out#0/mp4 @ 0x13010d860] Error writing trailer: No space left on device\n",
      "[out#0/mp4 @ 0x13010d860] Error closing file: No space left on device\n",
      "[out#0/mp4 @ 0x13010d860] video:3844kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "frame=   87 fps=0.0 q=-1.0 Lsize=    3584kB time=00:00:00.22 bitrate=131710.5kbits/s speed=1.93x    \n",
      "[libx264 @ 0x130105060] frame I:1     Avg QP: 0.00  size:108590\n",
      "[libx264 @ 0x130105060] frame P:106   Avg QP: 7.88  size: 44776\n",
      "[libx264 @ 0x130105060] mb I  I16..4: 100.0%  0.0%  0.0%\n",
      "[libx264 @ 0x130105060] mb P  I16..4:  1.1%  0.0%  0.0%  P16..4: 97.6%  0.0%  0.0%  0.0%  0.0%    skip: 1.3%\n",
      "[libx264 @ 0x130105060] coded y,u,v intra: 95.4% 83.5% 85.3% inter: 96.1% 72.4% 78.2%\n",
      "[libx264 @ 0x130105060] i16 v,h,dc,p: 42% 13% 27% 18%\n",
      "[libx264 @ 0x130105060] kb/s:174229.80\n",
      "Conversion failed!\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-i', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi', '-vf', 'crop=248:325:267:81', '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '1', '-an', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/tongue_bottom.mp4']' returned non-zero exit status 228.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# bounding_box = ((282, 140), (381, 200))  # Example bounding box\u001b[39;00m\n\u001b[1;32m     88\u001b[0m bounding_box \u001b[38;5;241m=\u001b[39m bounding_box\n\u001b[0;32m---> 89\u001b[0m \u001b[43mcrop_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 81\u001b[0m, in \u001b[0;36mcrop_video\u001b[0;34m(input_video_path, output_video_path, bounding_box)\u001b[0m\n\u001b[1;32m     49\u001b[0m command \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_video_path,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-vf\u001b[39m\u001b[38;5;124m\"\u001b[39m, crop_filter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     output_video_path\n\u001b[1;32m     57\u001b[0m ]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# high quality code for high-quality output\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# command = [\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# \"ffmpeg\", \"-i\", input_video_path,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCropped video saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/video-analysis-env/lib/python3.8/subprocess.py:516\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 516\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    517\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-i', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi', '-vf', 'crop=248:325:267:81', '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '1', '-an', '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/tongue_bottom.mp4']' returned non-zero exit status 228."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def crop_video(input_video_path, output_video_path, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a video to a specified bounding box and saves the output.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_video_path (str): Path to the input video.\n",
    "    - output_video_path (str): Path to save the cropped video.\n",
    "    - bounding_box (tuple): ((x1, y1), (x2, y2)) representing the top-left and bottom-right corners.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect video metadata to validate compatibility\n",
    "    probe = ffmpeg.probe(input_video_path)\n",
    "    video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "    video_meta = {\n",
    "        \"path\": input_video_path,\n",
    "        \"width\": video_stream['width'],\n",
    "        \"height\": video_stream['height'],\n",
    "        \"frames\": int(video_stream['nb_frames']),\n",
    "        \"frame_rate\": eval(video_stream['r_frame_rate']),\n",
    "        \"duration\": float(probe['format']['duration'])\n",
    "    }\n",
    "\n",
    "    # Print metadata\n",
    "    print(\"Video Metadata:\")\n",
    "    print(f\"  Path: {video_meta['path']}\")\n",
    "    print(f\"  Width: {video_meta['width']} px\")\n",
    "    print(f\"  Height: {video_meta['height']} px\")\n",
    "    print(f\"  Frames: {video_meta['frames']}\")\n",
    "    print(f\"  Frame Rate: {video_meta['frame_rate']} fps\")\n",
    "    print(f\"  Duration: {video_meta['duration']} seconds\\n\")\n",
    "\n",
    "\n",
    "    # Extract bounding box coordinates\n",
    "    (x1, y1), (x2, y2) = bounding_box\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_video_path), exist_ok=True)\n",
    "\n",
    "    # FFmpeg crop filter: crop=w: h: x: y\n",
    "    crop_filter = f\"crop={width}:{height}:{x1}:{y1}\"\n",
    "    \n",
    "    # FFmpeg command\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", input_video_path,\n",
    "        \"-vf\", crop_filter,\n",
    "        \"-c:v\", \"libx264\",  # Video codec\n",
    "        \"-preset\", \"ultrafast\",  # Encoding speed. Options: ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow. The -preset option controls encoding speed and compression efficiency. Slower presets result in better compression (smaller file size for the same quality). The default is medium.\n",
    "        \"-crf\", \"1\",       # Quality (lower is better, 23 is default). Use a CRF value between 0 (lossless) and 18 (visually lossless). CRF controls the quality of the output video. f you want perfect quality and don't care about file size, set -crf 0\n",
    "        \"-an\",              # Remove audio\n",
    "        output_video_path\n",
    "    ]\n",
    "\n",
    "    # high quality code for high-quality output\n",
    "    # command = [\n",
    "    # \"ffmpeg\", \"-i\", input_video_path,\n",
    "    # \"-vf\", crop_filter,\n",
    "    # \"-c:v\", \"libx264\",       # High-quality H.264 codec\n",
    "    # \"-preset\", \"veryslow\",   # Best compression quality\n",
    "    # \"-crf\", \"18\",            # High-quality constant rate factor\n",
    "    # \"-c:a\", \"aac\",           # High-quality audio codec\n",
    "    # \"-b:a\", \"320k\",          # High-quality audio bitrate\n",
    "    # output_video_path\n",
    "    # ]\n",
    "\n",
    "    # Set -crf to a low value (e.g., 18 or 0 for lossless).\n",
    "    # Use -preset veryslow for better compression and quality.\n",
    "    # Ensure -c:v libx264 or -c:v libx265 for efficient codecs.\n",
    "    # Include high-quality audio with -c:a aac -b:a 320k.\n",
    "    # Trade-Offs\n",
    "    # File Size: Higher quality produces larger files.\n",
    "    # Processing Time: Slower presets (veryslow) take significantly longer to encode.\n",
    "\n",
    "\n",
    "    # Run the command\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"Cropped video saved to {output_video_path}\")\n",
    "\n",
    "# Example Usage\n",
    "input_video_path = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/bottom_camera.avi'\n",
    "output_video_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/tongue_bottom.mp4\"\n",
    "# bounding_box = ((282, 140), (381, 200))  # Example bounding box\n",
    "bounding_box = bounding_box\n",
    "crop_video(input_video_path, output_video_path, bounding_box)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacks multiple videos side by side and saves the output to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def rotate_video(input_path, output_path):\n",
    "    \"\"\"Rotates a video 90 degrees clockwise.\"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"ffmpeg\", \"-i\", input_path, \"-vf\", \"transpose=1\", \"-c:a\", \"copy\", output_path],\n",
    "            check=True\n",
    "        )\n",
    "        print(f\"Rotated video saved at: {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error rotating video: {e}\")\n",
    "\n",
    "# Example usage\n",
    "input_path  = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/bottom_tongue.mp4 -vf transpose=1 -c:a copy output_video.mp4\"\n",
    "rotated_video_path = \"/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/bottom_tongue_rotated.mp4\"\n",
    "rotate_video(input_path, rotated_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Metadata:\n",
      "Video 1:\n",
      "  Path: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/right_eye_slower.mp4\n",
      "  Width: 104 px\n",
      "  Height: 76 px\n",
      "  Frames: 1708822\n",
      "  Frame Rate: 480.0 fps\n",
      "  Duration: 3560.045833 seconds\n",
      "\n",
      "Video 2:\n",
      "  Path: /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/left_eye.mp4\n",
      "  Width: 99 px\n",
      "  Height: 60 px\n",
      "  Frames: 1708822\n",
      "  Frame Rate: 480.0 fps\n",
      "  Duration: 3560.045833 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with clang version 16.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1699729534217/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/right_eye_slower.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:59:20.05, start: 0.002018, bitrate: 6795 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p(progressive), 104x76 [SAR 1:1 DAR 26:19], 6758 kb/s, 480 fps, 480 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/left_eye.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:59:20.05, start: 0.002018, bitrate: 13132 kb/s\n",
      "  Stream #1:0[0x1](und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p(progressive), 99x60 [SAR 1:1 DAR 33:20], 13116 kb/s, 480 fps, 480 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> pad:default\n",
      "  Stream #1:0 (h264) -> pad:default\n",
      "  hstack:default -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x136693c90] using SAR=1/1\n",
      "[libx264 @ 0x136693c90] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x136693c90] profile High 4:4:4 Predictive, level 3.0, 4:4:4, 8-bit\n",
      "[libx264 @ 0x136693c90] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=2 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=10.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/stacked_eye_output_with_padding.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(progressive), 210x76 [SAR 1:1 DAR 105:38], q=2-31, 480 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=1708532 fps= 28 q=20.0 size= 1552384kB time=00:59:19.43 bitrate=3572.8kbits/s speed=0.0578x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stacking completed successfully. Output saved at /Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/stacked_eye_output_with_padding.mp4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x136692b30] video:1552630kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.062278%\n",
      "frame=1708822 fps= 28 q=-1.0 Lsize= 1569124kB time=00:59:20.03 bitrate=3610.7kbits/s speed=0.0578x    \n",
      "[libx264 @ 0x136693c90] frame I:6836  Avg QP:12.03  size:  8647\n",
      "[libx264 @ 0x136693c90] frame P:867249 Avg QP:14.95  size:  1629\n",
      "[libx264 @ 0x136693c90] frame B:834737 Avg QP:21.54  size:   141\n",
      "[libx264 @ 0x136693c90] consecutive B-frames: 30.0% 10.3% 13.0% 46.7%\n",
      "[libx264 @ 0x136693c90] mb I  I16..4:  0.6% 15.8% 83.6%\n",
      "[libx264 @ 0x136693c90] mb P  I16..4:  0.0%  0.1%  0.8%  P16..4: 54.5% 15.8% 15.4%  0.0%  0.0%    skip:13.5%\n",
      "[libx264 @ 0x136693c90] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 28.4%  4.6%  2.0%  direct: 5.4%  skip:59.5%  L0:38.8% L1:50.1% BI:11.1%\n",
      "[libx264 @ 0x136693c90] 8x8 transform intra:11.0% inter:9.8%\n",
      "[libx264 @ 0x136693c90] direct mvs  spatial:100.0% temporal:0.0%\n",
      "[libx264 @ 0x136693c90] coded y,u,v intra: 69.5% 50.9% 57.4% inter: 31.0% 5.9% 11.6%\n",
      "[libx264 @ 0x136693c90] i16 v,h,dc,p:  1% 82% 11%  6%\n",
      "[libx264 @ 0x136693c90] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  5% 18% 32%  3%  8%  4%  7%  5% 18%\n",
      "[libx264 @ 0x136693c90] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 42% 15%  4%  6%  4%  6%  4%  9%\n",
      "[libx264 @ 0x136693c90] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x136693c90] ref P L0: 82.0%  4.7%  9.4%  2.1%  1.4%  0.4%  0.0%\n",
      "[libx264 @ 0x136693c90] ref B L0: 84.1% 12.7%  2.7%  0.5%\n",
      "[libx264 @ 0x136693c90] ref B L1: 95.0%  5.0%\n",
      "[libx264 @ 0x136693c90] kb/s:3572.75\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import ffmpeg\n",
    "\n",
    "def stack_videos_with_padding(video_paths, output_path, padding=10):\n",
    "    \"\"\"\n",
    "    Stacks videos side by side with padding, ensuring equal heights with additional black space.\n",
    "\n",
    "    Args:\n",
    "        video_paths (list): List of input video file paths.\n",
    "        output_path (str): Path to save the stacked video.\n",
    "        padding (int): Width of the padding (in pixels) between videos.\n",
    "    \"\"\"\n",
    "    if len(video_paths) < 2:\n",
    "        raise ValueError(\"You need at least two videos to stack them side by side.\")\n",
    "\n",
    "    # Collect video metadata to validate compatibility\n",
    "    metadata = []\n",
    "    for video in video_paths:\n",
    "        probe = ffmpeg.probe(video)\n",
    "        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "        video_meta = {\n",
    "            \"path\": video,\n",
    "            \"width\": video_stream['width'],\n",
    "            \"height\": video_stream['height'],\n",
    "            \"frames\": int(video_stream['nb_frames']),\n",
    "            \"frame_rate\": eval(video_stream['r_frame_rate']),\n",
    "            \"duration\": float(probe['format']['duration'])\n",
    "        }\n",
    "        metadata.append(video_meta)\n",
    "\n",
    "    # Print metadata\n",
    "    print(\"Video Metadata:\")\n",
    "    for i, meta in enumerate(metadata):\n",
    "        print(f\"Video {i+1}:\")\n",
    "        print(f\"  Path: {meta['path']}\")\n",
    "        print(f\"  Width: {meta['width']} px\")\n",
    "        print(f\"  Height: {meta['height']} px\")\n",
    "        print(f\"  Frames: {meta['frames']}\")\n",
    "        print(f\"  Frame Rate: {meta['frame_rate']} fps\")\n",
    "        print(f\"  Duration: {meta['duration']} seconds\\n\")\n",
    "\n",
    "    # Check for frame count and frame rate mismatches\n",
    "    frames = {meta['frames'] for meta in metadata}\n",
    "    frame_rates = {meta['frame_rate'] for meta in metadata}\n",
    "\n",
    "    if len(frames) > 1 or len(frame_rates) > 1:\n",
    "        print(\"Frame count or frame rate mismatch detected:\")\n",
    "        for i, meta in enumerate(metadata):\n",
    "            print(f\"Video {i+1}: {meta['frames']} frames, {meta['frame_rate']} fps, {meta['duration']} seconds\")\n",
    "        raise ValueError(\"All videos must have the same frame count and frame rate to stack.\")\n",
    "\n",
    "    # Prepare the filter_complex string\n",
    "    filter_complex_parts = []\n",
    "    max_height = max(meta['height'] for meta in metadata)\n",
    "    for i, meta in enumerate(metadata):\n",
    "        pad_filter = f\"[{i}:v]pad=width=iw+{padding if i < len(video_paths) - 1 else 0}:height={max_height}:x=0:y={(max_height - meta['height']) // 2}:color=black[v{i}]\"\n",
    "        filter_complex_parts.append(pad_filter)\n",
    "    stacked_filter = \"\".join(f\"[v{i}]\" for i in range(len(video_paths))) + f\"hstack=inputs={len(video_paths)}[v]\"\n",
    "    filter_complex_parts.append(stacked_filter)\n",
    "\n",
    "    # Build FFmpeg command\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        *[item for video in video_paths for item in (\"-i\", video)],\n",
    "        \"-filter_complex\", \";\".join(filter_complex_parts),\n",
    "        \"-map\", \"[v]\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-crf\", \"10\",\n",
    "        \"-preset\", \"slow\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Run FFmpeg\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, check=True)\n",
    "        print(f\"Video stacking completed successfully. Output saved at {output_path}.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during FFmpeg execution: {e}\")\n",
    "\n",
    "# Example usage\n",
    "video_paths = [\n",
    "    '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/right_tongue.mp4',\n",
    "    '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/bottom_tongue.mp4',\n",
    "    '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/tongue/left_tongue.mp4'\n",
    "]\n",
    "output_path = '/Users/faeze.aminmansoor/Documents/Allen/Xinxin_raw_data/706893_2024-05-28_15-15-38/eyes/stacked_eye_output_with_padding.mp4'\n",
    "\n",
    "stack_videos_with_padding(video_paths, output_path, padding=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is an alternative code for click detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def on_click(event):\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        print(f\"Clicked at ({event.xdata}, {event.ydata})\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: tk. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mclick_event\u001b[0;34m(event, x, y, flags, param)\u001b[0m\n\u001b[1;32m      3\u001b[0m coords \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the click event\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick_event\u001b[39m(event, x, y, flags, param):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_LBUTTONDOWN:\n\u001b[1;32m      8\u001b[0m         coords\u001b[38;5;241m.\u001b[39mappend((x, y))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "coords = []\n",
    "\n",
    "# Define the click event\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        coords.append((x, y))\n",
    "        print(f\"Point added at ({x}, {y})\")\n",
    "        cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('frame.png')\n",
    "\n",
    "# Display the image and set the mouse callback\n",
    "cv2.imshow('image', img)\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "# Wait until a key is pressed\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Coordinates of clicked points:\", coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frame timestamps of original and downsized video using frame_metadata.json metadata file\n",
    "\n",
    "\n",
    "### In Brief: \n",
    "\n",
    "ffprobe -i /home/faeze.aminmansoor/video-analysis/videos/706893_2024-05-28_15-15-38/nose/stacked_nose.mp4 -show_frames -select_streams v:0 -print_format json > /home/faeze.aminmansoor/video-analysis/videos/706893_2024-05-28_15-15-38/nose/frame_meta_data.json\n",
    "\n",
    "head -n 50 /home/faeze.aminmansoor/video-analysis/videos/706893_2024-05-28_15-15-38/nose/frame_meta_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# frame_meta_data_path = '/home/faeze.aminmansoor/video-analysis/videos/706893_2024-05-28_15-15-38/nose/frame_meta_data.json'\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"frame_metadata.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract frame information\n",
    "frames = data[\"frames\"]\n",
    "timestamps = []\n",
    "\n",
    "for frame in frames:\n",
    "    timestamps.append({\n",
    "        \"Frame_ID\": frame[\"coded_picture_number\"],\n",
    "        \"Timestamp(s)\": float(frame[\"pts_time\"]),  # Convert to float for calculations\n",
    "        \"Duration\": float(frame.get(\"pkt_duration_time\", 0))  # Handle missing values\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_48 = pd.DataFrame(timestamps)\n",
    "\n",
    "# Adjust the 'Timestamp(s)' column to start from 0\n",
    "df_48[\"Timestamp(s)\"] -= df_48[\"Timestamp(s)\"].iloc[0]\n",
    "\n",
    "# Save to CSV\n",
    "df_48.to_csv(\"frame_timestamps.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(df_48.head(10))\n",
    "print(df_48.tail(10))\n",
    "\n",
    "df_48.to_csv('df_48.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ffprobe -i segment_000.mp4 -show_frames -select_streams v:0 -print_format json > frame_metadata.json\n",
    "\n",
    "our MP4 file contains video metadata, and from this ffprobe output, we can extract useful details\n",
    "\n",
    "This should have saved per-frame metadata in frame_metadata.json.\n",
    "\n",
    "### head -n 50 frame_metadata.json\n",
    "\n",
    "Your frame_metadata.json file contains per-frame timestamps extracted by FFmpeg. Here are the relevant fields:\n",
    "\n",
    "Field\t                        Description\n",
    "\"pts_time\" (pkt_pts_time)\t    Frame presentation timestamp in seconds\n",
    "\"pkt_dts_time\" (pkt_dts)\t    Decoding timestamp (useful for reordering)\n",
    "\"pkt_duration_time\"\t            Frame duration in seconds\n",
    "\"coded_picture_number\"\t        Frame index (zero-based)\n",
    "\n",
    "\n",
    "If the file (frame_metadata.json) is empty or doesn't contain pkt_pts_time, try this modified command:\n",
    "### ffprobe -i segment_000.mp4 -show_entries frame=pkt_pts_time -of json > frame_timestamps.json\n",
    "\n",
    "### Extract Frame Timestamps to CSV\n",
    "To extract and save the frame timestamps into a structured format, use this Python script:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"frame_metadata.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract frame timestamps\n",
    "frames = data[\"frames\"]\n",
    "timestamps = []\n",
    "\n",
    "for frame in frames:\n",
    "    timestamps.append({\n",
    "        \"Frame_ID\": frame[\"coded_picture_number\"],\n",
    "        \"Timestamp\": float(frame[\"pts_time\"]),  # Convert to float for calculations\n",
    "        \"Duration\": float(frame.get(\"pkt_duration_time\", 0))  # Handle missing values\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(timestamps)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"frame_timestamps.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "### Expected Output (frame_timestamps.csv)\n",
    "Frame_ID\tTimestamp (s)\tDuration (s)\n",
    "0\t0.003971\t0.002083\n",
    "1\t0.006055\t0.002083\n",
    "2\t0.008139\t0.002083\n",
    "3\t0.010223\t0.002083\n",
    "\n",
    "\n",
    "1. Presentation Timestamp (PTS):\n",
    "\n",
    "The PTS indicates the exact moment a frame should be displayed during playback. It's crucial for synchronizing audio and video streams, ensuring that each frame appears at the intended time. For example, a PTS of 5.0 seconds means the frame should be shown precisely at the 5-second mark during playback. \n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "2. Decoding Timestamp (DTS):\n",
    "\n",
    "The DTS specifies when a frame should be decoded. This is particularly important for frames that rely on data from other frames, such as B-frames, which reference both previous and subsequent frames. Proper decoding order ensures that frames are ready for presentation at their designated PTS. \n",
    "ELECARD.COM\n",
    "\n",
    "3. Frame Duration:\n",
    "\n",
    "Frame duration denotes the length of time a frame is displayed. It's typically the inverse of the frame rate. For instance, at a frame rate of 25 frames per second (fps), each frame has a duration of 0.04 seconds (1/25). This metric ensures smooth motion by maintaining consistent timing between frames. \n",
    "STACKOVERFLOW.COM\n",
    "\n",
    "4. Frame Type:\n",
    "\n",
    "Frames in compressed video are categorized based on their compression method:\n",
    "\n",
    "I-Frames (Intra-coded): Self-contained frames that don't reference other frames.\n",
    "\n",
    "P-Frames (Predicted): Frames that reference preceding frames to save space.\n",
    "\n",
    "B-Frames (Bidirectional): Frames that reference both preceding and following frames for higher compression efficiency.\n",
    "\n",
    "Understanding frame types is essential for efficient video compression and decompression processes. \n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "5. Frame Size:\n",
    "\n",
    "Frame size refers to the amount of data a frame occupies, typically measured in bytes. Factors influencing frame size include resolution, compression level, and frame complexity. Higher resolution and more detailed frames generally result in larger frame sizes.\n",
    "\n",
    "These metadata elements are integral to video encoding and playback, ensuring that frames are decoded and presented in the correct sequence and at the appropriate times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
