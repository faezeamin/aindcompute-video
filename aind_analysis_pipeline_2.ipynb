{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af67dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5881bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: {'analysis_spec.analysis_name': 'MLE fitting', 'analysis_spec.analysis_ver': 'first version @ 0.10.0', 'subject_id': '706893', 'session_date': '2024-05-28'}\n",
      "Found 30 MLE fitting records!\n",
      "Found 30 successful MLE fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get latent variables from s3: 100%|██████████| 30/30 [00:01<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'nwb_name', 'session_date', 'status', 'subject_id',\n",
      "       'agent_alias', 'log_likelihood', 'AIC', 'BIC', 'LPT', 'LPT_AIC',\n",
      "       'LPT_BIC', 'k_model', 'n_trials', 'prediction_accuracy',\n",
      "       'prediction_accuracy_test', 'prediction_accuracy_fit',\n",
      "       'prediction_accuracy_test_bias_only', 'params',\n",
      "       'prediction_accuracy_10-CV_test', 'prediction_accuracy_10-CV_test_std',\n",
      "       'prediction_accuracy_10-CV_fit', 'prediction_accuracy_10-CV_fit_std',\n",
      "       'prediction_accuracy_10-CV_test_bias_only',\n",
      "       'prediction_accuracy_10-CV_test_bias_only_std', 'latent_variables'],\n",
      "      dtype='object')\n",
      "                      agent_alias          AIC  prediction_accuracy_10-CV_test\n",
      "0      QLearning_L2F1_CK1_softmax    88.269775                        0.935354\n",
      "1      QLearning_L2F0_CKfull_epsi   104.450774                        0.939057\n",
      "2          QLearning_L1F0_softmax   119.907831                        0.884848\n",
      "3      QLearning_L1F1_CK1_softmax    94.552043                        0.938384\n",
      "4                     WSLS_CKfull   734.526680                        0.247811\n",
      "5      QLearning_L1F0_CKfull_epsi   102.450774                        0.952525\n",
      "6      QLearning_L2F0_CK1_softmax   104.616753                        0.937710\n",
      "7   QLearning_L2F1_CKfull_softmax    88.977544                        0.942761\n",
      "8         QLearning_L1F0_CK1_epsi   130.183991                        0.924242\n",
      "9                LossCounting_CK1   229.410767                        0.818855\n",
      "10     QLearning_L1F0_CK1_softmax   102.598626                        0.937710\n",
      "11            LossCounting_CKfull   157.020206                        0.865657\n",
      "12  QLearning_L1F1_CKfull_softmax    87.293502                        0.937037\n",
      "13     QLearning_L1F1_CKfull_epsi   104.450774                        0.946465\n",
      "14     QLearning_L2F1_CKfull_epsi   106.450774                        0.927946\n",
      "15  QLearning_L2F0_CKfull_softmax    87.226278                        0.942761\n",
      "16            QLearning_L1F1_epsi   118.755153                        0.929630\n",
      "17            QLearning_L2F0_epsi   280.862243                        0.804040\n",
      "18        QLearning_L2F0_CK1_epsi   132.183991                        0.923569\n",
      "19            QLearning_L1F0_epsi   278.862243                        0.804714\n",
      "20        QLearning_L1F1_CK1_epsi   102.450774                        0.914478\n",
      "21                           WSLS  2980.791019                        0.800337\n",
      "22                   LossCounting   239.957736                        0.804040\n",
      "23         QLearning_L2F1_softmax    86.271276                        0.942088\n",
      "24        QLearning_L2F1_CK1_epsi   145.080749                        0.931650\n",
      "25         QLearning_L1F1_softmax    94.780358                        0.938384\n",
      "26                       WSLS_CK1   881.943626                        0.242424\n",
      "27            QLearning_L2F1_epsi   120.755153                        0.912458\n",
      "28         QLearning_L2F0_softmax   110.800547                        0.923569\n",
      "29  QLearning_L1F0_CKfull_softmax    85.639434                        0.939731\n"
     ]
    }
   ],
   "source": [
    "from aind_analysis_arch_result_access.han_pipeline import get_mle_model_fitting\n",
    "df = get_mle_model_fitting(subject_id=\"706893\", session_date=\"2024-05-28\", )\n",
    "\n",
    "print(df.columns)\n",
    "print(df[[\"agent_alias\", \"AIC\", \"prediction_accuracy_10-CV_test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e10a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>nwb_name</th>\n",
       "      <th>session_date</th>\n",
       "      <th>status</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>agent_alias</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>LPT</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_accuracy_fit</th>\n",
       "      <th>prediction_accuracy_test_bias_only</th>\n",
       "      <th>params</th>\n",
       "      <th>prediction_accuracy_10-CV_test</th>\n",
       "      <th>prediction_accuracy_10-CV_test_std</th>\n",
       "      <th>prediction_accuracy_10-CV_fit</th>\n",
       "      <th>prediction_accuracy_10-CV_fit_std</th>\n",
       "      <th>prediction_accuracy_10-CV_test_bias_only</th>\n",
       "      <th>prediction_accuracy_10-CV_test_bias_only_std</th>\n",
       "      <th>latent_variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0dfa4cfba459edefacae00fb908de0154c69ebd712c541...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CK1_softmax</td>\n",
       "      <td>-38.134888</td>\n",
       "      <td>88.269775</td>\n",
       "      <td>109.992181</td>\n",
       "      <td>0.870951</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9357429718875502, 0.947...</td>\n",
       "      <td>[0.8148148148148148, 0.8148148148148148, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.460696386602735, 'learn_r...</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.943656</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.460696386602735...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17d2ba980515530bcd7f23c993e6d90a0866a4661ffad9...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>104.450774</td>\n",
       "      <td>126.173179</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9678714859437751, 0.9598393574297188, 0.963...</td>\n",
       "      <td>[0.9259259259259259, 0.8148148148148148, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.13964793395391173, 'learn...</td>\n",
       "      <td>0.939057</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>0.961357</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.743771</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.139647933953911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b41a955e5764933bbf980b4d24d63774d07ef0405fdb8...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_softmax</td>\n",
       "      <td>-56.953915</td>\n",
       "      <td>119.907831</td>\n",
       "      <td>130.769033</td>\n",
       "      <td>0.813544</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.891566265060241, 0.8755020080321285, 0.8915...</td>\n",
       "      <td>[0.7037037037037037, 0.8518518518518519, 0.740...</td>\n",
       "      <td>{'learn_rate': 0.0057361265166139385, 'biasL':...</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.884873</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.005736126516613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1fcdc55fe3c259d3959fd675807c19eb1eeb7ed7daaf3d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CK1_softmax</td>\n",
       "      <td>-42.276022</td>\n",
       "      <td>94.552043</td>\n",
       "      <td>112.654048</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9397590361445783, 0.9477911646586346, 0.939...</td>\n",
       "      <td>[0.18518518518518517, 0.25925925925925924, 0.7...</td>\n",
       "      <td>{'learn_rate': 0.007641672474704939, 'forget_r...</td>\n",
       "      <td>0.938384</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.943626</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.301684</td>\n",
       "      <td>0.237598</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.007641672474704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271f44abdc762768297368204bd4b77290c179a47ed91b...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS_CKfull</td>\n",
       "      <td>-364.263340</td>\n",
       "      <td>734.526680</td>\n",
       "      <td>745.387883</td>\n",
       "      <td>0.267190</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.24096385542168675, 0.26506024096385544, 0.2...</td>\n",
       "      <td>[0.7407407407407407, 0.7777777777777778, 0.777...</td>\n",
       "      <td>{'biasL': -0.016164770687993015, 'choice_kerne...</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.085259</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2f54d18b4e3d56a77ab280228dc00be74433b0feb7b6aa...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>102.450774</td>\n",
       "      <td>120.552778</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9759036144578314, 0.9598393574297188, 0.963...</td>\n",
       "      <td>[0.9259259259259259, 0.8888888888888888, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.21128523786920977, 'choice_ke...</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>0.960142</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.735017</td>\n",
       "      <td>0.214037</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.211285237869209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35f4e878433df9d7658ad6a8dee30e1f4db838cbdc5c80...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CK1_softmax</td>\n",
       "      <td>-47.308376</td>\n",
       "      <td>104.616753</td>\n",
       "      <td>122.718757</td>\n",
       "      <td>0.842478</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9437751004016064, 0.951...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.777...</td>\n",
       "      <td>{'learn_rate_rew': 0.015408089857806765, 'lear...</td>\n",
       "      <td>0.937710</td>\n",
       "      <td>0.060160</td>\n",
       "      <td>0.940012</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.056062</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.015408089857806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>495e85c73c51a8c9ab9d7bf629e0631c1738b164d85642...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CKfull_softmax</td>\n",
       "      <td>-37.488772</td>\n",
       "      <td>88.977544</td>\n",
       "      <td>114.320351</td>\n",
       "      <td>0.872992</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9397590361445783, 0.947...</td>\n",
       "      <td>[0.9259259259259259, 0.8518518518518519, 0.740...</td>\n",
       "      <td>{'learn_rate_rew': 0.016305867407219492, 'lear...</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.016305867407219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4d3e0d0be93ac68f5ff562e42a3840fde0720b6fd06bc1...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CK1_epsi</td>\n",
       "      <td>-61.091995</td>\n",
       "      <td>130.183991</td>\n",
       "      <td>144.665594</td>\n",
       "      <td>0.801438</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9437751004016064, 0.951...</td>\n",
       "      <td>[0.7037037037037037, 0.8148148148148148, 0.888...</td>\n",
       "      <td>{'learn_rate': 0.16963313697979332, 'choice_ke...</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.944851</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.169633136979793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4f6cc4f4b82d18698f25eb1b540153ed21727b014b62be...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting_CK1</td>\n",
       "      <td>-110.705383</td>\n",
       "      <td>229.410767</td>\n",
       "      <td>243.892370</td>\n",
       "      <td>0.669579</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8353413654618473, 0.8192771084337349, 0.831...</td>\n",
       "      <td>[0.7777777777777778, 0.8518518518518519, 0.851...</td>\n",
       "      <td>{'loss_count_threshold_mean': 5.30395345038595...</td>\n",
       "      <td>0.818855</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.824865</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.058256</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55441aed29e92a1b81384ca026eb3e8aa25a8e16a132e0...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CK1_softmax</td>\n",
       "      <td>-47.299313</td>\n",
       "      <td>102.598626</td>\n",
       "      <td>117.080230</td>\n",
       "      <td>0.842506</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9437751004016064, 0.943...</td>\n",
       "      <td>[0.9259259259259259, 0.6296296296296297, 0.777...</td>\n",
       "      <td>{'learn_rate': 0.0037023287546044635, 'choice_...</td>\n",
       "      <td>0.937710</td>\n",
       "      <td>0.037742</td>\n",
       "      <td>0.940815</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.079250</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.003702328754604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>588fb69b6a94ae694002b3d67c2e2cdbc0a580c190da95...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting_CKfull</td>\n",
       "      <td>-73.510103</td>\n",
       "      <td>157.020206</td>\n",
       "      <td>175.122210</td>\n",
       "      <td>0.766178</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8634538152610441, 0.8714859437751004, 0.875...</td>\n",
       "      <td>[0.9259259259259259, 0.7037037037037037, 0.740...</td>\n",
       "      <td>{'loss_count_threshold_mean': 10, 'loss_count_...</td>\n",
       "      <td>0.865657</td>\n",
       "      <td>0.072331</td>\n",
       "      <td>0.875998</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>651d38ab922f0b27a7ec0d0f54fba41d0f3fbe6622d6a6...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CKfull_softmax</td>\n",
       "      <td>-37.646751</td>\n",
       "      <td>87.293502</td>\n",
       "      <td>109.015907</td>\n",
       "      <td>0.872492</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9317269076305221, 0.9598393574297188, 0.947...</td>\n",
       "      <td>[0.8888888888888888, 0.8518518518518519, 0.703...</td>\n",
       "      <td>{'learn_rate': 0.24457199743093422, 'forget_ra...</td>\n",
       "      <td>0.937037</td>\n",
       "      <td>0.043979</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.098443</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.244571997430934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6d01f31a00fd411ce942e792f1d52ef94ce36b5be6a209...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>104.450774</td>\n",
       "      <td>126.173179</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.963855421686747, 0.9558232931726908, 0.9678...</td>\n",
       "      <td>[0.9259259259259259, 0.7407407407407407, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.3003335824639858, 'forget_rat...</td>\n",
       "      <td>0.946465</td>\n",
       "      <td>0.035392</td>\n",
       "      <td>0.959740</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.056204</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.300333582463985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>814538c465bd69f4a975b859faa5affa89c51ba5b8d753...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>106.450774</td>\n",
       "      <td>131.793580</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9558232931726908, 0.959...</td>\n",
       "      <td>[0.8888888888888888, 0.9259259259259259, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.24161215238838513, 'learn...</td>\n",
       "      <td>0.927946</td>\n",
       "      <td>0.067461</td>\n",
       "      <td>0.958545</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.750505</td>\n",
       "      <td>0.190457</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.241612152388385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8674e4424c84df783449a009f3292e0b2a5d1c0709b484...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CKfull_softmax</td>\n",
       "      <td>-37.613139</td>\n",
       "      <td>87.226278</td>\n",
       "      <td>108.948683</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9437751004016064, 0.943...</td>\n",
       "      <td>[0.9259259259259259, 0.7777777777777778, 0.888...</td>\n",
       "      <td>{'learn_rate_rew': 0.01662460687527222, 'learn...</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>0.948495</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.016624606875272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8fdab4173cbc7f082d1a8ef897b6d66df046f69be39172...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_epsi</td>\n",
       "      <td>-55.377576</td>\n",
       "      <td>118.755153</td>\n",
       "      <td>133.236756</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9477911646586346, 0.955...</td>\n",
       "      <td>[0.8518518518518519, 0.18518518518518517, 0.70...</td>\n",
       "      <td>{'learn_rate': 0.030955106379390418, 'forget_r...</td>\n",
       "      <td>0.929630</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>0.951267</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.357239</td>\n",
       "      <td>0.279053</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.030955106379390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95f40a617531b491c5201fce28c159ffe3a5b5bfce5548...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_epsi</td>\n",
       "      <td>-136.431122</td>\n",
       "      <td>280.862243</td>\n",
       "      <td>295.343847</td>\n",
       "      <td>0.609988</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8032128514056225, 0.7991967871485943, 0.823...</td>\n",
       "      <td>[0.8148148148148148, 0.8518518518518519, 0.629...</td>\n",
       "      <td>{'learn_rate_rew': 0.6283479581832674, 'learn_...</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.805950</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.628347958183267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ae58bf1fd37be24880376827b39db489d7d1b588f78cfc...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CK1_epsi</td>\n",
       "      <td>-61.091995</td>\n",
       "      <td>132.183991</td>\n",
       "      <td>150.285995</td>\n",
       "      <td>0.801438</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9518072289156626, 0.947...</td>\n",
       "      <td>[0.6666666666666666, 0.7407407407407407, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.1322377703532952, 'learn_...</td>\n",
       "      <td>0.923569</td>\n",
       "      <td>0.042377</td>\n",
       "      <td>0.948465</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.084589</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.132237770353295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b0b66785a43344c0004e64858f0adb13af2d93263f4981...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_epsi</td>\n",
       "      <td>-136.431122</td>\n",
       "      <td>278.862243</td>\n",
       "      <td>289.723446</td>\n",
       "      <td>0.609988</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8072289156626506, 0.7951807228915663, 0.803...</td>\n",
       "      <td>[0.7777777777777778, 0.8888888888888888, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.7605286042879007, 'biasL': -4...</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>0.804353</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.760528604287900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b4d4fa61bb40b0aefbb6237df5179a05a4fb77bdd185c0...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CK1_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>102.450774</td>\n",
       "      <td>120.552778</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9397590361445783, 0.955...</td>\n",
       "      <td>[0.7037037037037037, 0.7037037037037037, 0.888...</td>\n",
       "      <td>{'learn_rate': 0.04185042934833261, 'forget_ra...</td>\n",
       "      <td>0.914478</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.558249</td>\n",
       "      <td>0.304950</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.041850429348332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b99fca1dd02c038abe09fe7db5bb5d99cbd7cb58b32984...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS</td>\n",
       "      <td>-1489.395510</td>\n",
       "      <td>2980.791019</td>\n",
       "      <td>2984.411420</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.7951807228915663, 0.8032128514056225, 0.795...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.851...</td>\n",
       "      <td>{'biasL': -0.9180327782848818, 'loss_count_thr...</td>\n",
       "      <td>0.800337</td>\n",
       "      <td>0.066749</td>\n",
       "      <td>0.800719</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.057571</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c13e5062bd5bf72c02626b4197cfd5a475b7363a3b099c...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting</td>\n",
       "      <td>-116.978868</td>\n",
       "      <td>239.957736</td>\n",
       "      <td>250.818939</td>\n",
       "      <td>0.654531</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8152610441767069, 0.8032128514056225, 0.795...</td>\n",
       "      <td>[0.7777777777777778, 0.9259259259259259, 0.888...</td>\n",
       "      <td>{'loss_count_threshold_mean': 10, 'loss_count_...</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.070431</td>\n",
       "      <td>0.804343</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.070431</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c23c0e97569743def70a4a415f14668eeff0538a48d52f...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_softmax</td>\n",
       "      <td>-38.135638</td>\n",
       "      <td>86.271276</td>\n",
       "      <td>104.373280</td>\n",
       "      <td>0.870948</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9518072289156626, 0.943...</td>\n",
       "      <td>[0.25925925925925924, 0.8518518518518519, 0.74...</td>\n",
       "      <td>{'learn_rate_rew': 0.4596583432690249, 'learn_...</td>\n",
       "      <td>0.942088</td>\n",
       "      <td>0.037457</td>\n",
       "      <td>0.944439</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.757239</td>\n",
       "      <td>0.180010</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.459658343269024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c2bcc2986491be9d35374ff87ea8e129475016e83d0221...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CK1_epsi</td>\n",
       "      <td>-66.540374</td>\n",
       "      <td>145.080749</td>\n",
       "      <td>166.803154</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9317269076305221, 0.9357429718875502, 0.959...</td>\n",
       "      <td>[0.7407407407407407, 0.7037037037037037, 0.703...</td>\n",
       "      <td>{'learn_rate_rew': 0.22649725287289912, 'learn...</td>\n",
       "      <td>0.931650</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>0.936799</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.756566</td>\n",
       "      <td>0.183994</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.226497252872899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>c7181ce080b809b24930d2354ef2506fa55cefd174f07a...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_softmax</td>\n",
       "      <td>-43.390179</td>\n",
       "      <td>94.780358</td>\n",
       "      <td>109.261962</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9477911646586346, 0.947...</td>\n",
       "      <td>[0.25925925925925924, 0.1111111111111111, 0.29...</td>\n",
       "      <td>{'learn_rate': 0.006298309291773297, 'forget_r...</td>\n",
       "      <td>0.938384</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.944449</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.195960</td>\n",
       "      <td>0.057571</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.006298309291773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e30c0a8d4b5c92c1ac5238da86b9e3d50ba06197126092...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS_CK1</td>\n",
       "      <td>-438.971813</td>\n",
       "      <td>881.943626</td>\n",
       "      <td>889.184428</td>\n",
       "      <td>0.203828</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25301204819277107, 0.26104417670682734, 0.2...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.703...</td>\n",
       "      <td>{'biasL': -0.14838754925011688, 'choice_kernel...</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.118736</td>\n",
       "      <td>0.246319</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>e62bde6a992ccb6e5441389a80406b2a364be9ebd3d67d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_epsi</td>\n",
       "      <td>-55.377576</td>\n",
       "      <td>120.755153</td>\n",
       "      <td>138.857157</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9518072289156626, 0.9598393574297188, 0.935...</td>\n",
       "      <td>[0.7777777777777778, 0.25925925925925924, 0.74...</td>\n",
       "      <td>{'learn_rate_rew': 0.37999581247450126, 'learn...</td>\n",
       "      <td>0.912458</td>\n",
       "      <td>0.050796</td>\n",
       "      <td>0.950082</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.296533</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.379995812474501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>f24efb6d46beadbd904bcff639b7b026b4ded5c0e3941b...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_softmax</td>\n",
       "      <td>-51.400274</td>\n",
       "      <td>110.800547</td>\n",
       "      <td>125.282151</td>\n",
       "      <td>0.830080</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9317269076305221, 0.927...</td>\n",
       "      <td>[0.7407407407407407, 0.6666666666666666, 0.777...</td>\n",
       "      <td>{'learn_rate_rew': 0.3041948491659956, 'learn_...</td>\n",
       "      <td>0.923569</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.930755</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.304194849165995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fcab1136a6ede41039e0175a515a881d705c6b24e05e4d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CKfull_softmax</td>\n",
       "      <td>-37.819717</td>\n",
       "      <td>85.639434</td>\n",
       "      <td>103.741439</td>\n",
       "      <td>0.871946</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9477911646586346, 0.939...</td>\n",
       "      <td>[0.7777777777777778, 0.7037037037037037, 0.703...</td>\n",
       "      <td>{'learn_rate': 0.23873165801064972, 'choice_ke...</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.039250</td>\n",
       "      <td>0.942843</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.238731658010649...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  _id  \\\n",
       "0   0dfa4cfba459edefacae00fb908de0154c69ebd712c541...   \n",
       "1   17d2ba980515530bcd7f23c993e6d90a0866a4661ffad9...   \n",
       "2   1b41a955e5764933bbf980b4d24d63774d07ef0405fdb8...   \n",
       "3   1fcdc55fe3c259d3959fd675807c19eb1eeb7ed7daaf3d...   \n",
       "4   271f44abdc762768297368204bd4b77290c179a47ed91b...   \n",
       "5   2f54d18b4e3d56a77ab280228dc00be74433b0feb7b6aa...   \n",
       "6   35f4e878433df9d7658ad6a8dee30e1f4db838cbdc5c80...   \n",
       "7   495e85c73c51a8c9ab9d7bf629e0631c1738b164d85642...   \n",
       "8   4d3e0d0be93ac68f5ff562e42a3840fde0720b6fd06bc1...   \n",
       "9   4f6cc4f4b82d18698f25eb1b540153ed21727b014b62be...   \n",
       "10  55441aed29e92a1b81384ca026eb3e8aa25a8e16a132e0...   \n",
       "11  588fb69b6a94ae694002b3d67c2e2cdbc0a580c190da95...   \n",
       "12  651d38ab922f0b27a7ec0d0f54fba41d0f3fbe6622d6a6...   \n",
       "13  6d01f31a00fd411ce942e792f1d52ef94ce36b5be6a209...   \n",
       "14  814538c465bd69f4a975b859faa5affa89c51ba5b8d753...   \n",
       "15  8674e4424c84df783449a009f3292e0b2a5d1c0709b484...   \n",
       "16  8fdab4173cbc7f082d1a8ef897b6d66df046f69be39172...   \n",
       "17  95f40a617531b491c5201fce28c159ffe3a5b5bfce5548...   \n",
       "18  ae58bf1fd37be24880376827b39db489d7d1b588f78cfc...   \n",
       "19  b0b66785a43344c0004e64858f0adb13af2d93263f4981...   \n",
       "20  b4d4fa61bb40b0aefbb6237df5179a05a4fb77bdd185c0...   \n",
       "21  b99fca1dd02c038abe09fe7db5bb5d99cbd7cb58b32984...   \n",
       "22  c13e5062bd5bf72c02626b4197cfd5a475b7363a3b099c...   \n",
       "23  c23c0e97569743def70a4a415f14668eeff0538a48d52f...   \n",
       "24  c2bcc2986491be9d35374ff87ea8e129475016e83d0221...   \n",
       "25  c7181ce080b809b24930d2354ef2506fa55cefd174f07a...   \n",
       "26  e30c0a8d4b5c92c1ac5238da86b9e3d50ba06197126092...   \n",
       "27  e62bde6a992ccb6e5441389a80406b2a364be9ebd3d67d...   \n",
       "28  f24efb6d46beadbd904bcff639b7b026b4ded5c0e3941b...   \n",
       "29  fcab1136a6ede41039e0175a515a881d705c6b24e05e4d...   \n",
       "\n",
       "                          nwb_name session_date   status subject_id  \\\n",
       "0   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "1   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "2   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "3   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "4   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "5   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "6   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "7   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "8   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "9   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "10  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "11  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "12  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "13  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "14  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "15  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "16  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "17  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "18  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "19  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "20  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "21  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "22  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "23  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "24  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "25  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "26  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "27  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "28  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "29  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "\n",
       "                      agent_alias  log_likelihood          AIC          BIC  \\\n",
       "0      QLearning_L2F1_CK1_softmax      -38.134888    88.269775   109.992181   \n",
       "1      QLearning_L2F0_CKfull_epsi      -46.225387   104.450774   126.173179   \n",
       "2          QLearning_L1F0_softmax      -56.953915   119.907831   130.769033   \n",
       "3      QLearning_L1F1_CK1_softmax      -42.276022    94.552043   112.654048   \n",
       "4                     WSLS_CKfull     -364.263340   734.526680   745.387883   \n",
       "5      QLearning_L1F0_CKfull_epsi      -46.225387   102.450774   120.552778   \n",
       "6      QLearning_L2F0_CK1_softmax      -47.308376   104.616753   122.718757   \n",
       "7   QLearning_L2F1_CKfull_softmax      -37.488772    88.977544   114.320351   \n",
       "8         QLearning_L1F0_CK1_epsi      -61.091995   130.183991   144.665594   \n",
       "9                LossCounting_CK1     -110.705383   229.410767   243.892370   \n",
       "10     QLearning_L1F0_CK1_softmax      -47.299313   102.598626   117.080230   \n",
       "11            LossCounting_CKfull      -73.510103   157.020206   175.122210   \n",
       "12  QLearning_L1F1_CKfull_softmax      -37.646751    87.293502   109.015907   \n",
       "13     QLearning_L1F1_CKfull_epsi      -46.225387   104.450774   126.173179   \n",
       "14     QLearning_L2F1_CKfull_epsi      -46.225387   106.450774   131.793580   \n",
       "15  QLearning_L2F0_CKfull_softmax      -37.613139    87.226278   108.948683   \n",
       "16            QLearning_L1F1_epsi      -55.377576   118.755153   133.236756   \n",
       "17            QLearning_L2F0_epsi     -136.431122   280.862243   295.343847   \n",
       "18        QLearning_L2F0_CK1_epsi      -61.091995   132.183991   150.285995   \n",
       "19            QLearning_L1F0_epsi     -136.431122   278.862243   289.723446   \n",
       "20        QLearning_L1F1_CK1_epsi      -46.225387   102.450774   120.552778   \n",
       "21                           WSLS    -1489.395510  2980.791019  2984.411420   \n",
       "22                   LossCounting     -116.978868   239.957736   250.818939   \n",
       "23         QLearning_L2F1_softmax      -38.135638    86.271276   104.373280   \n",
       "24        QLearning_L2F1_CK1_epsi      -66.540374   145.080749   166.803154   \n",
       "25         QLearning_L1F1_softmax      -43.390179    94.780358   109.261962   \n",
       "26                       WSLS_CK1     -438.971813   881.943626   889.184428   \n",
       "27            QLearning_L2F1_epsi      -55.377576   120.755153   138.857157   \n",
       "28         QLearning_L2F0_softmax      -51.400274   110.800547   125.282151   \n",
       "29  QLearning_L1F0_CKfull_softmax      -37.819717    85.639434   103.741439   \n",
       "\n",
       "         LPT  ...                            prediction_accuracy_fit  \\\n",
       "0   0.870951  ...  [0.9477911646586346, 0.9357429718875502, 0.947...   \n",
       "1   0.845791  ...  [0.9678714859437751, 0.9598393574297188, 0.963...   \n",
       "2   0.813544  ...  [0.891566265060241, 0.8755020080321285, 0.8915...   \n",
       "3   0.857980  ...  [0.9397590361445783, 0.9477911646586346, 0.939...   \n",
       "4   0.267190  ...  [0.24096385542168675, 0.26506024096385544, 0.2...   \n",
       "5   0.845791  ...  [0.9759036144578314, 0.9598393574297188, 0.963...   \n",
       "6   0.842478  ...  [0.9357429718875502, 0.9437751004016064, 0.951...   \n",
       "7   0.872992  ...  [0.9357429718875502, 0.9397590361445783, 0.947...   \n",
       "8   0.801438  ...  [0.9437751004016064, 0.9437751004016064, 0.951...   \n",
       "9   0.669579  ...  [0.8353413654618473, 0.8192771084337349, 0.831...   \n",
       "10  0.842506  ...  [0.9558232931726908, 0.9437751004016064, 0.943...   \n",
       "11  0.766178  ...  [0.8634538152610441, 0.8714859437751004, 0.875...   \n",
       "12  0.872492  ...  [0.9317269076305221, 0.9598393574297188, 0.947...   \n",
       "13  0.845791  ...  [0.963855421686747, 0.9558232931726908, 0.9678...   \n",
       "14  0.845791  ...  [0.9558232931726908, 0.9558232931726908, 0.959...   \n",
       "15  0.872599  ...  [0.9437751004016064, 0.9437751004016064, 0.943...   \n",
       "16  0.818204  ...  [0.9437751004016064, 0.9477911646586346, 0.955...   \n",
       "17  0.609988  ...  [0.8032128514056225, 0.7991967871485943, 0.823...   \n",
       "18  0.801438  ...  [0.9558232931726908, 0.9518072289156626, 0.947...   \n",
       "19  0.609988  ...  [0.8072289156626506, 0.7951807228915663, 0.803...   \n",
       "20  0.845791  ...  [0.9357429718875502, 0.9397590361445783, 0.955...   \n",
       "21  0.004533  ...  [0.7951807228915663, 0.8032128514056225, 0.795...   \n",
       "22  0.654531  ...  [0.8152610441767069, 0.8032128514056225, 0.795...   \n",
       "23  0.870948  ...  [0.9477911646586346, 0.9518072289156626, 0.943...   \n",
       "24  0.785772  ...  [0.9317269076305221, 0.9357429718875502, 0.959...   \n",
       "25  0.854524  ...  [0.9477911646586346, 0.9477911646586346, 0.947...   \n",
       "26  0.203828  ...  [0.25301204819277107, 0.26104417670682734, 0.2...   \n",
       "27  0.818204  ...  [0.9518072289156626, 0.9598393574297188, 0.935...   \n",
       "28  0.830080  ...  [0.9357429718875502, 0.9317269076305221, 0.927...   \n",
       "29  0.871946  ...  [0.9437751004016064, 0.9477911646586346, 0.939...   \n",
       "\n",
       "                   prediction_accuracy_test_bias_only  \\\n",
       "0   [0.8148148148148148, 0.8148148148148148, 0.851...   \n",
       "1   [0.9259259259259259, 0.8148148148148148, 0.851...   \n",
       "2   [0.7037037037037037, 0.8518518518518519, 0.740...   \n",
       "3   [0.18518518518518517, 0.25925925925925924, 0.7...   \n",
       "4   [0.7407407407407407, 0.7777777777777778, 0.777...   \n",
       "5   [0.9259259259259259, 0.8888888888888888, 0.814...   \n",
       "6   [0.8518518518518519, 0.7777777777777778, 0.777...   \n",
       "7   [0.9259259259259259, 0.8518518518518519, 0.740...   \n",
       "8   [0.7037037037037037, 0.8148148148148148, 0.888...   \n",
       "9   [0.7777777777777778, 0.8518518518518519, 0.851...   \n",
       "10  [0.9259259259259259, 0.6296296296296297, 0.777...   \n",
       "11  [0.9259259259259259, 0.7037037037037037, 0.740...   \n",
       "12  [0.8888888888888888, 0.8518518518518519, 0.703...   \n",
       "13  [0.9259259259259259, 0.7407407407407407, 0.814...   \n",
       "14  [0.8888888888888888, 0.9259259259259259, 0.851...   \n",
       "15  [0.9259259259259259, 0.7777777777777778, 0.888...   \n",
       "16  [0.8518518518518519, 0.18518518518518517, 0.70...   \n",
       "17  [0.8148148148148148, 0.8518518518518519, 0.629...   \n",
       "18  [0.6666666666666666, 0.7407407407407407, 0.851...   \n",
       "19  [0.7777777777777778, 0.8888888888888888, 0.814...   \n",
       "20  [0.7037037037037037, 0.7037037037037037, 0.888...   \n",
       "21  [0.8518518518518519, 0.7777777777777778, 0.851...   \n",
       "22  [0.7777777777777778, 0.9259259259259259, 0.888...   \n",
       "23  [0.25925925925925924, 0.8518518518518519, 0.74...   \n",
       "24  [0.7407407407407407, 0.7037037037037037, 0.703...   \n",
       "25  [0.25925925925925924, 0.1111111111111111, 0.29...   \n",
       "26  [0.8518518518518519, 0.7777777777777778, 0.703...   \n",
       "27  [0.7777777777777778, 0.25925925925925924, 0.74...   \n",
       "28  [0.7407407407407407, 0.6666666666666666, 0.777...   \n",
       "29  [0.7777777777777778, 0.7037037037037037, 0.703...   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'learn_rate_rew': 0.460696386602735, 'learn_r...   \n",
       "1   {'learn_rate_rew': 0.13964793395391173, 'learn...   \n",
       "2   {'learn_rate': 0.0057361265166139385, 'biasL':...   \n",
       "3   {'learn_rate': 0.007641672474704939, 'forget_r...   \n",
       "4   {'biasL': -0.016164770687993015, 'choice_kerne...   \n",
       "5   {'learn_rate': 0.21128523786920977, 'choice_ke...   \n",
       "6   {'learn_rate_rew': 0.015408089857806765, 'lear...   \n",
       "7   {'learn_rate_rew': 0.016305867407219492, 'lear...   \n",
       "8   {'learn_rate': 0.16963313697979332, 'choice_ke...   \n",
       "9   {'loss_count_threshold_mean': 5.30395345038595...   \n",
       "10  {'learn_rate': 0.0037023287546044635, 'choice_...   \n",
       "11  {'loss_count_threshold_mean': 10, 'loss_count_...   \n",
       "12  {'learn_rate': 0.24457199743093422, 'forget_ra...   \n",
       "13  {'learn_rate': 0.3003335824639858, 'forget_rat...   \n",
       "14  {'learn_rate_rew': 0.24161215238838513, 'learn...   \n",
       "15  {'learn_rate_rew': 0.01662460687527222, 'learn...   \n",
       "16  {'learn_rate': 0.030955106379390418, 'forget_r...   \n",
       "17  {'learn_rate_rew': 0.6283479581832674, 'learn_...   \n",
       "18  {'learn_rate_rew': 0.1322377703532952, 'learn_...   \n",
       "19  {'learn_rate': 0.7605286042879007, 'biasL': -4...   \n",
       "20  {'learn_rate': 0.04185042934833261, 'forget_ra...   \n",
       "21  {'biasL': -0.9180327782848818, 'loss_count_thr...   \n",
       "22  {'loss_count_threshold_mean': 10, 'loss_count_...   \n",
       "23  {'learn_rate_rew': 0.4596583432690249, 'learn_...   \n",
       "24  {'learn_rate_rew': 0.22649725287289912, 'learn...   \n",
       "25  {'learn_rate': 0.006298309291773297, 'forget_r...   \n",
       "26  {'biasL': -0.14838754925011688, 'choice_kernel...   \n",
       "27  {'learn_rate_rew': 0.37999581247450126, 'learn...   \n",
       "28  {'learn_rate_rew': 0.3041948491659956, 'learn_...   \n",
       "29  {'learn_rate': 0.23873165801064972, 'choice_ke...   \n",
       "\n",
       "    prediction_accuracy_10-CV_test  prediction_accuracy_10-CV_test_std  \\\n",
       "0                         0.935354                            0.050456   \n",
       "1                         0.939057                            0.030876   \n",
       "2                         0.884848                            0.053763   \n",
       "3                         0.938384                            0.037039   \n",
       "4                         0.247811                            0.070678   \n",
       "5                         0.952525                            0.052690   \n",
       "6                         0.937710                            0.060160   \n",
       "7                         0.942761                            0.045573   \n",
       "8                         0.924242                            0.029130   \n",
       "9                         0.818855                            0.050903   \n",
       "10                        0.937710                            0.037742   \n",
       "11                        0.865657                            0.072331   \n",
       "12                        0.937037                            0.043979   \n",
       "13                        0.946465                            0.035392   \n",
       "14                        0.927946                            0.067461   \n",
       "15                        0.942761                            0.035410   \n",
       "16                        0.929630                            0.048148   \n",
       "17                        0.804040                            0.074224   \n",
       "18                        0.923569                            0.042377   \n",
       "19                        0.804714                            0.052096   \n",
       "20                        0.914478                            0.041270   \n",
       "21                        0.800337                            0.066749   \n",
       "22                        0.804040                            0.070431   \n",
       "23                        0.942088                            0.037457   \n",
       "24                        0.931650                            0.036977   \n",
       "25                        0.938384                            0.033129   \n",
       "26                        0.242424                            0.118736   \n",
       "27                        0.912458                            0.050796   \n",
       "28                        0.923569                            0.048421   \n",
       "29                        0.939731                            0.039250   \n",
       "\n",
       "   prediction_accuracy_10-CV_fit prediction_accuracy_10-CV_fit_std  \\\n",
       "0                       0.943656                          0.006077   \n",
       "1                       0.961357                          0.003632   \n",
       "2                       0.884873                          0.006558   \n",
       "3                       0.943626                          0.005516   \n",
       "4                       0.246398                          0.007845   \n",
       "5                       0.960142                          0.007514   \n",
       "6                       0.940012                          0.006104   \n",
       "7                       0.946457                          0.007184   \n",
       "8                       0.944851                          0.005039   \n",
       "9                       0.824865                          0.008674   \n",
       "10                      0.940815                          0.006279   \n",
       "11                      0.875998                          0.010035   \n",
       "12                      0.944811                          0.008522   \n",
       "13                      0.959740                          0.004027   \n",
       "14                      0.958545                          0.003928   \n",
       "15                      0.948495                          0.007857   \n",
       "16                      0.951267                          0.006000   \n",
       "17                      0.805950                          0.009537   \n",
       "18                      0.948465                          0.004721   \n",
       "19                      0.804353                          0.005665   \n",
       "20                      0.948094                          0.008184   \n",
       "21                      0.800719                          0.007252   \n",
       "22                      0.804343                          0.007646   \n",
       "23                      0.944439                          0.003985   \n",
       "24                      0.936799                          0.008586   \n",
       "25                      0.944449                          0.003403   \n",
       "26                      0.246319                          0.013678   \n",
       "27                      0.950082                          0.006253   \n",
       "28                      0.930755                          0.017761   \n",
       "29                      0.942843                          0.006830   \n",
       "\n",
       "   prediction_accuracy_10-CV_test_bias_only  \\\n",
       "0                                  0.804040   \n",
       "1                                  0.743771   \n",
       "2                                  0.804714   \n",
       "3                                  0.301684   \n",
       "4                                  0.801347   \n",
       "5                                  0.735017   \n",
       "6                                  0.802694   \n",
       "7                                  0.803367   \n",
       "8                                  0.806734   \n",
       "9                                  0.805387   \n",
       "10                                 0.804714   \n",
       "11                                 0.802694   \n",
       "12                                 0.806734   \n",
       "13                                 0.806061   \n",
       "14                                 0.750505   \n",
       "15                                 0.804040   \n",
       "16                                 0.357239   \n",
       "17                                 0.804040   \n",
       "18                                 0.804040   \n",
       "19                                 0.804714   \n",
       "20                                 0.558249   \n",
       "21                                 0.804040   \n",
       "22                                 0.804040   \n",
       "23                                 0.757239   \n",
       "24                                 0.756566   \n",
       "25                                 0.195960   \n",
       "26                                 0.804714   \n",
       "27                                 0.387879   \n",
       "28                                 0.805387   \n",
       "29                                 0.805387   \n",
       "\n",
       "   prediction_accuracy_10-CV_test_bias_only_std  \\\n",
       "0                                      0.066421   \n",
       "1                                      0.197143   \n",
       "2                                      0.063920   \n",
       "3                                      0.237598   \n",
       "4                                      0.085259   \n",
       "5                                      0.214037   \n",
       "6                                      0.056062   \n",
       "7                                      0.070147   \n",
       "8                                      0.072811   \n",
       "9                                      0.058256   \n",
       "10                                     0.079250   \n",
       "11                                     0.069203   \n",
       "12                                     0.098443   \n",
       "13                                     0.056204   \n",
       "14                                     0.190457   \n",
       "15                                     0.077832   \n",
       "16                                     0.279053   \n",
       "17                                     0.074224   \n",
       "18                                     0.084589   \n",
       "19                                     0.052096   \n",
       "20                                     0.304950   \n",
       "21                                     0.057571   \n",
       "22                                     0.070431   \n",
       "23                                     0.180010   \n",
       "24                                     0.183994   \n",
       "25                                     0.057571   \n",
       "26                                     0.063920   \n",
       "27                                     0.296533   \n",
       "28                                     0.067016   \n",
       "29                                     0.067016   \n",
       "\n",
       "                                     latent_variables  \n",
       "0   {'q_value': [[0.0, 0.0, 0.0, 0.460696386602735...  \n",
       "1   {'q_value': [[0.0, 0.0, 0.0, 0.139647933953911...  \n",
       "2   {'q_value': [[0.0, 0.0, 0.0, 0.005736126516613...  \n",
       "3   {'q_value': [[0.0, 0.0, 0.0, 0.007641672474704...  \n",
       "4   {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "5   {'q_value': [[0.0, 0.0, 0.0, 0.211285237869209...  \n",
       "6   {'q_value': [[0.0, 0.0, 0.0, 0.015408089857806...  \n",
       "7   {'q_value': [[0.0, 0.0, 0.0, 0.016305867407219...  \n",
       "8   {'q_value': [[0.0, 0.0, 0.0, 0.169633136979793...  \n",
       "9   {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "10  {'q_value': [[0.0, 0.0, 0.0, 0.003702328754604...  \n",
       "11  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "12  {'q_value': [[0.0, 0.0, 0.0, 0.244571997430934...  \n",
       "13  {'q_value': [[0.0, 0.0, 0.0, 0.300333582463985...  \n",
       "14  {'q_value': [[0.0, 0.0, 0.0, 0.241612152388385...  \n",
       "15  {'q_value': [[0.0, 0.0, 0.0, 0.016624606875272...  \n",
       "16  {'q_value': [[0.0, 0.0, 0.0, 0.030955106379390...  \n",
       "17  {'q_value': [[0.0, 0.0, 0.0, 0.628347958183267...  \n",
       "18  {'q_value': [[0.0, 0.0, 0.0, 0.132237770353295...  \n",
       "19  {'q_value': [[0.0, 0.0, 0.0, 0.760528604287900...  \n",
       "20  {'q_value': [[0.0, 0.0, 0.0, 0.041850429348332...  \n",
       "21  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "22  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "23  {'q_value': [[0.0, 0.0, 0.0, 0.459658343269024...  \n",
       "24  {'q_value': [[0.0, 0.0, 0.0, 0.226497252872899...  \n",
       "25  {'q_value': [[0.0, 0.0, 0.0, 0.006298309291773...  \n",
       "26  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "27  {'q_value': [[0.0, 0.0, 0.0, 0.379995812474501...  \n",
       "28  {'q_value': [[0.0, 0.0, 0.0, 0.304194849165995...  \n",
       "29  {'q_value': [[0.0, 0.0, 0.0, 0.238731658010649...  \n",
       "\n",
       "[30 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e9ee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>nwb_name</th>\n",
       "      <th>session_date</th>\n",
       "      <th>status</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>agent_alias</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>LPT</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_accuracy_fit</th>\n",
       "      <th>prediction_accuracy_test_bias_only</th>\n",
       "      <th>params</th>\n",
       "      <th>prediction_accuracy_10-CV_test</th>\n",
       "      <th>prediction_accuracy_10-CV_test_std</th>\n",
       "      <th>prediction_accuracy_10-CV_fit</th>\n",
       "      <th>prediction_accuracy_10-CV_fit_std</th>\n",
       "      <th>prediction_accuracy_10-CV_test_bias_only</th>\n",
       "      <th>prediction_accuracy_10-CV_test_bias_only_std</th>\n",
       "      <th>latent_variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fcab1136a6ede41039e0175a515a881d705c6b24e05e4d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CKfull_softmax</td>\n",
       "      <td>-37.819717</td>\n",
       "      <td>85.639434</td>\n",
       "      <td>103.741439</td>\n",
       "      <td>0.871946</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9477911646586346, 0.939...</td>\n",
       "      <td>[0.7777777777777778, 0.7037037037037037, 0.703...</td>\n",
       "      <td>{'learn_rate': 0.23873165801064972, 'choice_ke...</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.039250</td>\n",
       "      <td>0.942843</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.238731658010649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c23c0e97569743def70a4a415f14668eeff0538a48d52f...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_softmax</td>\n",
       "      <td>-38.135638</td>\n",
       "      <td>86.271276</td>\n",
       "      <td>104.373280</td>\n",
       "      <td>0.870948</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9518072289156626, 0.943...</td>\n",
       "      <td>[0.25925925925925924, 0.8518518518518519, 0.74...</td>\n",
       "      <td>{'learn_rate_rew': 0.4596583432690249, 'learn_...</td>\n",
       "      <td>0.942088</td>\n",
       "      <td>0.037457</td>\n",
       "      <td>0.944439</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.757239</td>\n",
       "      <td>0.180010</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.459658343269024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8674e4424c84df783449a009f3292e0b2a5d1c0709b484...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CKfull_softmax</td>\n",
       "      <td>-37.613139</td>\n",
       "      <td>87.226278</td>\n",
       "      <td>108.948683</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9437751004016064, 0.943...</td>\n",
       "      <td>[0.9259259259259259, 0.7777777777777778, 0.888...</td>\n",
       "      <td>{'learn_rate_rew': 0.01662460687527222, 'learn...</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>0.948495</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.016624606875272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>651d38ab922f0b27a7ec0d0f54fba41d0f3fbe6622d6a6...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CKfull_softmax</td>\n",
       "      <td>-37.646751</td>\n",
       "      <td>87.293502</td>\n",
       "      <td>109.015907</td>\n",
       "      <td>0.872492</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9317269076305221, 0.9598393574297188, 0.947...</td>\n",
       "      <td>[0.8888888888888888, 0.8518518518518519, 0.703...</td>\n",
       "      <td>{'learn_rate': 0.24457199743093422, 'forget_ra...</td>\n",
       "      <td>0.937037</td>\n",
       "      <td>0.043979</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.098443</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.244571997430934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0dfa4cfba459edefacae00fb908de0154c69ebd712c541...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CK1_softmax</td>\n",
       "      <td>-38.134888</td>\n",
       "      <td>88.269775</td>\n",
       "      <td>109.992181</td>\n",
       "      <td>0.870951</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9357429718875502, 0.947...</td>\n",
       "      <td>[0.8148148148148148, 0.8148148148148148, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.460696386602735, 'learn_r...</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.943656</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.460696386602735...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>495e85c73c51a8c9ab9d7bf629e0631c1738b164d85642...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CKfull_softmax</td>\n",
       "      <td>-37.488772</td>\n",
       "      <td>88.977544</td>\n",
       "      <td>114.320351</td>\n",
       "      <td>0.872992</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9397590361445783, 0.947...</td>\n",
       "      <td>[0.9259259259259259, 0.8518518518518519, 0.740...</td>\n",
       "      <td>{'learn_rate_rew': 0.016305867407219492, 'lear...</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.016305867407219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1fcdc55fe3c259d3959fd675807c19eb1eeb7ed7daaf3d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CK1_softmax</td>\n",
       "      <td>-42.276022</td>\n",
       "      <td>94.552043</td>\n",
       "      <td>112.654048</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9397590361445783, 0.9477911646586346, 0.939...</td>\n",
       "      <td>[0.18518518518518517, 0.25925925925925924, 0.7...</td>\n",
       "      <td>{'learn_rate': 0.007641672474704939, 'forget_r...</td>\n",
       "      <td>0.938384</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.943626</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.301684</td>\n",
       "      <td>0.237598</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.007641672474704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>c7181ce080b809b24930d2354ef2506fa55cefd174f07a...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_softmax</td>\n",
       "      <td>-43.390179</td>\n",
       "      <td>94.780358</td>\n",
       "      <td>109.261962</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9477911646586346, 0.9477911646586346, 0.947...</td>\n",
       "      <td>[0.25925925925925924, 0.1111111111111111, 0.29...</td>\n",
       "      <td>{'learn_rate': 0.006298309291773297, 'forget_r...</td>\n",
       "      <td>0.938384</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.944449</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.195960</td>\n",
       "      <td>0.057571</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.006298309291773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b4d4fa61bb40b0aefbb6237df5179a05a4fb77bdd185c0...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CK1_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>102.450774</td>\n",
       "      <td>120.552778</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9397590361445783, 0.955...</td>\n",
       "      <td>[0.7037037037037037, 0.7037037037037037, 0.888...</td>\n",
       "      <td>{'learn_rate': 0.04185042934833261, 'forget_ra...</td>\n",
       "      <td>0.914478</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.558249</td>\n",
       "      <td>0.304950</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.041850429348332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2f54d18b4e3d56a77ab280228dc00be74433b0feb7b6aa...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>102.450774</td>\n",
       "      <td>120.552778</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9759036144578314, 0.9598393574297188, 0.963...</td>\n",
       "      <td>[0.9259259259259259, 0.8888888888888888, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.21128523786920977, 'choice_ke...</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>0.960142</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.735017</td>\n",
       "      <td>0.214037</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.211285237869209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55441aed29e92a1b81384ca026eb3e8aa25a8e16a132e0...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CK1_softmax</td>\n",
       "      <td>-47.299313</td>\n",
       "      <td>102.598626</td>\n",
       "      <td>117.080230</td>\n",
       "      <td>0.842506</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9437751004016064, 0.943...</td>\n",
       "      <td>[0.9259259259259259, 0.6296296296296297, 0.777...</td>\n",
       "      <td>{'learn_rate': 0.0037023287546044635, 'choice_...</td>\n",
       "      <td>0.937710</td>\n",
       "      <td>0.037742</td>\n",
       "      <td>0.940815</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.079250</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.003702328754604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6d01f31a00fd411ce942e792f1d52ef94ce36b5be6a209...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>104.450774</td>\n",
       "      <td>126.173179</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.963855421686747, 0.9558232931726908, 0.9678...</td>\n",
       "      <td>[0.9259259259259259, 0.7407407407407407, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.3003335824639858, 'forget_rat...</td>\n",
       "      <td>0.946465</td>\n",
       "      <td>0.035392</td>\n",
       "      <td>0.959740</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.056204</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.300333582463985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17d2ba980515530bcd7f23c993e6d90a0866a4661ffad9...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>104.450774</td>\n",
       "      <td>126.173179</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9678714859437751, 0.9598393574297188, 0.963...</td>\n",
       "      <td>[0.9259259259259259, 0.8148148148148148, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.13964793395391173, 'learn...</td>\n",
       "      <td>0.939057</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>0.961357</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.743771</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.139647933953911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35f4e878433df9d7658ad6a8dee30e1f4db838cbdc5c80...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CK1_softmax</td>\n",
       "      <td>-47.308376</td>\n",
       "      <td>104.616753</td>\n",
       "      <td>122.718757</td>\n",
       "      <td>0.842478</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9437751004016064, 0.951...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.777...</td>\n",
       "      <td>{'learn_rate_rew': 0.015408089857806765, 'lear...</td>\n",
       "      <td>0.937710</td>\n",
       "      <td>0.060160</td>\n",
       "      <td>0.940012</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.056062</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.015408089857806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>814538c465bd69f4a975b859faa5affa89c51ba5b8d753...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CKfull_epsi</td>\n",
       "      <td>-46.225387</td>\n",
       "      <td>106.450774</td>\n",
       "      <td>131.793580</td>\n",
       "      <td>0.845791</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9558232931726908, 0.959...</td>\n",
       "      <td>[0.8888888888888888, 0.9259259259259259, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.24161215238838513, 'learn...</td>\n",
       "      <td>0.927946</td>\n",
       "      <td>0.067461</td>\n",
       "      <td>0.958545</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.750505</td>\n",
       "      <td>0.190457</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.241612152388385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>f24efb6d46beadbd904bcff639b7b026b4ded5c0e3941b...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_softmax</td>\n",
       "      <td>-51.400274</td>\n",
       "      <td>110.800547</td>\n",
       "      <td>125.282151</td>\n",
       "      <td>0.830080</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9357429718875502, 0.9317269076305221, 0.927...</td>\n",
       "      <td>[0.7407407407407407, 0.6666666666666666, 0.777...</td>\n",
       "      <td>{'learn_rate_rew': 0.3041948491659956, 'learn_...</td>\n",
       "      <td>0.923569</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.930755</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.304194849165995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8fdab4173cbc7f082d1a8ef897b6d66df046f69be39172...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F1_epsi</td>\n",
       "      <td>-55.377576</td>\n",
       "      <td>118.755153</td>\n",
       "      <td>133.236756</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9477911646586346, 0.955...</td>\n",
       "      <td>[0.8518518518518519, 0.18518518518518517, 0.70...</td>\n",
       "      <td>{'learn_rate': 0.030955106379390418, 'forget_r...</td>\n",
       "      <td>0.929630</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>0.951267</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.357239</td>\n",
       "      <td>0.279053</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.030955106379390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b41a955e5764933bbf980b4d24d63774d07ef0405fdb8...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_softmax</td>\n",
       "      <td>-56.953915</td>\n",
       "      <td>119.907831</td>\n",
       "      <td>130.769033</td>\n",
       "      <td>0.813544</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.891566265060241, 0.8755020080321285, 0.8915...</td>\n",
       "      <td>[0.7037037037037037, 0.8518518518518519, 0.740...</td>\n",
       "      <td>{'learn_rate': 0.0057361265166139385, 'biasL':...</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.884873</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.005736126516613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>e62bde6a992ccb6e5441389a80406b2a364be9ebd3d67d...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_epsi</td>\n",
       "      <td>-55.377576</td>\n",
       "      <td>120.755153</td>\n",
       "      <td>138.857157</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9518072289156626, 0.9598393574297188, 0.935...</td>\n",
       "      <td>[0.7777777777777778, 0.25925925925925924, 0.74...</td>\n",
       "      <td>{'learn_rate_rew': 0.37999581247450126, 'learn...</td>\n",
       "      <td>0.912458</td>\n",
       "      <td>0.050796</td>\n",
       "      <td>0.950082</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.296533</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.379995812474501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4d3e0d0be93ac68f5ff562e42a3840fde0720b6fd06bc1...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_CK1_epsi</td>\n",
       "      <td>-61.091995</td>\n",
       "      <td>130.183991</td>\n",
       "      <td>144.665594</td>\n",
       "      <td>0.801438</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9437751004016064, 0.9437751004016064, 0.951...</td>\n",
       "      <td>[0.7037037037037037, 0.8148148148148148, 0.888...</td>\n",
       "      <td>{'learn_rate': 0.16963313697979332, 'choice_ke...</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.944851</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.169633136979793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ae58bf1fd37be24880376827b39db489d7d1b588f78cfc...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_CK1_epsi</td>\n",
       "      <td>-61.091995</td>\n",
       "      <td>132.183991</td>\n",
       "      <td>150.285995</td>\n",
       "      <td>0.801438</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9558232931726908, 0.9518072289156626, 0.947...</td>\n",
       "      <td>[0.6666666666666666, 0.7407407407407407, 0.851...</td>\n",
       "      <td>{'learn_rate_rew': 0.1322377703532952, 'learn_...</td>\n",
       "      <td>0.923569</td>\n",
       "      <td>0.042377</td>\n",
       "      <td>0.948465</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.084589</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.132237770353295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c2bcc2986491be9d35374ff87ea8e129475016e83d0221...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F1_CK1_epsi</td>\n",
       "      <td>-66.540374</td>\n",
       "      <td>145.080749</td>\n",
       "      <td>166.803154</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9317269076305221, 0.9357429718875502, 0.959...</td>\n",
       "      <td>[0.7407407407407407, 0.7037037037037037, 0.703...</td>\n",
       "      <td>{'learn_rate_rew': 0.22649725287289912, 'learn...</td>\n",
       "      <td>0.931650</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>0.936799</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.756566</td>\n",
       "      <td>0.183994</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.226497252872899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>588fb69b6a94ae694002b3d67c2e2cdbc0a580c190da95...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting_CKfull</td>\n",
       "      <td>-73.510103</td>\n",
       "      <td>157.020206</td>\n",
       "      <td>175.122210</td>\n",
       "      <td>0.766178</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8634538152610441, 0.8714859437751004, 0.875...</td>\n",
       "      <td>[0.9259259259259259, 0.7037037037037037, 0.740...</td>\n",
       "      <td>{'loss_count_threshold_mean': 10, 'loss_count_...</td>\n",
       "      <td>0.865657</td>\n",
       "      <td>0.072331</td>\n",
       "      <td>0.875998</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4f6cc4f4b82d18698f25eb1b540153ed21727b014b62be...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting_CK1</td>\n",
       "      <td>-110.705383</td>\n",
       "      <td>229.410767</td>\n",
       "      <td>243.892370</td>\n",
       "      <td>0.669579</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8353413654618473, 0.8192771084337349, 0.831...</td>\n",
       "      <td>[0.7777777777777778, 0.8518518518518519, 0.851...</td>\n",
       "      <td>{'loss_count_threshold_mean': 5.30395345038595...</td>\n",
       "      <td>0.818855</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.824865</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.058256</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c13e5062bd5bf72c02626b4197cfd5a475b7363a3b099c...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>LossCounting</td>\n",
       "      <td>-116.978868</td>\n",
       "      <td>239.957736</td>\n",
       "      <td>250.818939</td>\n",
       "      <td>0.654531</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8152610441767069, 0.8032128514056225, 0.795...</td>\n",
       "      <td>[0.7777777777777778, 0.9259259259259259, 0.888...</td>\n",
       "      <td>{'loss_count_threshold_mean': 10, 'loss_count_...</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.070431</td>\n",
       "      <td>0.804343</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.070431</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b0b66785a43344c0004e64858f0adb13af2d93263f4981...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L1F0_epsi</td>\n",
       "      <td>-136.431122</td>\n",
       "      <td>278.862243</td>\n",
       "      <td>289.723446</td>\n",
       "      <td>0.609988</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8072289156626506, 0.7951807228915663, 0.803...</td>\n",
       "      <td>[0.7777777777777778, 0.8888888888888888, 0.814...</td>\n",
       "      <td>{'learn_rate': 0.7605286042879007, 'biasL': -4...</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>0.804353</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.760528604287900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95f40a617531b491c5201fce28c159ffe3a5b5bfce5548...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>QLearning_L2F0_epsi</td>\n",
       "      <td>-136.431122</td>\n",
       "      <td>280.862243</td>\n",
       "      <td>295.343847</td>\n",
       "      <td>0.609988</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8032128514056225, 0.7991967871485943, 0.823...</td>\n",
       "      <td>[0.8148148148148148, 0.8518518518518519, 0.629...</td>\n",
       "      <td>{'learn_rate_rew': 0.6283479581832674, 'learn_...</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.805950</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>{'q_value': [[0.0, 0.0, 0.0, 0.628347958183267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271f44abdc762768297368204bd4b77290c179a47ed91b...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS_CKfull</td>\n",
       "      <td>-364.263340</td>\n",
       "      <td>734.526680</td>\n",
       "      <td>745.387883</td>\n",
       "      <td>0.267190</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.24096385542168675, 0.26506024096385544, 0.2...</td>\n",
       "      <td>[0.7407407407407407, 0.7777777777777778, 0.777...</td>\n",
       "      <td>{'biasL': -0.016164770687993015, 'choice_kerne...</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.085259</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e30c0a8d4b5c92c1ac5238da86b9e3d50ba06197126092...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS_CK1</td>\n",
       "      <td>-438.971813</td>\n",
       "      <td>881.943626</td>\n",
       "      <td>889.184428</td>\n",
       "      <td>0.203828</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25301204819277107, 0.26104417670682734, 0.2...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.703...</td>\n",
       "      <td>{'biasL': -0.14838754925011688, 'choice_kernel...</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.118736</td>\n",
       "      <td>0.246319</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b99fca1dd02c038abe09fe7db5bb5d99cbd7cb58b32984...</td>\n",
       "      <td>706893_2024-05-28_15-15-38.nwb</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>success</td>\n",
       "      <td>706893</td>\n",
       "      <td>WSLS</td>\n",
       "      <td>-1489.395510</td>\n",
       "      <td>2980.791019</td>\n",
       "      <td>2984.411420</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.7951807228915663, 0.8032128514056225, 0.795...</td>\n",
       "      <td>[0.8518518518518519, 0.7777777777777778, 0.851...</td>\n",
       "      <td>{'biasL': -0.9180327782848818, 'loss_count_thr...</td>\n",
       "      <td>0.800337</td>\n",
       "      <td>0.066749</td>\n",
       "      <td>0.800719</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.057571</td>\n",
       "      <td>{'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  _id  \\\n",
       "29  fcab1136a6ede41039e0175a515a881d705c6b24e05e4d...   \n",
       "23  c23c0e97569743def70a4a415f14668eeff0538a48d52f...   \n",
       "15  8674e4424c84df783449a009f3292e0b2a5d1c0709b484...   \n",
       "12  651d38ab922f0b27a7ec0d0f54fba41d0f3fbe6622d6a6...   \n",
       "0   0dfa4cfba459edefacae00fb908de0154c69ebd712c541...   \n",
       "7   495e85c73c51a8c9ab9d7bf629e0631c1738b164d85642...   \n",
       "3   1fcdc55fe3c259d3959fd675807c19eb1eeb7ed7daaf3d...   \n",
       "25  c7181ce080b809b24930d2354ef2506fa55cefd174f07a...   \n",
       "20  b4d4fa61bb40b0aefbb6237df5179a05a4fb77bdd185c0...   \n",
       "5   2f54d18b4e3d56a77ab280228dc00be74433b0feb7b6aa...   \n",
       "10  55441aed29e92a1b81384ca026eb3e8aa25a8e16a132e0...   \n",
       "13  6d01f31a00fd411ce942e792f1d52ef94ce36b5be6a209...   \n",
       "1   17d2ba980515530bcd7f23c993e6d90a0866a4661ffad9...   \n",
       "6   35f4e878433df9d7658ad6a8dee30e1f4db838cbdc5c80...   \n",
       "14  814538c465bd69f4a975b859faa5affa89c51ba5b8d753...   \n",
       "28  f24efb6d46beadbd904bcff639b7b026b4ded5c0e3941b...   \n",
       "16  8fdab4173cbc7f082d1a8ef897b6d66df046f69be39172...   \n",
       "2   1b41a955e5764933bbf980b4d24d63774d07ef0405fdb8...   \n",
       "27  e62bde6a992ccb6e5441389a80406b2a364be9ebd3d67d...   \n",
       "8   4d3e0d0be93ac68f5ff562e42a3840fde0720b6fd06bc1...   \n",
       "18  ae58bf1fd37be24880376827b39db489d7d1b588f78cfc...   \n",
       "24  c2bcc2986491be9d35374ff87ea8e129475016e83d0221...   \n",
       "11  588fb69b6a94ae694002b3d67c2e2cdbc0a580c190da95...   \n",
       "9   4f6cc4f4b82d18698f25eb1b540153ed21727b014b62be...   \n",
       "22  c13e5062bd5bf72c02626b4197cfd5a475b7363a3b099c...   \n",
       "19  b0b66785a43344c0004e64858f0adb13af2d93263f4981...   \n",
       "17  95f40a617531b491c5201fce28c159ffe3a5b5bfce5548...   \n",
       "4   271f44abdc762768297368204bd4b77290c179a47ed91b...   \n",
       "26  e30c0a8d4b5c92c1ac5238da86b9e3d50ba06197126092...   \n",
       "21  b99fca1dd02c038abe09fe7db5bb5d99cbd7cb58b32984...   \n",
       "\n",
       "                          nwb_name session_date   status subject_id  \\\n",
       "29  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "23  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "15  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "12  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "0   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "7   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "3   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "25  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "20  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "5   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "10  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "13  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "1   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "6   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "14  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "28  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "16  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "2   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "27  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "8   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "18  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "24  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "11  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "9   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "22  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "19  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "17  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "4   706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "26  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "21  706893_2024-05-28_15-15-38.nwb   2024-05-28  success     706893   \n",
       "\n",
       "                      agent_alias  log_likelihood          AIC          BIC  \\\n",
       "29  QLearning_L1F0_CKfull_softmax      -37.819717    85.639434   103.741439   \n",
       "23         QLearning_L2F1_softmax      -38.135638    86.271276   104.373280   \n",
       "15  QLearning_L2F0_CKfull_softmax      -37.613139    87.226278   108.948683   \n",
       "12  QLearning_L1F1_CKfull_softmax      -37.646751    87.293502   109.015907   \n",
       "0      QLearning_L2F1_CK1_softmax      -38.134888    88.269775   109.992181   \n",
       "7   QLearning_L2F1_CKfull_softmax      -37.488772    88.977544   114.320351   \n",
       "3      QLearning_L1F1_CK1_softmax      -42.276022    94.552043   112.654048   \n",
       "25         QLearning_L1F1_softmax      -43.390179    94.780358   109.261962   \n",
       "20        QLearning_L1F1_CK1_epsi      -46.225387   102.450774   120.552778   \n",
       "5      QLearning_L1F0_CKfull_epsi      -46.225387   102.450774   120.552778   \n",
       "10     QLearning_L1F0_CK1_softmax      -47.299313   102.598626   117.080230   \n",
       "13     QLearning_L1F1_CKfull_epsi      -46.225387   104.450774   126.173179   \n",
       "1      QLearning_L2F0_CKfull_epsi      -46.225387   104.450774   126.173179   \n",
       "6      QLearning_L2F0_CK1_softmax      -47.308376   104.616753   122.718757   \n",
       "14     QLearning_L2F1_CKfull_epsi      -46.225387   106.450774   131.793580   \n",
       "28         QLearning_L2F0_softmax      -51.400274   110.800547   125.282151   \n",
       "16            QLearning_L1F1_epsi      -55.377576   118.755153   133.236756   \n",
       "2          QLearning_L1F0_softmax      -56.953915   119.907831   130.769033   \n",
       "27            QLearning_L2F1_epsi      -55.377576   120.755153   138.857157   \n",
       "8         QLearning_L1F0_CK1_epsi      -61.091995   130.183991   144.665594   \n",
       "18        QLearning_L2F0_CK1_epsi      -61.091995   132.183991   150.285995   \n",
       "24        QLearning_L2F1_CK1_epsi      -66.540374   145.080749   166.803154   \n",
       "11            LossCounting_CKfull      -73.510103   157.020206   175.122210   \n",
       "9                LossCounting_CK1     -110.705383   229.410767   243.892370   \n",
       "22                   LossCounting     -116.978868   239.957736   250.818939   \n",
       "19            QLearning_L1F0_epsi     -136.431122   278.862243   289.723446   \n",
       "17            QLearning_L2F0_epsi     -136.431122   280.862243   295.343847   \n",
       "4                     WSLS_CKfull     -364.263340   734.526680   745.387883   \n",
       "26                       WSLS_CK1     -438.971813   881.943626   889.184428   \n",
       "21                           WSLS    -1489.395510  2980.791019  2984.411420   \n",
       "\n",
       "         LPT  ...                            prediction_accuracy_fit  \\\n",
       "29  0.871946  ...  [0.9437751004016064, 0.9477911646586346, 0.939...   \n",
       "23  0.870948  ...  [0.9477911646586346, 0.9518072289156626, 0.943...   \n",
       "15  0.872599  ...  [0.9437751004016064, 0.9437751004016064, 0.943...   \n",
       "12  0.872492  ...  [0.9317269076305221, 0.9598393574297188, 0.947...   \n",
       "0   0.870951  ...  [0.9477911646586346, 0.9357429718875502, 0.947...   \n",
       "7   0.872992  ...  [0.9357429718875502, 0.9397590361445783, 0.947...   \n",
       "3   0.857980  ...  [0.9397590361445783, 0.9477911646586346, 0.939...   \n",
       "25  0.854524  ...  [0.9477911646586346, 0.9477911646586346, 0.947...   \n",
       "20  0.845791  ...  [0.9357429718875502, 0.9397590361445783, 0.955...   \n",
       "5   0.845791  ...  [0.9759036144578314, 0.9598393574297188, 0.963...   \n",
       "10  0.842506  ...  [0.9558232931726908, 0.9437751004016064, 0.943...   \n",
       "13  0.845791  ...  [0.963855421686747, 0.9558232931726908, 0.9678...   \n",
       "1   0.845791  ...  [0.9678714859437751, 0.9598393574297188, 0.963...   \n",
       "6   0.842478  ...  [0.9357429718875502, 0.9437751004016064, 0.951...   \n",
       "14  0.845791  ...  [0.9558232931726908, 0.9558232931726908, 0.959...   \n",
       "28  0.830080  ...  [0.9357429718875502, 0.9317269076305221, 0.927...   \n",
       "16  0.818204  ...  [0.9437751004016064, 0.9477911646586346, 0.955...   \n",
       "2   0.813544  ...  [0.891566265060241, 0.8755020080321285, 0.8915...   \n",
       "27  0.818204  ...  [0.9518072289156626, 0.9598393574297188, 0.935...   \n",
       "8   0.801438  ...  [0.9437751004016064, 0.9437751004016064, 0.951...   \n",
       "18  0.801438  ...  [0.9558232931726908, 0.9518072289156626, 0.947...   \n",
       "24  0.785772  ...  [0.9317269076305221, 0.9357429718875502, 0.959...   \n",
       "11  0.766178  ...  [0.8634538152610441, 0.8714859437751004, 0.875...   \n",
       "9   0.669579  ...  [0.8353413654618473, 0.8192771084337349, 0.831...   \n",
       "22  0.654531  ...  [0.8152610441767069, 0.8032128514056225, 0.795...   \n",
       "19  0.609988  ...  [0.8072289156626506, 0.7951807228915663, 0.803...   \n",
       "17  0.609988  ...  [0.8032128514056225, 0.7991967871485943, 0.823...   \n",
       "4   0.267190  ...  [0.24096385542168675, 0.26506024096385544, 0.2...   \n",
       "26  0.203828  ...  [0.25301204819277107, 0.26104417670682734, 0.2...   \n",
       "21  0.004533  ...  [0.7951807228915663, 0.8032128514056225, 0.795...   \n",
       "\n",
       "                   prediction_accuracy_test_bias_only  \\\n",
       "29  [0.7777777777777778, 0.7037037037037037, 0.703...   \n",
       "23  [0.25925925925925924, 0.8518518518518519, 0.74...   \n",
       "15  [0.9259259259259259, 0.7777777777777778, 0.888...   \n",
       "12  [0.8888888888888888, 0.8518518518518519, 0.703...   \n",
       "0   [0.8148148148148148, 0.8148148148148148, 0.851...   \n",
       "7   [0.9259259259259259, 0.8518518518518519, 0.740...   \n",
       "3   [0.18518518518518517, 0.25925925925925924, 0.7...   \n",
       "25  [0.25925925925925924, 0.1111111111111111, 0.29...   \n",
       "20  [0.7037037037037037, 0.7037037037037037, 0.888...   \n",
       "5   [0.9259259259259259, 0.8888888888888888, 0.814...   \n",
       "10  [0.9259259259259259, 0.6296296296296297, 0.777...   \n",
       "13  [0.9259259259259259, 0.7407407407407407, 0.814...   \n",
       "1   [0.9259259259259259, 0.8148148148148148, 0.851...   \n",
       "6   [0.8518518518518519, 0.7777777777777778, 0.777...   \n",
       "14  [0.8888888888888888, 0.9259259259259259, 0.851...   \n",
       "28  [0.7407407407407407, 0.6666666666666666, 0.777...   \n",
       "16  [0.8518518518518519, 0.18518518518518517, 0.70...   \n",
       "2   [0.7037037037037037, 0.8518518518518519, 0.740...   \n",
       "27  [0.7777777777777778, 0.25925925925925924, 0.74...   \n",
       "8   [0.7037037037037037, 0.8148148148148148, 0.888...   \n",
       "18  [0.6666666666666666, 0.7407407407407407, 0.851...   \n",
       "24  [0.7407407407407407, 0.7037037037037037, 0.703...   \n",
       "11  [0.9259259259259259, 0.7037037037037037, 0.740...   \n",
       "9   [0.7777777777777778, 0.8518518518518519, 0.851...   \n",
       "22  [0.7777777777777778, 0.9259259259259259, 0.888...   \n",
       "19  [0.7777777777777778, 0.8888888888888888, 0.814...   \n",
       "17  [0.8148148148148148, 0.8518518518518519, 0.629...   \n",
       "4   [0.7407407407407407, 0.7777777777777778, 0.777...   \n",
       "26  [0.8518518518518519, 0.7777777777777778, 0.703...   \n",
       "21  [0.8518518518518519, 0.7777777777777778, 0.851...   \n",
       "\n",
       "                                               params  \\\n",
       "29  {'learn_rate': 0.23873165801064972, 'choice_ke...   \n",
       "23  {'learn_rate_rew': 0.4596583432690249, 'learn_...   \n",
       "15  {'learn_rate_rew': 0.01662460687527222, 'learn...   \n",
       "12  {'learn_rate': 0.24457199743093422, 'forget_ra...   \n",
       "0   {'learn_rate_rew': 0.460696386602735, 'learn_r...   \n",
       "7   {'learn_rate_rew': 0.016305867407219492, 'lear...   \n",
       "3   {'learn_rate': 0.007641672474704939, 'forget_r...   \n",
       "25  {'learn_rate': 0.006298309291773297, 'forget_r...   \n",
       "20  {'learn_rate': 0.04185042934833261, 'forget_ra...   \n",
       "5   {'learn_rate': 0.21128523786920977, 'choice_ke...   \n",
       "10  {'learn_rate': 0.0037023287546044635, 'choice_...   \n",
       "13  {'learn_rate': 0.3003335824639858, 'forget_rat...   \n",
       "1   {'learn_rate_rew': 0.13964793395391173, 'learn...   \n",
       "6   {'learn_rate_rew': 0.015408089857806765, 'lear...   \n",
       "14  {'learn_rate_rew': 0.24161215238838513, 'learn...   \n",
       "28  {'learn_rate_rew': 0.3041948491659956, 'learn_...   \n",
       "16  {'learn_rate': 0.030955106379390418, 'forget_r...   \n",
       "2   {'learn_rate': 0.0057361265166139385, 'biasL':...   \n",
       "27  {'learn_rate_rew': 0.37999581247450126, 'learn...   \n",
       "8   {'learn_rate': 0.16963313697979332, 'choice_ke...   \n",
       "18  {'learn_rate_rew': 0.1322377703532952, 'learn_...   \n",
       "24  {'learn_rate_rew': 0.22649725287289912, 'learn...   \n",
       "11  {'loss_count_threshold_mean': 10, 'loss_count_...   \n",
       "9   {'loss_count_threshold_mean': 5.30395345038595...   \n",
       "22  {'loss_count_threshold_mean': 10, 'loss_count_...   \n",
       "19  {'learn_rate': 0.7605286042879007, 'biasL': -4...   \n",
       "17  {'learn_rate_rew': 0.6283479581832674, 'learn_...   \n",
       "4   {'biasL': -0.016164770687993015, 'choice_kerne...   \n",
       "26  {'biasL': -0.14838754925011688, 'choice_kernel...   \n",
       "21  {'biasL': -0.9180327782848818, 'loss_count_thr...   \n",
       "\n",
       "    prediction_accuracy_10-CV_test  prediction_accuracy_10-CV_test_std  \\\n",
       "29                        0.939731                            0.039250   \n",
       "23                        0.942088                            0.037457   \n",
       "15                        0.942761                            0.035410   \n",
       "12                        0.937037                            0.043979   \n",
       "0                         0.935354                            0.050456   \n",
       "7                         0.942761                            0.045573   \n",
       "3                         0.938384                            0.037039   \n",
       "25                        0.938384                            0.033129   \n",
       "20                        0.914478                            0.041270   \n",
       "5                         0.952525                            0.052690   \n",
       "10                        0.937710                            0.037742   \n",
       "13                        0.946465                            0.035392   \n",
       "1                         0.939057                            0.030876   \n",
       "6                         0.937710                            0.060160   \n",
       "14                        0.927946                            0.067461   \n",
       "28                        0.923569                            0.048421   \n",
       "16                        0.929630                            0.048148   \n",
       "2                         0.884848                            0.053763   \n",
       "27                        0.912458                            0.050796   \n",
       "8                         0.924242                            0.029130   \n",
       "18                        0.923569                            0.042377   \n",
       "24                        0.931650                            0.036977   \n",
       "11                        0.865657                            0.072331   \n",
       "9                         0.818855                            0.050903   \n",
       "22                        0.804040                            0.070431   \n",
       "19                        0.804714                            0.052096   \n",
       "17                        0.804040                            0.074224   \n",
       "4                         0.247811                            0.070678   \n",
       "26                        0.242424                            0.118736   \n",
       "21                        0.800337                            0.066749   \n",
       "\n",
       "   prediction_accuracy_10-CV_fit prediction_accuracy_10-CV_fit_std  \\\n",
       "29                      0.942843                          0.006830   \n",
       "23                      0.944439                          0.003985   \n",
       "15                      0.948495                          0.007857   \n",
       "12                      0.944811                          0.008522   \n",
       "0                       0.943656                          0.006077   \n",
       "7                       0.946457                          0.007184   \n",
       "3                       0.943626                          0.005516   \n",
       "25                      0.944449                          0.003403   \n",
       "20                      0.948094                          0.008184   \n",
       "5                       0.960142                          0.007514   \n",
       "10                      0.940815                          0.006279   \n",
       "13                      0.959740                          0.004027   \n",
       "1                       0.961357                          0.003632   \n",
       "6                       0.940012                          0.006104   \n",
       "14                      0.958545                          0.003928   \n",
       "28                      0.930755                          0.017761   \n",
       "16                      0.951267                          0.006000   \n",
       "2                       0.884873                          0.006558   \n",
       "27                      0.950082                          0.006253   \n",
       "8                       0.944851                          0.005039   \n",
       "18                      0.948465                          0.004721   \n",
       "24                      0.936799                          0.008586   \n",
       "11                      0.875998                          0.010035   \n",
       "9                       0.824865                          0.008674   \n",
       "22                      0.804343                          0.007646   \n",
       "19                      0.804353                          0.005665   \n",
       "17                      0.805950                          0.009537   \n",
       "4                       0.246398                          0.007845   \n",
       "26                      0.246319                          0.013678   \n",
       "21                      0.800719                          0.007252   \n",
       "\n",
       "   prediction_accuracy_10-CV_test_bias_only  \\\n",
       "29                                 0.805387   \n",
       "23                                 0.757239   \n",
       "15                                 0.804040   \n",
       "12                                 0.806734   \n",
       "0                                  0.804040   \n",
       "7                                  0.803367   \n",
       "3                                  0.301684   \n",
       "25                                 0.195960   \n",
       "20                                 0.558249   \n",
       "5                                  0.735017   \n",
       "10                                 0.804714   \n",
       "13                                 0.806061   \n",
       "1                                  0.743771   \n",
       "6                                  0.802694   \n",
       "14                                 0.750505   \n",
       "28                                 0.805387   \n",
       "16                                 0.357239   \n",
       "2                                  0.804714   \n",
       "27                                 0.387879   \n",
       "8                                  0.806734   \n",
       "18                                 0.804040   \n",
       "24                                 0.756566   \n",
       "11                                 0.802694   \n",
       "9                                  0.805387   \n",
       "22                                 0.804040   \n",
       "19                                 0.804714   \n",
       "17                                 0.804040   \n",
       "4                                  0.801347   \n",
       "26                                 0.804714   \n",
       "21                                 0.804040   \n",
       "\n",
       "   prediction_accuracy_10-CV_test_bias_only_std  \\\n",
       "29                                     0.067016   \n",
       "23                                     0.180010   \n",
       "15                                     0.077832   \n",
       "12                                     0.098443   \n",
       "0                                      0.066421   \n",
       "7                                      0.070147   \n",
       "3                                      0.237598   \n",
       "25                                     0.057571   \n",
       "20                                     0.304950   \n",
       "5                                      0.214037   \n",
       "10                                     0.079250   \n",
       "13                                     0.056204   \n",
       "1                                      0.197143   \n",
       "6                                      0.056062   \n",
       "14                                     0.190457   \n",
       "28                                     0.067016   \n",
       "16                                     0.279053   \n",
       "2                                      0.063920   \n",
       "27                                     0.296533   \n",
       "8                                      0.072811   \n",
       "18                                     0.084589   \n",
       "24                                     0.183994   \n",
       "11                                     0.069203   \n",
       "9                                      0.058256   \n",
       "22                                     0.070431   \n",
       "19                                     0.052096   \n",
       "17                                     0.074224   \n",
       "4                                      0.085259   \n",
       "26                                     0.063920   \n",
       "21                                     0.057571   \n",
       "\n",
       "                                     latent_variables  \n",
       "29  {'q_value': [[0.0, 0.0, 0.0, 0.238731658010649...  \n",
       "23  {'q_value': [[0.0, 0.0, 0.0, 0.459658343269024...  \n",
       "15  {'q_value': [[0.0, 0.0, 0.0, 0.016624606875272...  \n",
       "12  {'q_value': [[0.0, 0.0, 0.0, 0.244571997430934...  \n",
       "0   {'q_value': [[0.0, 0.0, 0.0, 0.460696386602735...  \n",
       "7   {'q_value': [[0.0, 0.0, 0.0, 0.016305867407219...  \n",
       "3   {'q_value': [[0.0, 0.0, 0.0, 0.007641672474704...  \n",
       "25  {'q_value': [[0.0, 0.0, 0.0, 0.006298309291773...  \n",
       "20  {'q_value': [[0.0, 0.0, 0.0, 0.041850429348332...  \n",
       "5   {'q_value': [[0.0, 0.0, 0.0, 0.211285237869209...  \n",
       "10  {'q_value': [[0.0, 0.0, 0.0, 0.003702328754604...  \n",
       "13  {'q_value': [[0.0, 0.0, 0.0, 0.300333582463985...  \n",
       "1   {'q_value': [[0.0, 0.0, 0.0, 0.139647933953911...  \n",
       "6   {'q_value': [[0.0, 0.0, 0.0, 0.015408089857806...  \n",
       "14  {'q_value': [[0.0, 0.0, 0.0, 0.241612152388385...  \n",
       "28  {'q_value': [[0.0, 0.0, 0.0, 0.304194849165995...  \n",
       "16  {'q_value': [[0.0, 0.0, 0.0, 0.030955106379390...  \n",
       "2   {'q_value': [[0.0, 0.0, 0.0, 0.005736126516613...  \n",
       "27  {'q_value': [[0.0, 0.0, 0.0, 0.379995812474501...  \n",
       "8   {'q_value': [[0.0, 0.0, 0.0, 0.169633136979793...  \n",
       "18  {'q_value': [[0.0, 0.0, 0.0, 0.132237770353295...  \n",
       "24  {'q_value': [[0.0, 0.0, 0.0, 0.226497252872899...  \n",
       "11  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "9   {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "22  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "19  {'q_value': [[0.0, 0.0, 0.0, 0.760528604287900...  \n",
       "17  {'q_value': [[0.0, 0.0, 0.0, 0.628347958183267...  \n",
       "4   {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "26  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "21  {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...  \n",
       "\n",
       "[30 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\n",
    "    by=[\"AIC\", \"prediction_accuracy_10-CV_test\"],\n",
    "    ascending=[True, False],\n",
    "    inplace=True,\n",
    ")\n",
    "df #[[\"agent_alias\", \"AIC\", \"prediction_accuracy_10-CV_test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca1dcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    {'q_value': [[0.0, 0.0, 0.0, 0.238731658010649...\n",
       "23    {'q_value': [[0.0, 0.0, 0.0, 0.459658343269024...\n",
       "15    {'q_value': [[0.0, 0.0, 0.0, 0.016624606875272...\n",
       "12    {'q_value': [[0.0, 0.0, 0.0, 0.244571997430934...\n",
       "0     {'q_value': [[0.0, 0.0, 0.0, 0.460696386602735...\n",
       "7     {'q_value': [[0.0, 0.0, 0.0, 0.016305867407219...\n",
       "3     {'q_value': [[0.0, 0.0, 0.0, 0.007641672474704...\n",
       "25    {'q_value': [[0.0, 0.0, 0.0, 0.006298309291773...\n",
       "20    {'q_value': [[0.0, 0.0, 0.0, 0.041850429348332...\n",
       "5     {'q_value': [[0.0, 0.0, 0.0, 0.211285237869209...\n",
       "10    {'q_value': [[0.0, 0.0, 0.0, 0.003702328754604...\n",
       "13    {'q_value': [[0.0, 0.0, 0.0, 0.300333582463985...\n",
       "1     {'q_value': [[0.0, 0.0, 0.0, 0.139647933953911...\n",
       "6     {'q_value': [[0.0, 0.0, 0.0, 0.015408089857806...\n",
       "14    {'q_value': [[0.0, 0.0, 0.0, 0.241612152388385...\n",
       "28    {'q_value': [[0.0, 0.0, 0.0, 0.304194849165995...\n",
       "16    {'q_value': [[0.0, 0.0, 0.0, 0.030955106379390...\n",
       "2     {'q_value': [[0.0, 0.0, 0.0, 0.005736126516613...\n",
       "27    {'q_value': [[0.0, 0.0, 0.0, 0.379995812474501...\n",
       "8     {'q_value': [[0.0, 0.0, 0.0, 0.169633136979793...\n",
       "18    {'q_value': [[0.0, 0.0, 0.0, 0.132237770353295...\n",
       "24    {'q_value': [[0.0, 0.0, 0.0, 0.226497252872899...\n",
       "11    {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "9     {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "22    {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "19    {'q_value': [[0.0, 0.0, 0.0, 0.760528604287900...\n",
       "17    {'q_value': [[0.0, 0.0, 0.0, 0.628347958183267...\n",
       "4     {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "26    {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "21    {'loss_count': [0.0, 1.0, 2.0, 0.0, 1.0, 2.0, ...\n",
       "Name: latent_variables, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['latent_variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3295b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = df['latent_variables'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a190dec",
   "metadata": {},
   "source": [
    "# make a dataframe from latens of the selected model for trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6188e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dir = '/local1/video-analysis/scratch/706893_2024-05-28_15-15-38/results/xinxin/coupled-baiting_ear/706893/2024-05-28/dfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the target directory path\n",
    "rl_models_dir = \"/local1/video-analysis/scratch/706893_2024-05-28_15-15-38/rl_models\"\n",
    "df_original = pd.read_csv(os.path.join(dfs_dir, \"df_original.csv\"))\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(rl_models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c833fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>animal_response</th>\n",
       "      <th>rewarded_historyL</th>\n",
       "      <th>rewarded_historyR</th>\n",
       "      <th>delay_start_time</th>\n",
       "      <th>goCue_start_time</th>\n",
       "      <th>reward_outcome_time</th>\n",
       "      <th>bait_left</th>\n",
       "      <th>bait_right</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_train_curriculum_version</th>\n",
       "      <th>auto_train_curriculum_schema_version</th>\n",
       "      <th>auto_train_stage</th>\n",
       "      <th>auto_train_stage_overridden</th>\n",
       "      <th>lickspout_position_x</th>\n",
       "      <th>lickspout_position_y</th>\n",
       "      <th>lickspout_position_z</th>\n",
       "      <th>reward_size_left</th>\n",
       "      <th>reward_size_right</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.574702e+06</td>\n",
       "      <td>6.574709e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.574705e+06</td>\n",
       "      <td>6.574707e+06</td>\n",
       "      <td>6.574707e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.574709e+06</td>\n",
       "      <td>6.574716e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.574711e+06</td>\n",
       "      <td>6.574713e+06</td>\n",
       "      <td>6.574714e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.574716e+06</td>\n",
       "      <td>6.574750e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.574723e+06</td>\n",
       "      <td>6.574748e+06</td>\n",
       "      <td>6.574748e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.574750e+06</td>\n",
       "      <td>6.574758e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.574753e+06</td>\n",
       "      <td>6.574755e+06</td>\n",
       "      <td>6.574756e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.574758e+06</td>\n",
       "      <td>6.574764e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.574760e+06</td>\n",
       "      <td>6.574762e+06</td>\n",
       "      <td>6.574762e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>6.578160e+06</td>\n",
       "      <td>6.578181e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6.578163e+06</td>\n",
       "      <td>6.578179e+06</td>\n",
       "      <td>6.578179e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>6.578181e+06</td>\n",
       "      <td>6.578192e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6.578188e+06</td>\n",
       "      <td>6.578190e+06</td>\n",
       "      <td>6.578190e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>6.578192e+06</td>\n",
       "      <td>6.578210e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.578196e+06</td>\n",
       "      <td>6.578208e+06</td>\n",
       "      <td>6.578208e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.5</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>6.578210e+06</td>\n",
       "      <td>6.578217e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6.578213e+06</td>\n",
       "      <td>6.578215e+06</td>\n",
       "      <td>6.578215e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>6.578217e+06</td>\n",
       "      <td>6.578242e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.578221e+06</td>\n",
       "      <td>6.578239e+06</td>\n",
       "      <td>6.578240e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_time     stop_time  animal_response  rewarded_historyL  \\\n",
       "0    6.574702e+06  6.574709e+06              1.0              False   \n",
       "1    6.574709e+06  6.574716e+06              1.0              False   \n",
       "2    6.574716e+06  6.574750e+06              0.0               True   \n",
       "3    6.574750e+06  6.574758e+06              0.0              False   \n",
       "4    6.574758e+06  6.574764e+06              0.0              False   \n",
       "..            ...           ...              ...                ...   \n",
       "272  6.578160e+06  6.578181e+06              1.0              False   \n",
       "273  6.578181e+06  6.578192e+06              1.0              False   \n",
       "274  6.578192e+06  6.578210e+06              1.0              False   \n",
       "275  6.578210e+06  6.578217e+06              1.0              False   \n",
       "276  6.578217e+06  6.578242e+06              1.0              False   \n",
       "\n",
       "     rewarded_historyR  delay_start_time  goCue_start_time  \\\n",
       "0                False      6.574705e+06      6.574707e+06   \n",
       "1                False      6.574711e+06      6.574713e+06   \n",
       "2                False      6.574723e+06      6.574748e+06   \n",
       "3                False      6.574753e+06      6.574755e+06   \n",
       "4                False      6.574760e+06      6.574762e+06   \n",
       "..                 ...               ...               ...   \n",
       "272               True      6.578163e+06      6.578179e+06   \n",
       "273               True      6.578188e+06      6.578190e+06   \n",
       "274              False      6.578196e+06      6.578208e+06   \n",
       "275               True      6.578213e+06      6.578215e+06   \n",
       "276              False      6.578221e+06      6.578239e+06   \n",
       "\n",
       "     reward_outcome_time  bait_left  bait_right  ...  \\\n",
       "0           6.574707e+06      False       False  ...   \n",
       "1           6.574714e+06      False       False  ...   \n",
       "2           6.574748e+06       True       False  ...   \n",
       "3           6.574756e+06      False       False  ...   \n",
       "4           6.574762e+06      False       False  ...   \n",
       "..                   ...        ...         ...  ...   \n",
       "272         6.578179e+06       True        True  ...   \n",
       "273         6.578190e+06       True        True  ...   \n",
       "274         6.578208e+06       True       False  ...   \n",
       "275         6.578215e+06       True        True  ...   \n",
       "276         6.578240e+06       True       False  ...   \n",
       "\n",
       "     auto_train_curriculum_version  auto_train_curriculum_schema_version  \\\n",
       "0                              NaN                                   NaN   \n",
       "1                              NaN                                   NaN   \n",
       "2                              NaN                                   NaN   \n",
       "3                              NaN                                   NaN   \n",
       "4                              NaN                                   NaN   \n",
       "..                             ...                                   ...   \n",
       "272                            NaN                                   NaN   \n",
       "273                            NaN                                   NaN   \n",
       "274                            NaN                                   NaN   \n",
       "275                            NaN                                   NaN   \n",
       "276                            NaN                                   NaN   \n",
       "\n",
       "     auto_train_stage  auto_train_stage_overridden  lickspout_position_x  \\\n",
       "0                 NaN                          NaN                4652.0   \n",
       "1                 NaN                          NaN                4652.0   \n",
       "2                 NaN                          NaN                4651.5   \n",
       "3                 NaN                          NaN                4652.0   \n",
       "4                 NaN                          NaN                4652.0   \n",
       "..                ...                          ...                   ...   \n",
       "272               NaN                          NaN                4652.0   \n",
       "273               NaN                          NaN                4652.0   \n",
       "274               NaN                          NaN                4652.5   \n",
       "275               NaN                          NaN                4652.0   \n",
       "276               NaN                          NaN                4652.0   \n",
       "\n",
       "     lickspout_position_y  lickspout_position_z  reward_size_left  \\\n",
       "0                 14391.0                9579.5               3.0   \n",
       "1                 14391.0                9579.5               3.0   \n",
       "2                 14391.0                9580.0               3.0   \n",
       "3                 14391.0                9580.0               3.0   \n",
       "4                 14390.5                9580.0               3.0   \n",
       "..                    ...                   ...               ...   \n",
       "272               14390.5                9579.5               3.0   \n",
       "273               14391.0                9580.0               3.0   \n",
       "274               14390.5                9579.5               3.0   \n",
       "275               14391.0                9579.5               3.0   \n",
       "276               14390.5                9579.5               3.0   \n",
       "\n",
       "     reward_size_right  Trial  \n",
       "0                  3.0      1  \n",
       "1                  3.0      2  \n",
       "2                  3.0      3  \n",
       "3                  3.0      4  \n",
       "4                  3.0      5  \n",
       "..                 ...    ...  \n",
       "272                3.0    273  \n",
       "273                3.0    274  \n",
       "274                3.0    275  \n",
       "275                3.0    276  \n",
       "276                3.0    277  \n",
       "\n",
       "[277 rows x 68 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bb5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_original) # num of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bd5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>animal_response</th>\n",
       "      <th>rewarded_historyL</th>\n",
       "      <th>rewarded_historyR</th>\n",
       "      <th>delay_start_time</th>\n",
       "      <th>goCue_start_time</th>\n",
       "      <th>reward_outcome_time</th>\n",
       "      <th>bait_left</th>\n",
       "      <th>bait_right</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_train_curriculum_version</th>\n",
       "      <th>auto_train_curriculum_schema_version</th>\n",
       "      <th>auto_train_stage</th>\n",
       "      <th>auto_train_stage_overridden</th>\n",
       "      <th>lickspout_position_x</th>\n",
       "      <th>lickspout_position_y</th>\n",
       "      <th>lickspout_position_z</th>\n",
       "      <th>reward_size_left</th>\n",
       "      <th>reward_size_right</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.575077e+06</td>\n",
       "      <td>6.575093e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575082e+06</td>\n",
       "      <td>6.575091e+06</td>\n",
       "      <td>6.575091e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.575093e+06</td>\n",
       "      <td>6.575100e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575096e+06</td>\n",
       "      <td>6.575098e+06</td>\n",
       "      <td>6.575098e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6.575100e+06</td>\n",
       "      <td>6.575108e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575104e+06</td>\n",
       "      <td>6.575106e+06</td>\n",
       "      <td>6.575106e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6.575108e+06</td>\n",
       "      <td>6.575120e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6.575116e+06</td>\n",
       "      <td>6.575118e+06</td>\n",
       "      <td>6.575118e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.575120e+06</td>\n",
       "      <td>6.575132e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575123e+06</td>\n",
       "      <td>6.575130e+06</td>\n",
       "      <td>6.575130e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.575132e+06</td>\n",
       "      <td>6.575139e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575134e+06</td>\n",
       "      <td>6.575136e+06</td>\n",
       "      <td>6.575137e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.575139e+06</td>\n",
       "      <td>6.575149e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575145e+06</td>\n",
       "      <td>6.575147e+06</td>\n",
       "      <td>6.575147e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6.575149e+06</td>\n",
       "      <td>6.575161e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6.575156e+06</td>\n",
       "      <td>6.575158e+06</td>\n",
       "      <td>6.575159e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4651.5</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.575161e+06</td>\n",
       "      <td>6.575176e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575171e+06</td>\n",
       "      <td>6.575173e+06</td>\n",
       "      <td>6.575174e+06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.575176e+06</td>\n",
       "      <td>6.575183e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.575179e+06</td>\n",
       "      <td>6.575181e+06</td>\n",
       "      <td>6.575181e+06</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>14390.5</td>\n",
       "      <td>9579.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time     stop_time  animal_response  rewarded_historyL  \\\n",
       "35  6.575077e+06  6.575093e+06              0.0              False   \n",
       "36  6.575093e+06  6.575100e+06              0.0              False   \n",
       "37  6.575100e+06  6.575108e+06              0.0              False   \n",
       "38  6.575108e+06  6.575120e+06              1.0              False   \n",
       "39  6.575120e+06  6.575132e+06              1.0              False   \n",
       "40  6.575132e+06  6.575139e+06              0.0              False   \n",
       "41  6.575139e+06  6.575149e+06              0.0              False   \n",
       "42  6.575149e+06  6.575161e+06              1.0              False   \n",
       "43  6.575161e+06  6.575176e+06              2.0              False   \n",
       "44  6.575176e+06  6.575183e+06              0.0               True   \n",
       "\n",
       "    rewarded_historyR  delay_start_time  goCue_start_time  \\\n",
       "35              False      6.575082e+06      6.575091e+06   \n",
       "36              False      6.575096e+06      6.575098e+06   \n",
       "37              False      6.575104e+06      6.575106e+06   \n",
       "38               True      6.575116e+06      6.575118e+06   \n",
       "39              False      6.575123e+06      6.575130e+06   \n",
       "40              False      6.575134e+06      6.575136e+06   \n",
       "41              False      6.575145e+06      6.575147e+06   \n",
       "42               True      6.575156e+06      6.575158e+06   \n",
       "43              False      6.575171e+06      6.575173e+06   \n",
       "44              False      6.575179e+06      6.575181e+06   \n",
       "\n",
       "    reward_outcome_time  bait_left  bait_right  ...  \\\n",
       "35         6.575091e+06      False        True  ...   \n",
       "36         6.575098e+06      False        True  ...   \n",
       "37         6.575106e+06      False        True  ...   \n",
       "38         6.575118e+06      False        True  ...   \n",
       "39         6.575130e+06      False       False  ...   \n",
       "40         6.575137e+06      False        True  ...   \n",
       "41         6.575147e+06      False        True  ...   \n",
       "42         6.575159e+06      False        True  ...   \n",
       "43         6.575174e+06      False       False  ...   \n",
       "44         6.575181e+06       True       False  ...   \n",
       "\n",
       "    auto_train_curriculum_version  auto_train_curriculum_schema_version  \\\n",
       "35                            NaN                                   NaN   \n",
       "36                            NaN                                   NaN   \n",
       "37                            NaN                                   NaN   \n",
       "38                            NaN                                   NaN   \n",
       "39                            NaN                                   NaN   \n",
       "40                            NaN                                   NaN   \n",
       "41                            NaN                                   NaN   \n",
       "42                            NaN                                   NaN   \n",
       "43                            NaN                                   NaN   \n",
       "44                            NaN                                   NaN   \n",
       "\n",
       "    auto_train_stage  auto_train_stage_overridden  lickspout_position_x  \\\n",
       "35               NaN                          NaN                4651.5   \n",
       "36               NaN                          NaN                4652.0   \n",
       "37               NaN                          NaN                4652.0   \n",
       "38               NaN                          NaN                4651.5   \n",
       "39               NaN                          NaN                4652.0   \n",
       "40               NaN                          NaN                4651.5   \n",
       "41               NaN                          NaN                4651.5   \n",
       "42               NaN                          NaN                4651.5   \n",
       "43               NaN                          NaN                4652.0   \n",
       "44               NaN                          NaN                4652.0   \n",
       "\n",
       "    lickspout_position_y  lickspout_position_z  reward_size_left  \\\n",
       "35               14391.0                9580.0               3.0   \n",
       "36               14390.5                9580.0               3.0   \n",
       "37               14391.0                9579.5               3.0   \n",
       "38               14390.5                9579.5               3.0   \n",
       "39               14390.5                9579.5               3.0   \n",
       "40               14390.5                9580.0               3.0   \n",
       "41               14391.0                9579.5               3.0   \n",
       "42               14390.5                9580.0               3.0   \n",
       "43               14390.5                9580.0               3.0   \n",
       "44               14390.5                9579.5               3.0   \n",
       "\n",
       "    reward_size_right  Trial  \n",
       "35                3.0     36  \n",
       "36                3.0     37  \n",
       "37                3.0     38  \n",
       "38                3.0     39  \n",
       "39                3.0     40  \n",
       "40                3.0     41  \n",
       "41                3.0     42  \n",
       "42                3.0     43  \n",
       "43                3.0     44  \n",
       "44                3.0     45  \n",
       "\n",
       "[10 rows x 68 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original[35:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6467928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RL fitting latents saved to: /local1/video-analysis/scratch/706893_2024-05-28_15-15-38/rl_models/rl_fitting_latents.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load df_original\n",
    "df_original = pd.read_csv(os.path.join(dfs_dir, \"df_original.csv\"))\n",
    "trial_ids = df_original[\"Trial\"]\n",
    "ignored_mask = df_original[\"animal_response\"] == 2\n",
    "valid_mask = ~ignored_mask\n",
    "n_trials_total = len(df_original)\n",
    "n_valid_trials = valid_mask.sum()\n",
    "\n",
    "# Output directory\n",
    "rl_models_dir = \"/local1/video-analysis/scratch/706893_2024-05-28_15-15-38/rl_models\"\n",
    "os.makedirs(rl_models_dir, exist_ok=True)\n",
    "\n",
    "# Convert model outputs to arrays\n",
    "q_value = np.array(selected_model['q_value'])             # shape (2, N+1)\n",
    "choice_kernel = np.array(selected_model['choice_kernel'])  # shape (2, N+1)\n",
    "choice_prob = np.array(selected_model['choice_prob'])     # shape (2, N)\n",
    "rpe = np.array(selected_model['rpe'])                     # shape (N,)\n",
    "\n",
    "# Initialize padded arrays with NaNs\n",
    "q_value_before = np.full((2, n_trials_total), np.nan)\n",
    "q_value_after = np.full((2, n_trials_total), np.nan)\n",
    "kernel_before = np.full((2, n_trials_total), np.nan)\n",
    "kernel_after = np.full((2, n_trials_total), np.nan)\n",
    "choice_prob_padded = np.full((2, n_trials_total), np.nan)\n",
    "rpe_padded = np.full(n_trials_total, np.nan)\n",
    "\n",
    "# Fill values at valid trial positions\n",
    "q_value_before[:, valid_mask] = q_value[:, :-1]\n",
    "q_value_after[:, valid_mask] = q_value[:, 1:]\n",
    "kernel_before[:, valid_mask] = choice_kernel[:, :-1]\n",
    "kernel_after[:, valid_mask] = choice_kernel[:, 1:]\n",
    "choice_prob_padded[:, valid_mask] = choice_prob\n",
    "rpe_padded[valid_mask] = rpe\n",
    "\n",
    "# Build DataFrame\n",
    "rl_fitting_latents = pd.DataFrame({\n",
    "    \"Trial\": trial_ids,\n",
    "    \"q_value_left_before_update\": q_value_before[0],\n",
    "    \"q_value_right_before_update\": q_value_before[1],\n",
    "    \"q_value_left_after_update\": q_value_after[0],\n",
    "    \"q_value_right_after_update\": q_value_after[1],\n",
    "    \"choice_kernel_left_before_update\": kernel_before[0],\n",
    "    \"choice_kernel_right_before_update\": kernel_before[1],\n",
    "    \"choice_kernel_left_after_update\": kernel_after[0],\n",
    "    \"choice_kernel_right_after_update\": kernel_after[1],\n",
    "    \"choice_prob_left\": choice_prob_padded[0],  \n",
    "    \"choice_prob_right\": choice_prob_padded[1],\n",
    "    \"rpe\": rpe_padded\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "save_path = os.path.join(rl_models_dir, \"rl_fitting_latents.csv\")\n",
    "rl_fitting_latents.to_csv(save_path, index=False)\n",
    "print(f\"✅ RL fitting latents saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a3d3ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 277)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(choice_prob_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aee3d67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>q_value_left_before_update</th>\n",
       "      <th>q_value_right_before_update</th>\n",
       "      <th>q_value_left_after_update</th>\n",
       "      <th>q_value_right_after_update</th>\n",
       "      <th>choice_kernel_left_before_update</th>\n",
       "      <th>choice_kernel_right_before_update</th>\n",
       "      <th>choice_kernel_left_after_update</th>\n",
       "      <th>choice_kernel_right_after_update</th>\n",
       "      <th>choice_prob_left</th>\n",
       "      <th>choice_prob_right</th>\n",
       "      <th>rpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355051</td>\n",
       "      <td>0.644949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.352274</td>\n",
       "      <td>0.647726</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352274</td>\n",
       "      <td>0.647726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925296</td>\n",
       "      <td>0.074704</td>\n",
       "      <td>-0.460696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.458329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924187</td>\n",
       "      <td>0.075813</td>\n",
       "      <td>-0.458329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>273</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.009921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>274</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.997115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.999309</td>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>275</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.997115</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>-0.997115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.008010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>277</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.990564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>-0.995680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Trial  q_value_left_before_update  q_value_right_before_update  \\\n",
       "0        1                    0.000000                     0.000000   \n",
       "1        2                    0.000000                     0.000000   \n",
       "2        3                    0.000000                     0.000000   \n",
       "3        4                    0.460696                     0.000000   \n",
       "4        5                    0.458329                     0.000000   \n",
       "..     ...                         ...                          ...   \n",
       "272    273                    0.004222                     0.990079   \n",
       "273    274                    0.004107                     0.994650   \n",
       "274    275                    0.003994                     0.997115   \n",
       "275    276                    0.003884                     0.991990   \n",
       "276    277                    0.003778                     0.995680   \n",
       "\n",
       "     q_value_left_after_update  q_value_right_after_update  \\\n",
       "0                     0.000000                    0.000000   \n",
       "1                     0.000000                    0.000000   \n",
       "2                     0.460696                    0.000000   \n",
       "3                     0.458329                    0.000000   \n",
       "4                     0.455974                    0.000000   \n",
       "..                         ...                         ...   \n",
       "272                   0.004107                    0.994650   \n",
       "273                   0.003994                    0.997115   \n",
       "274                   0.003884                    0.991990   \n",
       "275                   0.003778                    0.995680   \n",
       "276                   0.003674                    0.990564   \n",
       "\n",
       "     choice_kernel_left_before_update  choice_kernel_right_before_update  \\\n",
       "0                                 0.0                                0.0   \n",
       "1                                 0.0                                1.0   \n",
       "2                                 0.0                                1.0   \n",
       "3                                 1.0                                0.0   \n",
       "4                                 1.0                                0.0   \n",
       "..                                ...                                ...   \n",
       "272                               0.0                                1.0   \n",
       "273                               0.0                                1.0   \n",
       "274                               0.0                                1.0   \n",
       "275                               0.0                                1.0   \n",
       "276                               0.0                                1.0   \n",
       "\n",
       "     choice_kernel_left_after_update  choice_kernel_right_after_update  \\\n",
       "0                                0.0                               1.0   \n",
       "1                                0.0                               1.0   \n",
       "2                                1.0                               0.0   \n",
       "3                                1.0                               0.0   \n",
       "4                                1.0                               0.0   \n",
       "..                               ...                               ...   \n",
       "272                              0.0                               1.0   \n",
       "273                              0.0                               1.0   \n",
       "274                              0.0                               1.0   \n",
       "275                              0.0                               1.0   \n",
       "276                              0.0                               1.0   \n",
       "\n",
       "     choice_prob_left  choice_prob_right       rpe  \n",
       "0            0.355051           0.644949  0.000000  \n",
       "1            0.352274           0.647726  0.000000  \n",
       "2            0.352274           0.647726  1.000000  \n",
       "3            0.925296           0.074704 -0.460696  \n",
       "4            0.924187           0.075813 -0.458329  \n",
       "..                ...                ...       ...  \n",
       "272          0.000713           0.999287  0.009921  \n",
       "273          0.000691           0.999309  0.005350  \n",
       "274          0.000679           0.999321 -0.997115  \n",
       "275          0.000702           0.999298  0.008010  \n",
       "276          0.000684           0.999316 -0.995680  \n",
       "\n",
       "[277 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_fitting_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2095bf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q_value', 'choice_kernel', 'choice_prob', 'rpe'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['latent_variables'][0].keys()\n",
    "selected_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc557f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 277)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.shape(df['latent_variables'][0]['q_value'])\n",
    "np.shape(selected_model['q_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92da4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.460696386602735,\n",
       "  0.4583288655576522,\n",
       "  0.45597351121511337,\n",
       "  0.45363026105037313,\n",
       "  0.45129905286000094,\n",
       "  0.44897982476023,\n",
       "  0.4466725151853146,\n",
       "  0.4443770628858955,\n",
       "  0.4420934069273745,\n",
       "  0.43982148668829635,\n",
       "  0.43756124185873996,\n",
       "  0.4353126124387171,\n",
       "  0.43307553873657983,\n",
       "  0.4308499613674359,\n",
       "  0.4190332383948545,\n",
       "  0.6866825262026376,\n",
       "  0.6831536612508982,\n",
       "  0.8291236246209155,\n",
       "  0.8248627541488446,\n",
       "  0.9055478504720267,\n",
       "  0.900894235519386,\n",
       "  0.8962645355173645,\n",
       "  0.944055089167071,\n",
       "  0.9392035853213334,\n",
       "  0.9343770133782309,\n",
       "  0.9646092861929595,\n",
       "  0.9809136601631546,\n",
       "  0.9758727399359073,\n",
       "  0.9708577250230311,\n",
       "  0.9658684822969854,\n",
       "  0.9609048793143725,\n",
       "  0.9559667843124222,\n",
       "  0.9510540662054937,\n",
       "  0.9461665945815959,\n",
       "  0.9413042396989258,\n",
       "  0.9364668724824241,\n",
       "  0.9107828279254668,\n",
       "  0.8858032078005827,\n",
       "  0.8812510606658188,\n",
       "  0.8767223070380483,\n",
       "  0.8526768490942424,\n",
       "  0.9205480923794543,\n",
       "  0.8953006448548867,\n",
       "  0.8906996903433898,\n",
       "  0.8662708811608449,\n",
       "  0.9278794029936114,\n",
       "  0.9231110260803785,\n",
       "  0.9585334985347401,\n",
       "  0.9536075900705291,\n",
       "  0.9487069958746611,\n",
       "  0.9438315858569841,\n",
       "  0.9389812305958799,\n",
       "  0.9132282258997915,\n",
       "  0.9085351414592447,\n",
       "  0.903866174803214,\n",
       "  0.8992212019902832,\n",
       "  0.8745586772420705,\n",
       "  0.8505725601737589,\n",
       "  0.8272442992642006,\n",
       "  0.8229930866545787,\n",
       "  0.8187637210479138,\n",
       "  0.8145560901723481,\n",
       "  0.8103700823329891,\n",
       "  0.7881444362222066,\n",
       "  0.7665283626460119,\n",
       "  0.7455051431399303,\n",
       "  0.7250585177690941,\n",
       "  0.7051726725523619,\n",
       "  0.685832227231352,\n",
       "  0.6670222233749284,\n",
       "  0.64872811280994,\n",
       "  0.6309357463692638,\n",
       "  0.613631362948451,\n",
       "  0.5968015788625113,\n",
       "  0.5804333774946034,\n",
       "  0.5645140992286267,\n",
       "  0.5490314316579266,\n",
       "  0.533973400062541,\n",
       "  0.5193283581476241,\n",
       "  0.5050849790358816,\n",
       "  0.4912322465070532,\n",
       "  0.477759446477666,\n",
       "  0.4646561587144676,\n",
       "  0.4519122487751323,\n",
       "  0.7044142953056476,\n",
       "  0.6850946496472503,\n",
       "  0.6663048749906959,\n",
       "  0.6480304388086514,\n",
       "  0.6302572071507014,\n",
       "  0.6129714337117634,\n",
       "  0.5961597492003176,\n",
       "  0.5798091509982303,\n",
       "  0.5639069931041724,\n",
       "  0.5484409763528546,\n",
       "  0.5333991389025157,\n",
       "  0.5187698469833059,\n",
       "  0.5045417858994097,\n",
       "  0.49070395127795013,\n",
       "  0.47724564055790447,\n",
       "  0.4641564447124498,\n",
       "  0.4514262401983364,\n",
       "  0.4390451811260611,\n",
       "  0.42700369164478663,\n",
       "  0.4152924585361154,\n",
       "  0.4039024240109912,\n",
       "  0.3928247787041562,\n",
       "  0.38205095486074653,\n",
       "  0.3715726197097552,\n",
       "  0.36138166901923857,\n",
       "  0.3514702208282809,\n",
       "  0.34183060935086945,\n",
       "  0.33245537904696526,\n",
       "  0.32333727885618396,\n",
       "  0.3144692565896265,\n",
       "  0.30584445347552297,\n",
       "  0.29745619885447017,\n",
       "  0.2892980050201605,\n",
       "  0.2813635622016121,\n",
       "  0.2736467336830186,\n",
       "  0.26614155105744486,\n",
       "  0.25884220961069715,\n",
       "  0.25174306383179806,\n",
       "  0.24483862304659326,\n",
       "  0.23812354717111345,\n",
       "  0.2315926425814069,\n",
       "  0.22524085809664823,\n",
       "  0.21906328107241646,\n",
       "  0.21305513360112105,\n",
       "  0.20721176881663703,\n",
       "  0.20152866730029126,\n",
       "  0.19600143358542,\n",
       "  0.19062579275779434,\n",
       "  0.18539758714928428,\n",
       "  0.18031277312220403,\n",
       "  0.1753674179418518,\n",
       "  0.17055769673482468,\n",
       "  0.16587988953075675,\n",
       "  0.16133037838519182,\n",
       "  0.15690564458136597,\n",
       "  0.1526022659087354,\n",
       "  0.14841691401614493,\n",
       "  0.1443463518375898,\n",
       "  0.1403874310885801,\n",
       "  0.13653708983117108,\n",
       "  0.13279235010577636,\n",
       "  0.12915031562793225,\n",
       "  0.12560816954823184,\n",
       "  0.12216317227369645,\n",
       "  0.11881265934889915,\n",
       "  0.11555403939520187,\n",
       "  0.11238479210651205,\n",
       "  0.10930246630000871,\n",
       "  0.10630467802033047,\n",
       "  0.10338910869575897,\n",
       "  0.10055350334497193,\n",
       "  0.09779566883297867,\n",
       "  0.09511347217488941,\n",
       "  0.09250483888620613,\n",
       "  0.08996775137835938,\n",
       "  0.08750024739824992,\n",
       "  0.08510041851058832,\n",
       "  0.08276640862185872,\n",
       "  0.08049641254476518,\n",
       "  0.07828867460205033,\n",
       "  0.07614148726860631,\n",
       "  0.07405318985082811,\n",
       "  0.07202216720218745,\n",
       "  0.07004684847403422,\n",
       "  0.068125705900659,\n",
       "  0.0662572536176771,\n",
       "  0.06444004651282036,\n",
       "  0.06267267910824754,\n",
       "  0.060953784473509326,\n",
       "  0.0592820331683267,\n",
       "  0.057656132214365406,\n",
       "  0.05607482409521101,\n",
       "  0.054536885783771194,\n",
       "  0.05304112779635305,\n",
       "  0.05158639327268375,\n",
       "  0.050171557081163054,\n",
       "  0.04879552494865566,\n",
       "  0.04745723261415035,\n",
       "  0.04615564500563129,\n",
       "  0.04488975543952495,\n",
       "  0.0436585848421034,\n",
       "  0.042461180992241825,\n",
       "  0.04129661778494456,\n",
       "  0.040163994515070106,\n",
       "  0.03906243518070101,\n",
       "  0.03799108780561999,\n",
       "  0.03694912378036811,\n",
       "  0.03593573722137553,\n",
       "  0.034950144347669,\n",
       "  0.033991582874674166,\n",
       "  0.03305931142464375,\n",
       "  0.032152608953255675,\n",
       "  0.03127077419193758,\n",
       "  0.030413125105486473,\n",
       "  0.029578998364563996,\n",
       "  0.02876774883265929,\n",
       "  0.027978749067122742,\n",
       "  0.0272113888338846,\n",
       "  0.026465074635483206,\n",
       "  0.02573922925203777,\n",
       "  0.02503329129481069,\n",
       "  0.02434671477201407,\n",
       "  0.02367896866652471,\n",
       "  0.023029536525180885,\n",
       "  0.022397916059343295,\n",
       "  0.021783618756411247,\n",
       "  0.021186169501993615,\n",
       "  0.020605106212442315,\n",
       "  0.02003997947746415,\n",
       "  0.019490352212534545,\n",
       "  0.018955799320844374,\n",
       "  0.018435907364518448,\n",
       "  0.017930274244851295,\n",
       "  0.017438508891312998,\n",
       "  0.016960230959084503,\n",
       "  0.016495070534888516,\n",
       "  0.016042667850888415,\n",
       "  0.015602673006433929,\n",
       "  0.015174745697438378,\n",
       "  0.014758554953178155,\n",
       "  0.014353778880310884,\n",
       "  0.013960104413914277,\n",
       "  0.01357722707535313,\n",
       "  0.013204850736787196,\n",
       "  0.01284268739213778,\n",
       "  0.012490456934335942,\n",
       "  0.012147886938679997,\n",
       "  0.01181471245213478,\n",
       "  0.011490675788409697,\n",
       "  0.011175526328657074,\n",
       "  0.010869020327636664,\n",
       "  0.010570920725196394,\n",
       "  0.01028099696292353,\n",
       "  0.009999024805824479,\n",
       "  0.009724786168895293,\n",
       "  0.00945806894844874,\n",
       "  0.00919866685806749,\n",
       "  0.008946379269056544,\n",
       "  0.00870101105527149,\n",
       "  0.008462372442202597,\n",
       "  0.008230278860197988,\n",
       "  0.008004550801712421,\n",
       "  0.007785013682471219,\n",
       "  0.007571497706442002,\n",
       "  0.00736383773450978,\n",
       "  0.007161873156753825,\n",
       "  0.006965447768227555,\n",
       "  0.006774409648145338,\n",
       "  0.006588611042382792,\n",
       "  0.006407908249199687,\n",
       "  0.006232161508097078,\n",
       "  0.006061234891722698,\n",
       "  0.005894996200741014,\n",
       "  0.005733316861586635,\n",
       "  0.005576071827021988,\n",
       "  0.005423139479422351,\n",
       "  0.005274401536713447,\n",
       "  0.005129742960888839,\n",
       "  0.004989051869036382,\n",
       "  0.0048522194468049095,\n",
       "  0.004719139864244224,\n",
       "  0.004589710193953311,\n",
       "  0.004463830331473466,\n",
       "  0.004341402917864755,\n",
       "  0.00422233326440594,\n",
       "  0.004106529279359623,\n",
       "  0.003993901396745973,\n",
       "  0.003884362507069934,\n",
       "  0.003777827889948354,\n",
       "  0.0036742151485849154],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.460696386602735,\n",
       "  0.44806107950493274,\n",
       "  0.43577231514134435,\n",
       "  0.42382058904439285,\n",
       "  0.4121966574211454,\n",
       "  0.4008915300039102,\n",
       "  0.3898964630969167,\n",
       "  0.3792029528137014,\n",
       "  0.36880272849996876,\n",
       "  0.3586877463368401,\n",
       "  0.34885018311954336,\n",
       "  0.339282430206732,\n",
       "  0.3299770876357528,\n",
       "  0.3209269583993118,\n",
       "  0.31212504287911125,\n",
       "  0.30356453343215295,\n",
       "  0.2952388091255201,\n",
       "  0.28714143061556624,\n",
       "  0.27926613516755017,\n",
       "  0.271606831811865,\n",
       "  0.26415759663311517,\n",
       "  0.25691266818839753,\n",
       "  0.5992503168842703,\n",
       "  0.5961707664954381,\n",
       "  0.579819866127084,\n",
       "  0.5639174143541341,\n",
       "  0.7648190858215622,\n",
       "  0.7438427458617939,\n",
       "  0.7400201342540789,\n",
       "  0.7197239436895974,\n",
       "  0.7160252787274073,\n",
       "  0.696387183987342,\n",
       "  0.6772876942050586,\n",
       "  0.6587120373110471,\n",
       "  0.6406458463825275,\n",
       "  0.6230751485316782,\n",
       "  0.6059863540986208,\n",
       "  0.5893662461408039,\n",
       "  0.7785437327608524,\n",
       "  0.7571909732459718,\n",
       "  0.7364238460080135,\n",
       "  0.7162262891808971,\n",
       "  0.8469598123681072,\n",
       "  0.8426072816376026,\n",
       "  0.838277118584387,\n",
       "  0.8152860790746544,\n",
       "  0.7929256041908903,\n",
       "  0.7711783997282217,\n",
       "  0.7500276458019483,\n",
       "  0.8651890061315697,\n",
       "  0.8607427954827392,\n",
       "  0.8563194339327689,\n",
       "  0.9225125515449778,\n",
       "  0.9582107390552722,\n",
       "  0.9774629005713071,\n",
       "  0.9724397138149373,\n",
       "  0.985136638074133,\n",
       "  0.9919841352061486,\n",
       "  0.9868863237520422,\n",
       "  0.9929277470145544,\n",
       "  0.9961859084100896,\n",
       "  0.9910665040223804,\n",
       "  0.9951821333389999,\n",
       "  0.9900678873564235,\n",
       "  0.9849799235096433,\n",
       "  0.9799181067346312,\n",
       "  0.9748823026614543,\n",
       "  0.9864539350651034,\n",
       "  0.9813845433373031,\n",
       "  0.9763412032390583,\n",
       "  0.9495635438219006,\n",
       "  0.9446837320000198,\n",
       "  0.9398289975556057,\n",
       "  0.9349992116158894,\n",
       "  0.93019424597038,\n",
       "  0.9254139730674609,\n",
       "  0.9206582660110038,\n",
       "  0.9159269985570003,\n",
       "  0.9112200451102107,\n",
       "  0.9065372807208298,\n",
       "  0.90187858108117,\n",
       "  0.8972438225223617,\n",
       "  0.8926328820110699,\n",
       "  0.8880456371462291,\n",
       "  0.8834819661557929,\n",
       "  0.8789417478935023,\n",
       "  0.8744248618356697,\n",
       "  0.8699311880779791,\n",
       "  0.8654606073323035,\n",
       "  0.861013000923538,\n",
       "  0.9250438091828217,\n",
       "  0.9202900044004273,\n",
       "  0.9155606294446906,\n",
       "  0.9108555587706098,\n",
       "  0.9061746674783591,\n",
       "  0.901517831309974,\n",
       "  0.896884926646052,\n",
       "  0.8922758305024716,\n",
       "  0.8876904205271271,\n",
       "  0.883128574996681,\n",
       "  0.8785901728133324,\n",
       "  0.874075093501603,\n",
       "  0.8695832172051382,\n",
       "  0.8651144246835262,\n",
       "  0.8606685973091319,\n",
       "  0.8562456170639485,\n",
       "  0.8518453665364641,\n",
       "  0.8474677289185454,\n",
       "  0.8431125880023365,\n",
       "  0.8387798281771741,\n",
       "  0.8344693344265192,\n",
       "  0.8301809923249028,\n",
       "  0.8259146880348893,\n",
       "  0.8216703083040542,\n",
       "  0.8174477404619778,\n",
       "  0.813246872417254,\n",
       "  0.8090675926545153,\n",
       "  0.8049097902314722,\n",
       "  0.8947871449334026,\n",
       "  0.8901888293005819,\n",
       "  0.885614144434898,\n",
       "  0.9383112947722029,\n",
       "  0.9334893083147148,\n",
       "  0.9286921020698552,\n",
       "  0.9239195486919869,\n",
       "  0.9589695377006938,\n",
       "  0.977872123422624,\n",
       "  0.9880663562050124,\n",
       "  0.982988678236874,\n",
       "  0.9779370944813218,\n",
       "  0.9881013953317344,\n",
       "  0.9830235372973477,\n",
       "  0.9779717744009087,\n",
       "  0.9881200983376799,\n",
       "  0.9830421441884517,\n",
       "  0.9779902856711058,\n",
       "  0.9729643886800589,\n",
       "  0.9679643197988967,\n",
       "  0.962989946296833,\n",
       "  0.9800403443058552,\n",
       "  0.9750039120531856,\n",
       "  0.9699933620511633,\n",
       "  0.9650085612907721,\n",
       "  0.96004937744653,\n",
       "  0.9551156788729761,\n",
       "  0.9502073346011765,\n",
       "  0.9453242143352469,\n",
       "  0.9705131512256643,\n",
       "  0.9655256792660942,\n",
       "  0.9605638379499791,\n",
       "  0.9556274955613137,\n",
       "  0.9507165210609815,\n",
       "  0.945830784083277,\n",
       "  0.9409701549324447,\n",
       "  0.9361345045792362,\n",
       "  0.9313237046574849,\n",
       "  0.9265376274606989,\n",
       "  0.9603814770408189,\n",
       "  0.9554460718057817,\n",
       "  0.9505360296430406,\n",
       "  0.9456512202116397,\n",
       "  0.9407915138404459,\n",
       "  0.9359567815247066,\n",
       "  0.9311468949226254,\n",
       "  0.9263617263519549,\n",
       "  0.9216011487866077,\n",
       "  0.9168650358532838,\n",
       "  0.9121532618281164,\n",
       "  0.9074657016333342,\n",
       "  0.9028022308339411,\n",
       "  0.8981627256344132,\n",
       "  0.8935470628754125,\n",
       "  0.8889551200305174,\n",
       "  0.8843867752029699,\n",
       "  0.8798419071224406,\n",
       "  0.8753203951418085,\n",
       "  0.8708221192339589,\n",
       "  0.8663469599885971,\n",
       "  0.8618947986090784,\n",
       "  0.8574655169092547,\n",
       "  0.9231306382354496,\n",
       "  0.9183866652481647,\n",
       "  0.913667071561893,\n",
       "  0.9089717318912841,\n",
       "  0.9043005215948298,\n",
       "  0.899653316671555,\n",
       "  0.9458826710885385,\n",
       "  0.9410217752901255,\n",
       "  0.9361858596596396,\n",
       "  0.9313747958238722,\n",
       "  0.9265884560693254,\n",
       "  0.9218267133388216,\n",
       "  0.9578408640324862,\n",
       "  0.9529185150204618,\n",
       "  0.9480214619847377,\n",
       "  0.971967786629262,\n",
       "  0.9669728392910454,\n",
       "  0.9620035610122922,\n",
       "  0.957059819879577,\n",
       "  0.9521414846573779,\n",
       "  0.9472484247845933,\n",
       "  0.9423805103710753,\n",
       "  0.9375376121941826,\n",
       "  0.9663138085549015,\n",
       "  0.961347917038412,\n",
       "  0.9791547919934848,\n",
       "  0.9741229105985971,\n",
       "  0.9691168880674758,\n",
       "  0.9641365915112898,\n",
       "  0.9591818887241249,\n",
       "  0.9542526481794734,\n",
       "  0.9493487390267431,\n",
       "  0.9726835919339947,\n",
       "  0.9676849660687211,\n",
       "  0.9627120281668801,\n",
       "  0.979890462054143,\n",
       "  0.974854800047118,\n",
       "  0.986439102805814,\n",
       "  0.9813697873010687,\n",
       "  0.9763265230341682,\n",
       "  0.9713091761276704,\n",
       "  0.9663176133921301,\n",
       "  0.9818349671945321,\n",
       "  0.9767893123658223,\n",
       "  0.9717695871826244,\n",
       "  0.9667756583923597,\n",
       "  0.9618073934272354,\n",
       "  0.9794025892702479,\n",
       "  0.9743694344439102,\n",
       "  0.9861773433821853,\n",
       "  0.981109373060433,\n",
       "  0.9898122166321518,\n",
       "  0.984725566678508,\n",
       "  0.9796650570445289,\n",
       "  0.9746305533949806,\n",
       "  0.9696219220849784,\n",
       "  0.9646390301564395,\n",
       "  0.9596817453345531,\n",
       "  0.9782562195730533,\n",
       "  0.9732289559463483,\n",
       "  0.9855622792074482,\n",
       "  0.9804974697035796,\n",
       "  0.9894822149407508,\n",
       "  0.9943277205126112,\n",
       "  0.9892178653618418,\n",
       "  0.9841342697823617,\n",
       "  0.9790767988261024,\n",
       "  0.9740453182384937,\n",
       "  0.9860025463414436,\n",
       "  0.9809354743025618,\n",
       "  0.9758944419723424,\n",
       "  0.970879315532592,\n",
       "  0.9658899618528092,\n",
       "  0.9816043331741015,\n",
       "  0.9900791504099408,\n",
       "  0.9946496499681102,\n",
       "  0.9971145368948616,\n",
       "  0.9919903602807041,\n",
       "  0.9956803723573735,\n",
       "  0.9905635659219787]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['latent_variables'][0]['q_value']\n",
    "selected_model['q_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8b63ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_model['rpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83487ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  1.        , -0.46069639, -0.45832887,\n",
       "       -0.45597351, -0.45363026, -0.45129905, -0.44897982, -0.44667252,\n",
       "       -0.44437706, -0.44209341, -0.43982149, -0.43756124, -0.43531261,\n",
       "       -0.43307554,  1.        ,  0.58096676, -0.68668253,  0.31684634,\n",
       "       -0.82912362,  0.17513725, -0.90554785, -0.90089424,  0.10373546,\n",
       "       -0.94405509, -0.93920359,  0.06562299,  0.03539071, -0.98091366,\n",
       "       -0.97587274, -0.97085773, -0.96586848, -0.96090488, -0.95596678,\n",
       "       -0.95105407, -0.94616659, -0.94130424,  0.74308733, -0.59925032,\n",
       "       -0.88580321, -0.88125106,  0.43608259,  0.14732315, -0.74384275,\n",
       "       -0.89530064, -0.71972394,  0.13372912, -0.9278794 ,  0.07688897,\n",
       "       -0.9585335 , -0.95360759, -0.948707  , -0.94383159,  0.41063375,\n",
       "       -0.91322823, -0.90853514, -0.90386617,  0.28377371, -0.84695981,\n",
       "       -0.84260728, -0.8272443 , -0.82299309, -0.81876372, -0.81455609,\n",
       "        0.24997235, -0.86518901, -0.8607428 ,  0.14368057,  0.07748745,\n",
       "        0.04178926, -0.9774629 ,  0.02756029,  0.01486336, -0.99198414,\n",
       "        0.01311368,  0.00707225, -0.99618591,  0.0089335 , -0.99518213,\n",
       "       -0.99006789, -0.98497992, -0.97991811,  0.0251177 , -0.98645394,\n",
       "       -0.98138454,  0.54808775, -0.94956354, -0.94468373, -0.939829  ,\n",
       "       -0.93499921, -0.93019425, -0.92541397, -0.92065827, -0.915927  ,\n",
       "       -0.91122005, -0.90653728, -0.90187858, -0.89724382, -0.89263288,\n",
       "       -0.88804564, -0.88348197, -0.87894175, -0.87442486, -0.86993119,\n",
       "       -0.86546061,  0.138987  , -0.92504381, -0.92029   , -0.91556063,\n",
       "       -0.91085556, -0.90617467, -0.90151783, -0.89688493, -0.89227583,\n",
       "       -0.88769042, -0.88312857, -0.87859017, -0.87407509, -0.86958322,\n",
       "       -0.86511442, -0.8606686 , -0.85624562, -0.85184537, -0.84746773,\n",
       "       -0.84311259, -0.83877983, -0.83446933, -0.83018099, -0.82591469,\n",
       "       -0.82167031, -0.81744774, -0.81324687, -0.80906759,  0.19509021,\n",
       "       -0.89478714, -0.89018883,  0.11438586, -0.93831129, -0.93348931,\n",
       "       -0.9286921 ,  0.07608045,  0.04103046,  0.02212788, -0.98806636,\n",
       "       -0.98298868,  0.02206291, -0.9881014 , -0.98302354,  0.02202823,\n",
       "       -0.9881201 , -0.98304214, -0.97799029, -0.97296439, -0.96796432,\n",
       "        0.03701005, -0.98004034, -0.97500391, -0.96999336, -0.96500856,\n",
       "       -0.96004938, -0.95511568, -0.95020733,  0.05467579, -0.97051315,\n",
       "       -0.96552568, -0.96056384, -0.9556275 , -0.95071652, -0.94583078,\n",
       "       -0.94097015, -0.9361345 , -0.9313237 ,  0.07346237, -0.96038148,\n",
       "       -0.95544607, -0.95053603, -0.94565122, -0.94079151, -0.93595678,\n",
       "       -0.93114689, -0.92636173, -0.92160115, -0.91686504, -0.91215326,\n",
       "       -0.9074657 , -0.90280223, -0.89816273, -0.89354706, -0.88895512,\n",
       "       -0.88438678, -0.87984191, -0.8753204 , -0.87082212, -0.86634696,\n",
       "       -0.8618948 ,  0.14253448, -0.92313064, -0.91838667, -0.91366707,\n",
       "       -0.90897173, -0.90430052,  0.10034668, -0.94588267, -0.94102178,\n",
       "       -0.93618586, -0.9313748 , -0.92658846,  0.07817329, -0.95784086,\n",
       "       -0.95291852,  0.05197854, -0.97196779, -0.96697284, -0.96200356,\n",
       "       -0.95705982, -0.95214148, -0.94724842, -0.94238051,  0.06246239,\n",
       "       -0.96631381,  0.03865208, -0.97915479, -0.97412291, -0.96911689,\n",
       "       -0.96413659, -0.95918189, -0.95425265,  0.05065126, -0.97268359,\n",
       "       -0.96768497,  0.03728797, -0.97989046,  0.0251452 , -0.9864391 ,\n",
       "       -0.98136979, -0.97632652, -0.97130918,  0.03368239, -0.98183497,\n",
       "       -0.97678931, -0.97176959, -0.96677566,  0.03819261, -0.97940259,\n",
       "        0.02563057, -0.98617734,  0.01889063, -0.98981222, -0.98472557,\n",
       "       -0.97966506, -0.97463055, -0.96962192, -0.96463903,  0.04031825,\n",
       "       -0.97825622,  0.02677104, -0.98556228,  0.01950253,  0.01051779,\n",
       "       -0.99432772, -0.98921787, -0.98413427, -0.9790768 ,  0.02595468,\n",
       "       -0.98600255, -0.98093547, -0.97589444, -0.97087932,  0.03411004,\n",
       "        0.01839567,  0.00992085,  0.00535035, -0.99711454,  0.00800964,\n",
       "       -0.99568037])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['latent_variables'][0]['rpe']  # rew\n",
    "selected_model['rpe']  # rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a533fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 277)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_model['choice_kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b3a6a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model['choice_kernel']  # choice kernel (2, 277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa776634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 276)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_model['choice_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9350665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3550508467017394,\n",
       "  0.3522744092462053,\n",
       "  0.3522744092462053,\n",
       "  0.9252959679493504,\n",
       "  0.9241867976962418,\n",
       "  0.9230683448441883,\n",
       "  0.9219406497635152,\n",
       "  0.920803754613384,\n",
       "  0.9196577033299882,\n",
       "  0.918502541613963,\n",
       "  0.917338316917025,\n",
       "  0.9161650784278449,\n",
       "  0.9149828770571694,\n",
       "  0.9137917654222002,\n",
       "  0.9125917978302421,\n",
       "  0.9113830302616337,\n",
       "  0.9101655203519714,\n",
       "  0.29120740713939697,\n",
       "  0.7352845427197062,\n",
       "  0.7466023037507427,\n",
       "  0.8950766495923818,\n",
       "  0.8996413911772703,\n",
       "  0.94334820155292,\n",
       "  0.9455869329658245,\n",
       "  0.9476494506602126,\n",
       "  0.9640063181076812,\n",
       "  0.965215766026353,\n",
       "  0.9663307342601248,\n",
       "  0.9740388234165914,\n",
       "  0.9780597945693192,\n",
       "  0.9786315446167712,\n",
       "  0.9791581933709812,\n",
       "  0.9796432033275538,\n",
       "  0.980089700035549,\n",
       "  0.9805005083902019,\n",
       "  0.9808781846271785,\n",
       "  0.9812250445654421,\n",
       "  0.9815431885723425,\n",
       "  0.9818345236612861,\n",
       "  0.8157984417491402,\n",
       "  0.7926064327620782,\n",
       "  0.8091394963211369,\n",
       "  0.8206849039294927,\n",
       "  0.4955974937312832,\n",
       "  0.6467517595581543,\n",
       "  0.6073699011983025,\n",
       "  0.6378906495786096,\n",
       "  0.599258326456325,\n",
       "  0.7258382807105732,\n",
       "  0.7446129168021276,\n",
       "  0.8074603769531592,\n",
       "  0.8208402386859748,\n",
       "  0.8330423006581366,\n",
       "  0.844166647263851,\n",
       "  0.8543077627392087,\n",
       "  0.5738607342647567,\n",
       "  0.6068435964087161,\n",
       "  0.6323784829000355,\n",
       "  0.6563638712048855,\n",
       "  0.3957357332101968,\n",
       "  0.36460424230678873,\n",
       "  0.3355189118994928,\n",
       "  0.3698450162795275,\n",
       "  0.39871416169250273,\n",
       "  0.4273303419458231,\n",
       "  0.45548135939892015,\n",
       "  0.24458396099035878,\n",
       "  0.22386294378127533,\n",
       "  0.20504711836672174,\n",
       "  0.12583586954735557,\n",
       "  0.09009515217067168,\n",
       "  0.07094429411972802,\n",
       "  0.06506533983794009,\n",
       "  0.05346847867230442,\n",
       "  0.04566929367612282,\n",
       "  0.04221866644053194,\n",
       "  0.036413494876727445,\n",
       "  0.032051194104340035,\n",
       "  0.029870795353737135,\n",
       "  0.02627576754894131,\n",
       "  0.024616322149583803,\n",
       "  0.02311791487439471,\n",
       "  0.021762437820163637,\n",
       "  0.020534081346383057,\n",
       "  0.017403673804071984,\n",
       "  0.016502550064296486,\n",
       "  0.01568194085943046,\n",
       "  0.09664467942514593,\n",
       "  0.08654463677084608,\n",
       "  0.07941054959683178,\n",
       "  0.073040861328635,\n",
       "  0.06734598493921767,\n",
       "  0.062246996820895004,\n",
       "  0.057674508760661894,\n",
       "  0.05356759820507948,\n",
       "  0.04987281783118978,\n",
       "  0.04654329417901415,\n",
       "  0.04353791765414077,\n",
       "  0.04082062149295614,\n",
       "  0.03835974447948415,\n",
       "  0.03612747070729857,\n",
       "  0.03409933905567561,\n",
       "  0.03225381498596764,\n",
       "  0.03057191754597927,\n",
       "  0.02903689494909479,\n",
       "  0.027633942672123202,\n",
       "  0.02634995862682979,\n",
       "  0.01602724958973503,\n",
       "  0.015369535928077785,\n",
       "  0.014765745485654883,\n",
       "  0.014210884859108463,\n",
       "  0.013700507279460065,\n",
       "  0.013230646178060732,\n",
       "  0.01279775753874486,\n",
       "  0.012398669796561112,\n",
       "  0.01203054022678524,\n",
       "  0.011690816923356306,\n",
       "  0.011377205597682391,\n",
       "  0.011087640540564547,\n",
       "  0.01082025918487883,\n",
       "  0.010573379787249915,\n",
       "  0.010345481815458956,\n",
       "  0.010135188686621447,\n",
       "  0.00994125255082239,\n",
       "  0.009762540857236346,\n",
       "  0.009598024475906746,\n",
       "  0.009446767179258082,\n",
       "  0.00930791631386039,\n",
       "  0.009180694515630637,\n",
       "  0.009064392341105518,\n",
       "  0.008958361704134325,\n",
       "  0.008862010021723042,\n",
       "  0.008774794985154035,\n",
       "  0.008696219883199385,\n",
       "  0.008625829413486504,\n",
       "  0.004565877257099871,\n",
       "  0.004551016231191834,\n",
       "  0.004539725722708955,\n",
       "  0.0030869904520552742,\n",
       "  0.0030899788601982427,\n",
       "  0.0030951195794739956,\n",
       "  0.003102352699603469,\n",
       "  0.002382050468033334,\n",
       "  0.002039857255671217,\n",
       "  0.001853430067362882,\n",
       "  0.001867415368803229,\n",
       "  0.0018825490835396297,\n",
       "  0.0017145682774905866,\n",
       "  0.0017311924124566015,\n",
       "  0.0017488444821229408,\n",
       "  0.0015961586080853673,\n",
       "  0.0016147983631089474,\n",
       "  0.0016343780211354603,\n",
       "  0.0016548998080999212,\n",
       "  0.0016763669869734842,\n",
       "  0.0016987838037297485,\n",
       "  0.001485450585431458,\n",
       "  0.0015075889292176983,\n",
       "  0.0015305904395026524,\n",
       "  0.001554463498321563,\n",
       "  0.0015792171586185458,\n",
       "  0.0016048611175149905,\n",
       "  0.001631405691501772,\n",
       "  0.0016588617933805609,\n",
       "  0.0013786870888243504,\n",
       "  0.0014041047022891778,\n",
       "  0.001430342379841342,\n",
       "  0.0014574129840310857,\n",
       "  0.0014853298158647426,\n",
       "  0.0015141066038989106,\n",
       "  0.0015437574939734938,\n",
       "  0.0015742970395221235,\n",
       "  0.0016057401924036798,\n",
       "  0.0016381022942034084,\n",
       "  0.0012893754127793638,\n",
       "  0.001317561662254673,\n",
       "  0.0013465603981297836,\n",
       "  0.0013763872585952801,\n",
       "  0.0014070582030693065,\n",
       "  0.0014385895082201362,\n",
       "  0.0014709977640953048,\n",
       "  0.0015042998703392223,\n",
       "  0.0015385130324825547,\n",
       "  0.0015736547582879561,\n",
       "  0.0016097428541379177,\n",
       "  0.0016467954214515591,\n",
       "  0.001684830853118242,\n",
       "  0.0017238678299367604,\n",
       "  0.0017639253170497833,\n",
       "  0.001805022560363969,\n",
       "  0.0018471790829469427,\n",
       "  0.0018904146813930286,\n",
       "  0.0019347494221502355,\n",
       "  0.001980203637801622,\n",
       "  0.0020267979232947353,\n",
       "  0.0020745531321133036,\n",
       "  0.002123490372385895,\n",
       "  0.001357309310290723,\n",
       "  0.0013927785986473714,\n",
       "  0.001429178138369175,\n",
       "  0.0014665268902803047,\n",
       "  0.0015048440670688455,\n",
       "  0.0015441491314415877,\n",
       "  0.0011256617412208766,\n",
       "  0.0011570766985872913,\n",
       "  0.0011893358789965302,\n",
       "  0.0012224573155201924,\n",
       "  0.001256459289807434,\n",
       "  0.001291360331018369,\n",
       "  0.0010090823681392044,\n",
       "  0.0010384992114956598,\n",
       "  0.001068718910007854,\n",
       "  0.0009060007432908144,\n",
       "  0.0009331969288592276,\n",
       "  0.00096114869104339,\n",
       "  0.0009898729401648081,\n",
       "  0.0010193868324524828,\n",
       "  0.0010497077696430754,\n",
       "  0.0010808533984706333,\n",
       "  0.0011128416100444354,\n",
       "  0.000914011566888398,\n",
       "  0.0009420187532860036,\n",
       "  0.0008330797898150023,\n",
       "  0.0008591398837864121,\n",
       "  0.0008859343028249872,\n",
       "  0.0009134796899622833,\n",
       "  0.0009417929320627616,\n",
       "  0.000970891159570443,\n",
       "  0.0010007917461473416,\n",
       "  0.0008532306904410809,\n",
       "  0.0008801974290895656,\n",
       "  0.00090792118701372,\n",
       "  0.0008069362428723837,\n",
       "  0.0008328153931027365,\n",
       "  0.0007686605171444133,\n",
       "  0.0007935916361335964,\n",
       "  0.000819236133170611,\n",
       "  0.0008456103625049203,\n",
       "  0.00087273092067867,\n",
       "  0.000784701192541183,\n",
       "  0.0008102524572573312,\n",
       "  0.0008365326293339988,\n",
       "  0.0008635582964537146,\n",
       "  0.0008913462880859868,\n",
       "  0.0007905169885396499,\n",
       "  0.0008163898233172215,\n",
       "  0.0007528453900977202,\n",
       "  0.0007777377755542813,\n",
       "  0.0007324015207655215,\n",
       "  0.000756777449460769,\n",
       "  0.0007818582088191709,\n",
       "  0.0008076600353978225,\n",
       "  0.0008341994068764537,\n",
       "  0.0008614930419779423,\n",
       "  0.0008895579002857223,\n",
       "  0.000784101598403407,\n",
       "  0.0008100848291607038,\n",
       "  0.0007447101483412891,\n",
       "  0.0007696339979643293,\n",
       "  0.0007236862258993027,\n",
       "  0.0006997157811626663,\n",
       "  0.0007234205920207058,\n",
       "  0.000747817457382909,\n",
       "  0.0007729224262251348,\n",
       "  0.0007987517879211206,\n",
       "  0.0007363247177138427,\n",
       "  0.000761154265470637,\n",
       "  0.0007867024825792387,\n",
       "  0.0008129858153118892,\n",
       "  0.0008400209501246311,\n",
       "  0.0007551381116694154,\n",
       "  0.0007127211584114041,\n",
       "  0.000690602809822387,\n",
       "  0.0006787312611604851,\n",
       "  0.0007020185313287717,\n",
       "  0.0006843159276370049],\n",
       " [0.6449491532982606,\n",
       "  0.6477255907537947,\n",
       "  0.6477255907537947,\n",
       "  0.07470403205064957,\n",
       "  0.07581320230375818,\n",
       "  0.07693165515581167,\n",
       "  0.07805935023648485,\n",
       "  0.07919624538661596,\n",
       "  0.08034229667001186,\n",
       "  0.0814974583860369,\n",
       "  0.08266168308297496,\n",
       "  0.08383492157215514,\n",
       "  0.08501712294283056,\n",
       "  0.0862082345777998,\n",
       "  0.08740820216975789,\n",
       "  0.08861696973836633,\n",
       "  0.08983447964802854,\n",
       "  0.708792592860603,\n",
       "  0.2647154572802938,\n",
       "  0.2533976962492574,\n",
       "  0.10492335040761833,\n",
       "  0.10035860882272975,\n",
       "  0.05665179844707999,\n",
       "  0.054413067034175505,\n",
       "  0.05235054933978745,\n",
       "  0.035993681892318774,\n",
       "  0.03478423397364713,\n",
       "  0.033669265739875186,\n",
       "  0.025961176583408626,\n",
       "  0.021940205430680787,\n",
       "  0.021368455383228884,\n",
       "  0.02084180662901884,\n",
       "  0.020356796672446095,\n",
       "  0.01991029996445112,\n",
       "  0.019499491609798237,\n",
       "  0.019121815372821562,\n",
       "  0.018774955434557792,\n",
       "  0.018456811427657503,\n",
       "  0.01816547633871387,\n",
       "  0.18420155825085982,\n",
       "  0.20739356723792182,\n",
       "  0.19086050367886312,\n",
       "  0.17931509607050738,\n",
       "  0.5044025062687167,\n",
       "  0.3532482404418458,\n",
       "  0.3926300988016975,\n",
       "  0.3621093504213904,\n",
       "  0.4007416735436749,\n",
       "  0.27416171928942684,\n",
       "  0.2553870831978725,\n",
       "  0.1925396230468408,\n",
       "  0.17915976131402514,\n",
       "  0.1669576993418635,\n",
       "  0.15583335273614898,\n",
       "  0.1456922372607913,\n",
       "  0.4261392657352433,\n",
       "  0.3931564035912839,\n",
       "  0.36762151709996455,\n",
       "  0.3436361287951145,\n",
       "  0.6042642667898032,\n",
       "  0.6353957576932112,\n",
       "  0.6644810881005072,\n",
       "  0.6301549837204726,\n",
       "  0.6012858383074974,\n",
       "  0.5726696580541769,\n",
       "  0.5445186406010799,\n",
       "  0.7554160390096412,\n",
       "  0.7761370562187248,\n",
       "  0.7949528816332783,\n",
       "  0.8741641304526443,\n",
       "  0.9099048478293283,\n",
       "  0.929055705880272,\n",
       "  0.93493466016206,\n",
       "  0.9465315213276956,\n",
       "  0.9543307063238772,\n",
       "  0.957781333559468,\n",
       "  0.9635865051232726,\n",
       "  0.9679488058956599,\n",
       "  0.9701292046462628,\n",
       "  0.9737242324510587,\n",
       "  0.9753836778504161,\n",
       "  0.9768820851256053,\n",
       "  0.9782375621798364,\n",
       "  0.979465918653617,\n",
       "  0.9825963261959281,\n",
       "  0.9834974499357034,\n",
       "  0.9843180591405696,\n",
       "  0.903355320574854,\n",
       "  0.913455363229154,\n",
       "  0.9205894504031683,\n",
       "  0.9269591386713649,\n",
       "  0.9326540150607823,\n",
       "  0.9377530031791049,\n",
       "  0.9423254912393381,\n",
       "  0.9464324017949205,\n",
       "  0.9501271821688102,\n",
       "  0.9534567058209859,\n",
       "  0.9564620823458593,\n",
       "  0.9591793785070438,\n",
       "  0.9616402555205159,\n",
       "  0.9638725292927014,\n",
       "  0.9659006609443244,\n",
       "  0.9677461850140324,\n",
       "  0.9694280824540208,\n",
       "  0.9709631050509052,\n",
       "  0.9723660573278767,\n",
       "  0.9736500413731701,\n",
       "  0.9839727504102649,\n",
       "  0.9846304640719222,\n",
       "  0.9852342545143451,\n",
       "  0.9857891151408915,\n",
       "  0.98629949272054,\n",
       "  0.9867693538219393,\n",
       "  0.9872022424612551,\n",
       "  0.9876013302034389,\n",
       "  0.9879694597732148,\n",
       "  0.9883091830766437,\n",
       "  0.9886227944023176,\n",
       "  0.9889123594594355,\n",
       "  0.9891797408151212,\n",
       "  0.9894266202127501,\n",
       "  0.9896545181845411,\n",
       "  0.9898648113133786,\n",
       "  0.9900587474491777,\n",
       "  0.9902374591427637,\n",
       "  0.9904019755240934,\n",
       "  0.9905532328207418,\n",
       "  0.9906920836861396,\n",
       "  0.9908193054843695,\n",
       "  0.9909356076588945,\n",
       "  0.9910416382958657,\n",
       "  0.9911379899782771,\n",
       "  0.9912252050148459,\n",
       "  0.9913037801168006,\n",
       "  0.9913741705865134,\n",
       "  0.9954341227429001,\n",
       "  0.9954489837688082,\n",
       "  0.995460274277291,\n",
       "  0.9969130095479448,\n",
       "  0.9969100211398018,\n",
       "  0.9969048804205259,\n",
       "  0.9968976473003965,\n",
       "  0.9976179495319666,\n",
       "  0.9979601427443288,\n",
       "  0.9981465699326371,\n",
       "  0.9981325846311968,\n",
       "  0.9981174509164603,\n",
       "  0.9982854317225095,\n",
       "  0.9982688075875434,\n",
       "  0.998251155517877,\n",
       "  0.9984038413919146,\n",
       "  0.9983852016368912,\n",
       "  0.9983656219788646,\n",
       "  0.9983451001919,\n",
       "  0.9983236330130265,\n",
       "  0.9983012161962702,\n",
       "  0.9985145494145685,\n",
       "  0.9984924110707823,\n",
       "  0.9984694095604973,\n",
       "  0.9984455365016784,\n",
       "  0.9984207828413815,\n",
       "  0.998395138882485,\n",
       "  0.9983685943084981,\n",
       "  0.9983411382066194,\n",
       "  0.9986213129111756,\n",
       "  0.9985958952977108,\n",
       "  0.9985696576201587,\n",
       "  0.9985425870159689,\n",
       "  0.9985146701841352,\n",
       "  0.9984858933961012,\n",
       "  0.9984562425060265,\n",
       "  0.9984257029604778,\n",
       "  0.9983942598075963,\n",
       "  0.9983618977057966,\n",
       "  0.9987106245872206,\n",
       "  0.9986824383377454,\n",
       "  0.9986534396018701,\n",
       "  0.9986236127414047,\n",
       "  0.9985929417969306,\n",
       "  0.9985614104917798,\n",
       "  0.9985290022359046,\n",
       "  0.9984957001296607,\n",
       "  0.9984614869675175,\n",
       "  0.9984263452417121,\n",
       "  0.998390257145862,\n",
       "  0.9983532045785484,\n",
       "  0.9983151691468818,\n",
       "  0.9982761321700633,\n",
       "  0.9982360746829503,\n",
       "  0.998194977439636,\n",
       "  0.9981528209170532,\n",
       "  0.9981095853186069,\n",
       "  0.9980652505778498,\n",
       "  0.9980197963621984,\n",
       "  0.9979732020767053,\n",
       "  0.9979254468678866,\n",
       "  0.9978765096276141,\n",
       "  0.9986426906897092,\n",
       "  0.9986072214013526,\n",
       "  0.9985708218616308,\n",
       "  0.9985334731097197,\n",
       "  0.9984951559329311,\n",
       "  0.9984558508685584,\n",
       "  0.9988743382587791,\n",
       "  0.9988429233014128,\n",
       "  0.9988106641210035,\n",
       "  0.9987775426844798,\n",
       "  0.9987435407101926,\n",
       "  0.9987086396689817,\n",
       "  0.9989909176318609,\n",
       "  0.9989615007885042,\n",
       "  0.9989312810899922,\n",
       "  0.9990939992567093,\n",
       "  0.9990668030711408,\n",
       "  0.9990388513089566,\n",
       "  0.9990101270598352,\n",
       "  0.9989806131675475,\n",
       "  0.9989502922303569,\n",
       "  0.9989191466015294,\n",
       "  0.9988871583899555,\n",
       "  0.9990859884331116,\n",
       "  0.999057981246714,\n",
       "  0.9991669202101849,\n",
       "  0.9991408601162136,\n",
       "  0.9991140656971751,\n",
       "  0.9990865203100376,\n",
       "  0.9990582070679371,\n",
       "  0.9990291088404296,\n",
       "  0.9989992082538527,\n",
       "  0.9991467693095588,\n",
       "  0.9991198025709104,\n",
       "  0.9990920788129862,\n",
       "  0.9991930637571276,\n",
       "  0.9991671846068972,\n",
       "  0.9992313394828556,\n",
       "  0.9992064083638664,\n",
       "  0.9991807638668294,\n",
       "  0.999154389637495,\n",
       "  0.9991272690793214,\n",
       "  0.9992152988074587,\n",
       "  0.9991897475427427,\n",
       "  0.9991634673706661,\n",
       "  0.9991364417035462,\n",
       "  0.9991086537119139,\n",
       "  0.9992094830114603,\n",
       "  0.9991836101766827,\n",
       "  0.9992471546099023,\n",
       "  0.9992222622244458,\n",
       "  0.9992675984792344,\n",
       "  0.9992432225505392,\n",
       "  0.9992181417911807,\n",
       "  0.9991923399646022,\n",
       "  0.9991658005931235,\n",
       "  0.9991385069580221,\n",
       "  0.9991104420997143,\n",
       "  0.9992158984015965,\n",
       "  0.9991899151708393,\n",
       "  0.9992552898516587,\n",
       "  0.9992303660020357,\n",
       "  0.9992763137741008,\n",
       "  0.9993002842188373,\n",
       "  0.9992765794079793,\n",
       "  0.999252182542617,\n",
       "  0.9992270775737749,\n",
       "  0.9992012482120789,\n",
       "  0.9992636752822861,\n",
       "  0.9992388457345293,\n",
       "  0.9992132975174207,\n",
       "  0.9991870141846881,\n",
       "  0.9991599790498753,\n",
       "  0.9992448618883306,\n",
       "  0.9992872788415886,\n",
       "  0.9993093971901775,\n",
       "  0.9993212687388395,\n",
       "  0.9992979814686712,\n",
       "  0.9993156840723629]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model['choice_prob'] # choice probability (2, 277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441f2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: {'analysis_spec.analysis_name': 'MLE fitting', 'analysis_spec.analysis_ver': 'first version @ 0.10.0', 'subject_id': '706893', 'session_date': '2024-05-28'}\n",
      "Found 30 MLE fitting records!\n",
      "Found 30 successful MLE fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get latent variables from s3: 100%|██████████| 30/30 [00:00<00:00, 56.09it/s]\n",
      "Download figures from s3: 100%|██████████| 30/30 [00:00<00:00, 54.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706893_2024-05-28_15-15-38_LossCounting_c13e5062bd.png\n",
      "706893_2024-05-28_15-15-38_LossCounting_CK1_4f6cc4f4b8.png\n",
      "706893_2024-05-28_15-15-38_LossCounting_CKfull_588fb69b6a.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_CK1_epsi_4d3e0d0be9.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_CK1_softmax_55441aed29.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_CKfull_epsi_2f54d18b4e.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_CKfull_softmax_fcab1136a6.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_epsi_b0b66785a4.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F0_softmax_1b41a955e5.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_CK1_epsi_b4d4fa61bb.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_CK1_softmax_1fcdc55fe3.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_CKfull_epsi_6d01f31a00.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_CKfull_softmax_651d38ab92.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_epsi_8fdab4173c.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L1F1_softmax_c7181ce080.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_CK1_epsi_ae58bf1fd3.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_CK1_softmax_35f4e87843.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_CKfull_epsi_17d2ba9805.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_CKfull_softmax_8674e4424c.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_epsi_95f40a6175.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F0_softmax_f24efb6d46.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_CK1_epsi_c2bcc29864.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_CK1_softmax_0dfa4cfba4.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_CKfull_epsi_814538c465.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_CKfull_softmax_495e85c73c.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_epsi_e62bde6a99.png\n",
      "706893_2024-05-28_15-15-38_QLearning_L2F1_softmax_c23c0e9756.png\n",
      "706893_2024-05-28_15-15-38_WSLS_b99fca1dd0.png\n",
      "706893_2024-05-28_15-15-38_WSLS_CK1_e30c0a8d4b.png\n",
      "706893_2024-05-28_15-15-38_WSLS_CKfull_271f44abdc.png\n",
      "730945_2024-10-24_17-38-06_QLearning_L1F0_epsi_58cc5b6f6e.png\n",
      "730945_2024-10-24_17-38-06_QLearning_L1F1_CK1_softmax_3ffdf98012.png\n",
      "730945_2024-10-24_17-38-06_QLearning_L2F1_CK1_softmax_5ce7f1f816.png\n",
      "730945_2024-10-24_17-38-06_QLearning_L2F1_softmax_ec59be40c0.png\n",
      "730945_2024-10-24_17-38-06_WSLS_7c61d01e0f.png\n"
     ]
    }
   ],
   "source": [
    "df = get_mle_model_fitting(\n",
    "    subject_id=\"706893\",\n",
    "    session_date=\"2024-05-28\",\n",
    "    if_download_figures=True,\n",
    "    download_path=\"./mle_figures\",\n",
    ")\n",
    "!ls ./mle_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "973168e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_logistic = get_logistic_regression(\n",
    "#     df_sessions=pd.DataFrame(\n",
    "#         {\n",
    "#             \"subject_id\": [\"769253\"],\n",
    "#             \"session_date\": [\"2025-03-12\"],\n",
    "#         }\n",
    "#     ),\n",
    "#     model=None,\n",
    "#     if_download_figures=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3cef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_mle_model_fitting(\n",
      "    subject_id: str = None,\n",
      "    session_date: str = None,\n",
      "    agent_alias: str = None,\n",
      "    from_custom_query: dict = None,\n",
      "    if_include_metrics: bool = True,\n",
      "    if_include_latent_variables: bool = True,\n",
      "    if_download_figures: bool = False,\n",
      "    download_path: str = \"./results/mle_figures/\",\n",
      "    paginate_settings: dict = {\"paginate\": False},\n",
      "    max_threads_for_s3: int = 10,\n",
      ") -> pd.DataFrame:\n",
      "    \"\"\"Get MLE fitting from Han's analysis pipeline (the newer one with docDB)\n",
      "    (https://github.com/AllenNeuralDynamics/aind-analysis-arch-pipeine-dynamic-foraging)\n",
      "\n",
      "    The method queries fitting metrics from docDB and, optionally, download the latent variables and\n",
      "    figures from s3.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    subject_id : str, optional\n",
      "        The subject_id, by default None\n",
      "    session_date : str, optional\n",
      "        The session_date, by default None\n",
      "    agent_alias : str, optional\n",
      "        The agent_alias, by default None\n",
      "    from_custom_query : dict, optional\n",
      "        The custom query, by default None\n",
      "        If provided, subject_id, session_date, and agent_alias will be ignored.\n",
      "        Error will be raised if none of the four is provided.\n",
      "    if_include_metrics : bool, optional\n",
      "        Whether to include the metrics in the DataFrame, by default True\n",
      "        If False, only the agent_alias will be included.\n",
      "    if_include_latent_variables : bool, optional\n",
      "        Whether to include the latent variables in the DataFrame, by default True\n",
      "    if_download_figures : bool, optional\n",
      "        Whether to download the figures from s3, by default False\n",
      "    download_path : str, optional\n",
      "        The path to download the figures, by default \"./results/mle_figures/\"\n",
      "    paginate_settings : dict, optional\n",
      "        The settings for pagination, by default {\"paginate\": False}.\n",
      "        If you see a 503 error, you may need to set paginate to True.\n",
      "        See aind_data_access_api documentation.\n",
      "    max_threads_for_s3: int, optional\n",
      "        The maximum number of parallel threads for getting result from s3, by default 10\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame containing model fitting results\n",
      "    \"\"\"\n",
      "\n",
      "    # -- Build query --\n",
      "    filter_query = build_query(from_custom_query, subject_id, session_date, agent_alias)\n",
      "\n",
      "    projection = {\n",
      "        \"_id\": 1,\n",
      "        \"nwb_name\": 1,\n",
      "        \"analysis_results.fit_settings.agent_alias\": 1,\n",
      "        \"status\": 1,\n",
      "        \"subject_id\": 1,\n",
      "        \"session_date\": 1,\n",
      "    }\n",
      "    if if_include_metrics:\n",
      "        projection.update(\n",
      "            {\n",
      "                \"analysis_results.log_likelihood\": 1,\n",
      "                \"analysis_results.prediction_accuracy\": 1,\n",
      "                \"analysis_results.k_model\": 1,\n",
      "                \"analysis_results.n_trials\": 1,\n",
      "                \"analysis_results.AIC\": 1,\n",
      "                \"analysis_results.BIC\": 1,\n",
      "                \"analysis_results.LPT\": 1,\n",
      "                \"analysis_results.LPT_AIC\": 1,\n",
      "                \"analysis_results.LPT_BIC\": 1,\n",
      "                \"analysis_results.cross_validation\": 1,\n",
      "                \"analysis_results.params\": 1,\n",
      "            }\n",
      "        )\n",
      "\n",
      "    # -- Retrieve records --\n",
      "    print(f\"Query: {filter_query}\")\n",
      "    records = analysis_docDB_dft.retrieve_docdb_records(\n",
      "        filter_query=filter_query,\n",
      "        projection=projection,\n",
      "        **paginate_settings,\n",
      "    )\n",
      "\n",
      "    if not records:\n",
      "        print(f\"No MLE fitting available for {subject_id} on {session_date}\")\n",
      "        return None\n",
      "\n",
      "    print(f\"Found {len(records)} MLE fitting records!\")\n",
      "\n",
      "    # -- Reformat the records --\n",
      "    # Turn the nested json into a flat DataFrame and rename the columns, except params\n",
      "    if if_include_metrics:\n",
      "        params = [\n",
      "            record[\"analysis_results\"].pop(\"params\") if record[\"status\"] == \"success\" else None\n",
      "            for record in records\n",
      "        ]\n",
      "    df = pd.json_normalize(records)\n",
      "    df = df.rename(\n",
      "        columns={\n",
      "            col: col.replace(\"analysis_results.\", \"\")\n",
      "            .replace(\"cross_validation.\", \"\")\n",
      "            .replace(\"fit_settings.\", \"\")\n",
      "            for col in df.columns\n",
      "        }\n",
      "    )\n",
      "\n",
      "    # If the user specifies one certain session, and there are multiple nwbs for this session,\n",
      "    # we warn the user to check nwb time stamps.\n",
      "    if subject_id and session_date and df.agent_alias.duplicated().any():\n",
      "        print(\n",
      "            \"Duplicated agent_alias!\\n\"\n",
      "            \"There are multiple nwbs for this session:\\n\"\n",
      "            f\"{df.nwb_name.unique()}\\n\"\n",
      "            \"You should check the time stamps to select the one you want.\"\n",
      "        )\n",
      "\n",
      "    # -- Some post-processing of metrics --\n",
      "    if if_include_metrics:\n",
      "        # Put in params as dict\n",
      "        df[\"params\"] = params\n",
      "\n",
      "        # Compute cross_validation mean and std\n",
      "        for group in [\"test\", \"fit\", \"test_bias_only\"]:\n",
      "            df[f\"prediction_accuracy_10-CV_{group}\"] = df[f\"prediction_accuracy_{group}\"].apply(\n",
      "                lambda x: np.mean(x)\n",
      "            )\n",
      "            df[f\"prediction_accuracy_10-CV_{group}_std\"] = df[f\"prediction_accuracy_{group}\"].apply(\n",
      "                lambda x: np.std(x)\n",
      "            )\n",
      "\n",
      "    # -- Get latent variables --\n",
      "    df_success = df.query(\"status == 'success'\")\n",
      "    print(f\"Found {len(df_success)} successful MLE fitting!\")\n",
      "    if not len(df_success):\n",
      "        return df\n",
      "\n",
      "    if if_include_latent_variables:\n",
      "        latents = get_s3_latent_variable_batch(\n",
      "            df_success._id, max_threads_for_s3=max_threads_for_s3\n",
      "        )\n",
      "        df = df.merge(pd.DataFrame(latents), on=\"_id\", how=\"left\")\n",
      "\n",
      "    # -- Download figures --\n",
      "    if if_download_figures:\n",
      "        f_names = (\n",
      "            df.nwb_name.map(lambda x: x.replace(\".nwb\", \"\"))\n",
      "            + \"_\"\n",
      "            + df.agent_alias\n",
      "            + \"_\"\n",
      "            + df._id.map(lambda x: x[:10])\n",
      "            + \".png\"\n",
      "        )  # Build the file names\n",
      "        get_s3_mle_figure_batch(\n",
      "            ids=df_success._id,\n",
      "            f_names=f_names,\n",
      "            download_path=download_path,\n",
      "            max_threads_for_s3=max_threads_for_s3,\n",
      "        )\n",
      "\n",
      "    return df\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from aind_analysis_arch_result_access.han_pipeline import get_mle_model_fitting\n",
    "import inspect\n",
    "\n",
    "print(inspect.getsource(get_mle_model_fitting))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aind_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
